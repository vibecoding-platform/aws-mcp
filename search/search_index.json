{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to AWS MCP Servers","text":"<p>A suite of specialized MCP servers that help you get the most out of AWS, wherever you use MCP.</p>"},{"location":"#available-mcp-servers","title":"Available MCP Servers","text":""},{"location":"#core-mcp-server","title":"Core MCP Server","text":"<p>The Core MCP Server manages and coordinates other MCP servers in your environment, providing automatic installation, configuration, and management.</p> <p>Features:</p> <ul> <li>Automatic MCP Server Management</li> <li>Planning and guidance to orchestrate MCP Servers</li> <li>UVX Installation Support</li> <li>Centralized Configuration</li> </ul> <p>Learn more about the Core MCP Server</p>"},{"location":"#aws-documentation-mcp-server","title":"AWS Documentation MCP Server","text":"<p>The AWS Documentation MCP Server provides access to AWS documentation and best practices.</p> <p>Features:</p> <ul> <li>Search Documentation using the official AWS search API</li> <li>Get content recommendations for AWS documentation pages</li> <li>Convert documentation to markdown format</li> </ul> <p>Learn more about the AWS Documentation MCP Server</p>"},{"location":"#aws-cdk-mcp-server","title":"AWS CDK MCP Server","text":"<p>The CDK MCP Server provides AWS Cloud Development Kit (CDK) best practices, infrastructure as code patterns, and security compliance with CDK Nag.</p> <p>Features:</p> <ul> <li>CDK Best Practices</li> <li>CDK Nag Integration</li> <li>AWS Solutions Constructs</li> <li>GenAI CDK Constructs</li> </ul> <p>Learn more about the CDK MCP Server</p>"},{"location":"#amazon-nova-canvas-mcp-server","title":"Amazon Nova Canvas MCP Server","text":"<p>The Nova Canvas MCP Server enables AI assistants to generate images using Amazon Nova Canvas.</p> <p>Features:</p> <ul> <li>Text-based image generation</li> <li>Color-guided image generation</li> <li>Workspace integration</li> </ul> <p>Learn more about the Amazon Nova Canvas MCP Server</p>"},{"location":"#amazon-kendra-index-mcp-server","title":"Amazon Kendra Index MCP Server","text":"<p>The Amazon Kendra Index MCP Server enables AI assistants to retrieve additional context from a specified Amazon Kendra index.</p> <p>Features:</p> <ul> <li>Query a specified Kendra index</li> </ul> <p>Learn more about the Amazon Kendra Index MCP Server</p>"},{"location":"#amazon-bedrock-knowledge-base-retrieval-mcp-server","title":"Amazon Bedrock Knowledge Base Retrieval MCP Server","text":"<p>The Bedrock Knowledge Base Retrieval MCP Server enables AI assistants to retrieve information from Amazon Bedrock Knowledge Bases.</p> <p>Features:</p> <ul> <li>Discover knowledge bases and their data sources</li> <li>Query knowledge bases with natural language</li> <li>Filter results by data source</li> <li>Rerank results</li> </ul> <p>Learn more about the Bedrock Knowledge Base Retrieval MCP Server</p>"},{"location":"#cost-analysis-mcp-server","title":"Cost Analysis MCP Server","text":"<p>The Cost Analysis MCP Server enables AI assistants to analyze the cost of AWS services.</p> <p>Features:</p> <ul> <li>Analyze and predict AWS costs before deployment</li> <li>Query cost data with natural language</li> <li>Generate cost reports and insights</li> </ul> <p>Learn more about the Cost Analysis MCP Server</p>"},{"location":"#aws-lambda-tool-mcp-server","title":"AWS Lambda Tool MCP Server","text":"<p>The AWS Lambda Tool MCP Server enables AI assistants to select and run AWS Lambda functions as MCP tools.</p> <p>Features:</p> <ul> <li>Select and run AWS Lambda functions as MCP tools</li> <li>Tool names and descriptions are taken from the AWS Lambda function configuration</li> <li>Filter functions by name, tag, or both</li> <li>Use AWS credentials to invoke the Lambda functions</li> </ul> <p>Learn more about the AWS Lambda Tool MCP Server</p>"},{"location":"#amazon-aurora-dsql-mcp-server","title":"Amazon Aurora DSQL MCP Server","text":"<p>An AWS Labs Model Context Protocol (MCP) server for Aurora DSQL</p> <p>Features:</p> <ul> <li>Execute read only queries</li> <li>Fetch table schema</li> <li>Write or modify data using SQL, in a transaction</li> </ul> <p>Learn more about the Amazon Aurora DSQL MCP Server</p>"},{"location":"#aws-diagram-mcp-server","title":"AWS Diagram MCP Server","text":"<p>This MCP server that seamlessly creates diagrams using the Python diagrams package DSL. This server allows you to generate AWS diagrams, sequence diagrams, flow diagrams, and class diagrams using Python code.</p> <p>Features:</p> <p>The Diagrams MCP Server provides the following capabilities:</p> <ol> <li>Generate Diagrams: Create professional diagrams using Python code</li> <li>Multiple Diagram Types: Support for AWS architecture, sequence diagrams, flow charts, class diagrams, and more</li> <li>Customization: Customize diagram appearance, layout, and styling</li> <li>Security: Code scanning to ensure secure diagram generation</li> </ol> <p>Learn more about the AWS Diagram MCP Server</p>"},{"location":"#aws-terraform-mcp-server","title":"AWS Terraform MCP Server","text":"<p>The Terraform MCP Server enables AWS best practices, infrastructure as code patterns, and security compliance with Checkov.</p> <p>Features:</p> <p>The Terraform MCP Server provides the following capabilities:</p> <ul> <li>Terraform Best Practices</li> <li>Security-First Development Workflow</li> <li>Checkov Integration</li> <li>AWS and AWSCC Provider Documentation</li> <li>AWS-IA GenAI Modules</li> <li>Terraform Workflow Execution</li> </ul> <p>Learn more about the AWS Terraform MCP Server</p>"},{"location":"#frontend-mcp-server","title":"Frontend MCP Server","text":"<p>The Frontend MCP Server provides specialized tools for prototyping web applications with React and AWS Amplify.</p> <p>Features:</p> <ul> <li>Create a web application using React, Tailwind, and shadcn</li> <li>Customize the application based on functional requirements, deconstructing high-level application goals into features, pages, and components</li> <li>Automatic application naming, branding (customized theme) and thematic image generation (splash images, fav icon) using Nova Canvas MCP</li> <li>Integrated authentication flows with AWS Amplify auth</li> </ul> <p>Learn more about the Frontend MCP Server</p>"},{"location":"#amazon-elasticachememorydb-for-valkey-mcp-server","title":"Amazon ElastiCache/MemoryDB for Valkey MCP Server","text":"<p>The Amazon ElastiCache/MemoryDB Valkey MCP Server provides a natural language interface to interact with Valkey datastores, enabling AI assistants to work with various data structures and perform complex data operations.</p> <p>Features:</p> <ul> <li>Support for multiple data types (Strings, Lists, Sets, Sorted Sets, Hashes, Streams, etc.)</li> <li>Advanced features like cluster support</li> <li>JSON document storage and querying</li> <li>Secure connections with SSL/TLS support</li> <li>Connection pooling for efficient resource management</li> </ul> <p>Learn more about the Amazon ElastiCache for Valkey MCP Server</p>"},{"location":"#amazon-elasticache-for-memcached-mcp-server","title":"Amazon ElastiCache for Memcached MCP Server","text":"<p>A server that provides natural language interface to interact with Amazon ElastiCache  Memcached caches, enabling AI agents to efficiently manage and search cached data.</p> <p>Features:</p> <ul> <li>Natural language interface for cache operations</li> <li>Comprehensive command support (Get, Set, Remove, Touch, CAS, Increment, Decrement)</li> <li>Secure connections with SSL/TLS</li> <li>Connection pooling and efficient resource management</li> </ul> <p>Learn more about the Amazon ElastiCache for Memcached MCP Server</p>"},{"location":"#code-documentation-generation-mcp-server","title":"Code Documentation Generation MCP Server","text":"<p>The Code Documentation Generation MCP Server automatically generates comprehensive documentation for code repositories.</p> <p>Features:</p> <ul> <li>Automated documentation generation based on repository analysis</li> <li>AWS architecture diagram integration</li> <li>Multiple document types (README, API, Backend, Frontend)</li> <li>Interactive documentation creation workflow</li> </ul> <p>Learn more about the Code Documentation Generation MCP Server</p>"},{"location":"#aws-location-service-mcp-server","title":"AWS Location Service MCP Server","text":"<p>A server for accessing AWS Location Service capabilities, focusing on place search, geographical coordinates, and route planning.</p> <p>Features:</p> <ul> <li>Search for places using geocoding</li> <li>Get details for specific places by PlaceId</li> <li>Reverse geocode coordinates to addresses</li> <li>Search for places near a location</li> <li>Search for places that are currently open</li> <li>Calculate routes between locations with turn-by-turn directions</li> <li>Optimize waypoints for efficient routing</li> </ul> <p>Learn more about the AWS Location Service MCP Server</p>"},{"location":"#aws-cloudformation-mcp-server","title":"AWS CloudFormation MCP Server","text":"<p>A server for managing your AWS resources directly and through cloudformation.</p> <p>Features:</p> <ul> <li>Create/Update/Delete your resources with the resource access tools</li> <li>List/Read your resources with the resource access tools</li> </ul> <p>Learn more about the AWS CloudFormation MCP Server</p>"},{"location":"#git-repo-research-mcp-server","title":"Git Repo Research MCP Server","text":"<p>A server for researching Git repositories using semantic search.</p> <p>Features:</p> <ul> <li>Repository Indexing with FAISS and Amazon Bedrock embeddings</li> <li>Semantic Search within repositories</li> <li>Repository Structure Analysis</li> <li>GitHub Repository Search in AWS organizations</li> <li>File Access with text and binary support</li> </ul> <p>Learn more about the Git Repo Research MCP Server</p>"},{"location":"#amazon-aurora-postgres-mcp-server","title":"Amazon Aurora Postgres MCP Server","text":"<p>A server for Aurora Postgres.</p> <p>Features:</p> <ul> <li>Converting human-readable questions and commands into structured Postgres-compatible SQL queries and executing them against the configured Aurora Postgres database</li> <li>Fetch table columns and comments from Postgres using RDS Data API</li> </ul> <p>Learn more about the Amazon Aurora Postgres MCP Server</p>"},{"location":"#amazon-aurora-mysql-mcp-server","title":"Amazon Aurora MySql MCP Server","text":"<p>A server for Aurora MySql.</p> <p>Features:</p> <ul> <li>Converting human-readable questions and commands into structured MySQL-compatible SQL queries and executing them against the configured Aurora MySQL database.</li> <li>Fetch table schema</li> </ul> <p>Learn more about the Amazon Aurora MySql MCP Server</p>"},{"location":"#amazon-cloudwatch-logs-mcp-server","title":"Amazon CloudWatch Logs MCP Server","text":"<p>An AWS Labs Model Context Protocol (MCP) server for Amazon Cloudwatch Logs.</p> <p>Features:</p> <ul> <li>Discover log groups and their metadata</li> <li>Execute CloudWatch Log Insights queries against log groups</li> </ul> <p>Use this MCP server to first discover available logs groups, then run queries on them to filter, analyze, aggregate, etc. logs.</p> <p>Learn more about the Amazon CloudWatch Logs MCP Server</p>"},{"location":"#aws-managed-prometheus-mcp-server","title":"AWS Managed Prometheus MCP Server","text":"<p>The Prometheus MCP Server provides a robust interface for interacting with AWS Managed Prometheus.</p> <p>Features:</p> <ul> <li>Execute instant PromQL queries against AWS Managed Prometheus</li> <li>Execute range queries with start time, end time, and step interval</li> <li>List all available metrics in your Prometheus instance</li> <li>Get server configuration information</li> <li>AWS SigV4 authentication for secure access</li> </ul> <p>Learn more about the AWS Managed Prometheus MCP Server</p>"},{"location":"#amazon-dynamodb-mcp-server","title":"Amazon DynamoDB MCP Server","text":"<p>A server for interacting with Amazon DynamoDB</p> <p>Features:</p> <ul> <li>Control Plane operations like table creation, table update, global secondary index, streams, global table management, backup, restore, etc.</li> <li>Data Plane operations like put, get, update, query and scan.</li> </ul> <p>Learn more about the Amazon DynamoDB MCP Server</p>"},{"location":"#amazon-elasticache-mcp-server","title":"Amazon ElastiCache MCP Server","text":"<p>A server for managing and interacting with Amazon ElastiCache resources.</p> <p>Features:</p> <ul> <li>Replication Group Operations (create, delete, modify, describe)</li> <li>Cache Cluster Operations (create, delete, modify, describe)</li> <li>Serverless Cache Operations (create, delete, modify, describe)</li> <li>Jump Host Configuration for secure access</li> <li>Service Updates and Engine Management</li> <li>Comprehensive monitoring and event tracking</li> </ul> <p>Learn more about the Amazon ElastiCache MCP Server</p>"},{"location":"#amazon-documentdb-mcp-server","title":"Amazon DocumentDB MCP Server","text":"<p>The DocumentDB MCP Server enables AI assistants to interact with Amazon DocumentDB databases, providing secure query capabilities and database operations.</p> <p>Features:</p> <ul> <li>Connection management for DocumentDB clusters</li> <li>Query documents with filtering and projection</li> <li>Execute MongoDB aggregation pipelines</li> <li>Optional read-only mode for enhanced security</li> <li>Automatic connection cleanup and resource management</li> </ul> <p>Learn more about the Amazon DocumentDB MCP Server</p>"},{"location":"#amazon-eks-mcp-server","title":"Amazon EKS MCP Server","text":"<p>A Model Context Protocol (MCP) server for Amazon EKS that enables generative AI models to create and manage Kubernetes clusters on AWS through MCP tools.</p> <p>Features:</p> <ul> <li>EKS Cluster Management: Create and manage EKS clusters with dedicated VPCs, proper networking, and CloudFormation templates for reliable, repeatable deployments</li> <li>Kubernetes Resource Management: Create, read, update, delete, and list Kubernetes resources with support for applying YAML manifests</li> <li>Application Deployment: Generate and deploy Kubernetes manifests with customizable parameters for containerized applications</li> <li>Operational Support: Access pod logs, Kubernetes events, and monitor cluster resources</li> <li>CloudWatch Integration: Retrieve logs and metrics from CloudWatch for comprehensive monitoring</li> <li>Security-First Design: Configurable read-only mode, sensitive data access controls, and IAM integration for proper permissions management</li> </ul> <p>Learn more about the Amazon EKS MCP Server</p>"},{"location":"#synthetic-data-mcp-server","title":"Synthetic Data MCP Server","text":"<p>A server for generating, validating, and managing synthetic data.</p> <ul> <li>Business-Driven Generation: Generate synthetic data instructions based on business descriptions</li> <li>Safe Pandas Code Execution: Run pandas code in a restricted environment with automatic DataFrame detection</li> <li>JSON Lines Validation: Validate and convert JSON Lines data to CSV format</li> <li>Data Validation: Validate data structure, referential integrity, and save as CSV files</li> <li>Referential Integrity Checking: Validate relationships between tables</li> <li>Data Quality Assessment: Identify potential issues in data models (3NF validation)</li> <li>Storage Integration: Load data to various storage targets (S3) with support for multiple formats and configurations</li> </ul> <p>Learn more about the Synthetic Data MCP Server</p>"},{"location":"#amazon-neptune-mcp-server","title":"Amazon Neptune MCP Server","text":"<p>A server for interacting with Amazon Neptune graph database.</p> <ul> <li>Run openCypher/Gremlin queries on a Neptune Database</li> <li>Run openCypher queries on Neptune Analytics</li> <li>Get the schema of the graph</li> </ul> <p>Learn more about the Amazon Neptune MCP Server</p>"},{"location":"#aws-bedrock-data-automation-mcp-server","title":"AWS Bedrock Data Automation MCP Server","text":"<p>A Model Context Protocol (MCP) server for Amazon Bedrock Data Automation that enables AI assistants to analyze documents, images, videos, and audio files using Amazon Bedrock Data Automation projects.</p> <p>Features:</p> <ul> <li>Project Management: List and get details about Bedrock Data Automation projects</li> <li>Asset Analysis: Extract insights from unstructured content using Bedrock Data Automation</li> <li>Support for Multiple Content Types: Process documents, images, videos, and audio files</li> <li>Integration with Amazon S3: Seamlessly upload and download assets and results</li> </ul> <p>Learn more about the AWS Bedrock Data Automation MCP Server</p>"},{"location":"#amazon-keyspaces-for-apache-cassandra-mcp-server","title":"Amazon Keyspaces (for Apache Cassandra) MCP Server","text":"<p>An Amazon Keyspaces (for Apache Cassandra) MCP server enables AI assistants to interact with Amazon Keyspaces and Apache Cassandra.</p> <p>Features: - Explore keyspaces and tables. - Execute CQL SELECT queries against the configured database. - Get feedback and suggestions for improving query performance. - Use with Amazon Keyspaces, or with Apache Cassandra.</p> <p>Learn more about the Amazon Keysapces MCP Server</p>"},{"location":"#amazon-timestream-for-influxdb-mcp-server","title":"Amazon Timestream for InfluxDB MCP Server","text":"<p>A Model Context Protocol (MCP) server for Amazon Timestream for InfluxDB that enables AI assistants to help create, list, store, and query time-series data using InfluxDB.</p> <p>** Features ** - Create, update, list, describe, and delete Timestream for InfluxDB database instances - Create, update, list, describe, and delete Timestream for InfluxDB database clusters - Manage DB parameter groups - Tag management for Timestream for InfluxDB resources - Write and query data using InfluxDB's APIs</p> <p>Learn more about the Amazon Timestream for InfluxDB MCP Server</p>"},{"location":"#aws-cost-explorer-mcp-server","title":"AWS Cost Explorer MCP Server","text":"<p>A server for interacting with AWS Cost Explorer to analyze AWS costs and usage data.</p> <p>Features:</p> <ul> <li>Get detailed breakdowns of AWS costs by service, region, and other dimensions</li> <li>Understand how costs are distributed across various services</li> <li>Query historical cost data for specific time periods</li> <li>Filter costs by various dimensions, tags, and cost categories</li> <li>Ask natural language questions about AWS costs</li> </ul> <p>Learn more about the AWS Cost Explorer MCP Server</p>"},{"location":"#installation-and-setup","title":"Installation and Setup","text":"<p>Please refer to the README files in each server's directory for specific installation instructions.</p>"},{"location":"#samples","title":"Samples","text":"<p>Please refer to the samples directory for examples of how to use the MCP Servers.</p>"},{"location":"#contributing","title":"Contributing","text":"<p>Contributions are welcome! Please see the contributing guidelines for more information.</p>"},{"location":"#disclaimer","title":"Disclaimer","text":"<p>Before using an MCP Server, you should consider conducting your own independent assessment to ensure that your use would comply with your own specific security and quality control practices and standards, as well as the laws, rules, and regulations that govern you and your content.</p>"},{"location":"samples/","title":"AWS MCP Servers - Samples","text":"<p>This directory contains a collection of examples demonstrating how to use the AWS MCP Servers provided in the <code>src</code> directory. Each sample is organized into its own folder with relevant documentation and code.</p>"},{"location":"samples/#structure","title":"Structure","text":"<pre><code>samples/\n\u251c\u2500\u2500 project-name/\n\u2502   \u251c\u2500\u2500 README.md\n\u2502   \u2514\u2500\u2500 (sample code and resources)\n</code></pre>"},{"location":"samples/#purpose","title":"Purpose","text":"<p>The samples in this directory provide:</p> <ul> <li>Working examples for each AWS MCP Server</li> <li>Integration patterns and best practices</li> <li>Code snippets for common use cases</li> <li>Step-by-step guides</li> </ul>"},{"location":"samples/#guidelines","title":"Guidelines","text":"<ul> <li>Each sample directory should focus on demonstrating one or more MCP servers</li> <li>All samples must include a README.md with clear instructions</li> <li>Samples should not introduce new MCP servers, but only demonstrate usage of existing ones</li> </ul>"},{"location":"samples/#available-samples","title":"Available Samples","text":""},{"location":"samples/#mcp-integration-with-kb","title":"MCP Integration with KB","text":"<p>A client that integrates with the Amazon Bedrock Knowledge Base MCP server. Code can be found in the mcp-integration-with-kb folder.</p>"},{"location":"samples/#aws-step-functions-tool-mcp-server","title":"AWS Step Functions Tool MCP Server","text":"<p>A server that enables AI models to execute AWS Step Functions state machines as tools, allowing seamless integration with existing workflows. The server supports both Standard and Express workflows, and integrates with EventBridge Schema Registry for input validation. Code can be found in the src/stepfunctions-tool-mcp-server folder.</p>"},{"location":"samples/#coming-soon","title":"Coming Soon","text":""},{"location":"samples/#contributing","title":"Contributing","text":"<p>We welcome contributions of additional samples. Please ensure your sample follows the guidelines above and demonstrates real-world usage of the MCP servers.</p>"},{"location":"samples/mcp-integration-with-kb/","title":"MCP Integration with Amazon Bedrock Knowledge Bases","text":"<p>This repository outlines a basic implementation of the Model Context Protocol integration with Amazon Bedrock Knowledge Bases</p>"},{"location":"samples/mcp-integration-with-kb/#overview","title":"Overview","text":"<p>There are two parts to this implementation:</p> <ol> <li>The <code>user_interfaces/chat_bedrock_st.py</code> file, which handles the Streamlit/User Interface for the chatbot</li> <li>The <code>client_server.py</code> file, which handles the MCP client and server implementation</li> </ol> <p>The exact MCP server code used in this implementation can be found in the src/bedrock-kb-retrieval-mcp-server folder.</p>"},{"location":"samples/mcp-integration-with-kb/#architecture","title":"Architecture","text":""},{"location":"samples/mcp-integration-with-kb/#setup","title":"Setup","text":""},{"location":"samples/mcp-integration-with-kb/#prerequisites","title":"Prerequisites","text":"<ul> <li>The uv package manager</li> <li>AWS Account with Bedrock access and proper IAM permissions - Getting Started with Amazon Bedrock</li> <li>A Bedrock Knowledge Base</li> <li>For a quick reference Knowledge Base setup, check out the e2e RAG solution via CDK repo. This will set you up with everything you need - IAM roles, vector storage (either OpenSearch Serverless or Aurora PostgreSQL), and a fully configured Knowledge Base with sample data. The Knowledge Base is the only component you'll really need for this implementation.</li> </ul> <p>Note: Reranking for Amazon Bedrock is not supported in us-east-1. For more information about supported regions and models for reranking, see Supported Regions and models for reranking in Amazon Bedrock.</p>"},{"location":"samples/mcp-integration-with-kb/#installation","title":"Installation","text":"<ol> <li>Clone the repository.</li> </ol> <pre><code>git clone https://github.com/awslabs/mcp.git\n</code></pre> <ol> <li>Navigate to the sample directory and copy the .env.example file to .env and add your AWS credentials.</li> </ol> <pre><code>cd mcp/samples/mcp-integration-with-kb\ncp .env.example .env\n</code></pre> <ol> <li>Open two different terminals and install the dependencies in each.</li> </ol> <pre><code>uv sync\n</code></pre> <p>then activate the virtual environment</p> <pre><code>source .venv/bin/activate\n</code></pre> <ol> <li>In one of the terminals, run the FastAPI server</li> </ol> <pre><code>uvicorn clients.client_server:app --reload\n</code></pre> <ol> <li>In the other terminal, run the Streamlit app</li> </ol> <pre><code>streamlit run user_interfaces/chat_bedrock_st.py\n</code></pre> <ol> <li>The chatbot should now be running on http://localhost:8501/</li> </ol>"},{"location":"samples/mcp-integration-with-kb/#usage","title":"Usage","text":"<p>Grab your Bedrock Knowledge Base ID from the Bedrock Knowledge Base console and add it to the UI first on the left hand side menu.</p> <p>Ask away!</p>"},{"location":"samples/mcp-integration-with-kb/#troubleshooting","title":"Troubleshooting","text":"<p>Logs are available in the terminal where you ran the FastAPI server, outlining various steps and actions taken by the server.</p> <p>If you see an error about <code>boto3</code> or <code>streamlit</code> not being found, it is likely because you did not activate the virtual environment:</p> <pre><code>uv sync\nsource .venv/bin/activate\n</code></pre>"},{"location":"servers/amazon-keyspaces-mcp-server/","title":"AWS Labs amazon-keyspaces MCP Server","text":"<p>An Amazon Keyspaces (for Apache Cassandra) MCP server for interacting with Amazon Keyspaces and Apache Cassandra.</p>"},{"location":"servers/amazon-keyspaces-mcp-server/#overview","title":"Overview","text":"<p>The Amazon Keyspaces MCP server implements the Model Context Protocol (MCP) to enable AI assistants like Amazon Q to interact with Amazon Keyspaces or Apache Cassandra databases through natural language. This server allows you to explore  database schemas, execute queries, and analyze query performance without having to write CQL code directly.</p>"},{"location":"servers/amazon-keyspaces-mcp-server/#features","title":"Features","text":"<p>The Amazon Keyspaces (for Apache Cassandra) MCP server provides the following capabilities: 1. Schema: Explore keyspaces and tables. 2. Run Queries: Execute CQL SELECT queries against the configured database. 3. Query Analysis: Get feedback and suggestions for improving query performance. 4. Cassandra-Compatible: Use with Amazon Keyspaces, or with Apache Cassandra.</p> <p>Here are some example prompts that this MCP server can help with: - \"List all keyspaces in my Cassandra database\" - \"Show me the tables in the 'sales' keyspace\" - \"Describe the 'users' table in the 'sales' keyspace\" - \"What's the schema of the 'products' table?\" - \"Run a SELECT query to get all users from the 'users' table in 'sales'\" - \"Query the first 10 records from the 'events' table\" - \"Analyze the performance of this query: SELECT * FROM users WHERE last_name = 'Smith'\" - \"Is this query efficient: SELECT * FROM orders WHERE order_date &gt; '2023-01-01'?\"</p>"},{"location":"servers/amazon-keyspaces-mcp-server/#installation","title":"Installation","text":""},{"location":"servers/amazon-keyspaces-mcp-server/#prerequisites","title":"Prerequisites","text":"<ul> <li>Python 3.10 or 3.11 (Python 3.12+ is not fully supported due to asyncore module removal)</li> <li>Access to an Amazon Keyspaces instance or Apache Cassandra cluster that supports password authentication</li> <li>Appropriate Cassandra log-in credentials</li> <li>Starfield digital certificate (required for Amazon Keyspaces)</li> </ul>"},{"location":"servers/amazon-keyspaces-mcp-server/#install-from-pypi","title":"Install from PyPI","text":"<pre><code>pip install awslabs.amazon-keyspaces-mcp-server\n</code></pre>"},{"location":"servers/amazon-keyspaces-mcp-server/#install-from-source","title":"Install from Source","text":"<ol> <li> <p>Clone the repository:    <pre><code>git clone https://github.com/awslabs/mcp.git\ncd mcp/src/amazon-keyspaces-mcp-server\n</code></pre></p> </li> <li> <p>Create a virtual environment:    <pre><code>python -m venv .venv\nsource .venv/bin/activate  # On Windows: .venv\\Scripts\\activate\n</code></pre></p> </li> <li> <p>Install the package:    <pre><code>pip install -e .\n</code></pre></p> </li> </ol>"},{"location":"servers/amazon-keyspaces-mcp-server/#configuration","title":"Configuration","text":"<p>Create a <code>.env</code> file in your working directory with your database connection settings:</p> <pre><code># Set to true for Amazon Keyspaces, false for Apache Cassandra\nDB_USE_KEYSPACES=true\n\n# Cassandra configuration (for native Cassandra)\nDB_CASSANDRA_CONTACT_POINTS=127.0.0.1\nDB_CASSANDRA_PORT=9042\nDB_CASSANDRA_LOCAL_DATACENTER=datacenter1\nDB_CASSANDRA_USERNAME=\nDB_CASSANDRA_PASSWORD=\n\n# Keyspaces configuration (for Amazon Keyspaces)\nDB_KEYSPACES_ENDPOINT=cassandra.us-west-2.amazonaws.com\nDB_KEYSPACES_REGION=us-west-2\n</code></pre>"},{"location":"servers/amazon-keyspaces-mcp-server/#authentication-credentials","title":"Authentication Credentials","text":"<p>This MCP server uses username and password authentication for both Amazon Keyspaces and Apache Cassandra:</p> <ul> <li> <p>For Amazon Keyspaces: Set the <code>DB_CASSANDRA_USERNAME</code> and <code>DB_CASSANDRA_PASSWORD</code> environment variables with your Keyspaces username and password. These are the same service-specific credentials you would use to access Keyspaces via the Cassandra Query Language (CQL) shell.</p> </li> <li> <p>For Apache Cassandra: Set the <code>DB_CASSANDRA_USERNAME</code> and <code>DB_CASSANDRA_PASSWORD</code> environment variables with your Cassandra username and password.</p> </li> </ul>"},{"location":"servers/amazon-keyspaces-mcp-server/#starfield-digital-certificate-for-amazon-keyspaces","title":"Starfield Digital Certificate for Amazon Keyspaces","text":"<p>Before connecting to Amazon Keyspaces, you need to download and install the Starfield digital certificate that Amazon Keyspaces uses for TLS connections:</p> <ol> <li> <p>Download the Starfield digital certificate:    <pre><code>curl -O https://certs.secureserver.net/repository/sf-class2-root.crt\n</code></pre></p> </li> <li> <p>Place the certificate in the correct location:    <pre><code># If you installed the package from PyPI\nmkdir -p ~/.keyspaces-mcp/certs\ncp sf-class2-root.crt ~/.keyspaces-mcp/certs/\n\n# If you installed from source\nmkdir -p /path/to/mcp/src/amazon-keyspaces-mcp-server/awslabs/certs\ncp sf-class2-root.crt /path/to/mcp/src/amazon-keyspaces-mcp-server/awslabs/certs/\n</code></pre></p> </li> </ol> <p>The MCP server looks for the certificate in the <code>awslabs/certs</code> directory relative to the installation.</p>"},{"location":"servers/amazon-keyspaces-mcp-server/#running-the-mcp-server","title":"Running the MCP Server","text":"<p>After installation, you can run the server directly:</p> <pre><code>awslabs.amazon-keyspaces-mcp-server\n</code></pre>"},{"location":"servers/amazon-keyspaces-mcp-server/#configuring-amazon-q-to-use-the-mcp-server","title":"Configuring Amazon Q to Use the MCP Server","text":"<p>To use the Amazon Keyspaces MCP server with Amazon Q CLI, you need to configure it in your Q configuration file.</p>"},{"location":"servers/amazon-keyspaces-mcp-server/#configuration-for-amazon-q-cli","title":"Configuration for Amazon Q CLI","text":"<p>Edit the Q configuration file at <code>~/.config/amazon-q/config.json</code>:</p> <pre><code>{\n  \"mcpServers\": [\n    {\n      \"name\": \"keyspaces-mcp\",\n      \"command\": \"awslabs.amazon-keyspaces-mcp-server\",\n      \"args\": [],\n      \"env\": {}\n    }\n  ]\n}\n</code></pre> <p>If the file doesn't exist yet or doesn't have an <code>mcpServers</code> section, create it with the structure shown above.</p> <p>Now when you use Q Chat by running <code>q chat</code>, it will automatically connect to your Keyspaces MCP server.</p>"},{"location":"servers/amazon-keyspaces-mcp-server/#available-tools","title":"Available Tools","text":"<p>The Amazon Keyspaces MCP server provides the following tools that AI assistants can use:</p> <ul> <li><code>listKeyspaces</code>: Lists all keyspaces in the database</li> <li><code>listTables</code>: Lists all tables in a specified keyspace</li> <li><code>describeKeyspace</code>: Gets detailed information about a keyspace</li> <li><code>describeTable</code>: Gets detailed information about a table</li> <li><code>executeQuery</code>: Executes a read-only SELECT query against the database</li> <li><code>analyzeQueryPerformance</code>: Analyzes the performance characteristics of a CQL query</li> </ul>"},{"location":"servers/amazon-keyspaces-mcp-server/#security-considerations","title":"Security Considerations","text":"<ul> <li>When using Amazon Keyspaces, ensure your IAM policies follow the principle of least privilege. While this MCP server does not mutate Keyspaces data or resources, it cannot prevent agent-driven attempts to (for example) invoke AWS SDK operations on your behalf, including mutating operations.</li> <li>This MCP server only allows read-only SELECT queries to protect your data.</li> <li>Queries are validated to prevent potentially harmful operations.</li> </ul>"},{"location":"servers/amazon-keyspaces-mcp-server/#troubleshooting","title":"Troubleshooting","text":""},{"location":"servers/amazon-keyspaces-mcp-server/#connection-issues","title":"Connection Issues","text":"<ul> <li>Verify your database connection settings in the <code>.env</code> file.</li> <li>Ensure your logged-in user has the necessary permissions for the operations performed by this server.</li> <li>Check that your database is accessible from your network.</li> <li>For Amazon Keyspaces, verify that the Starfield certificate is correctly installed in the <code>awslabs/certs</code> directory.</li> <li>If you get SSL/TLS errors, check that the certificate path is correct and the certificate is valid.</li> </ul>"},{"location":"servers/amazon-keyspaces-mcp-server/#python-version-compatibility","title":"Python Version Compatibility","text":"<ul> <li>The MCP server works best with Python 3.10 or 3.11.</li> <li>Python 3.12+ may have issues due to the removal of the asyncore module which the Cassandra driver depends on.</li> </ul>"},{"location":"servers/amazon-keyspaces-mcp-server/#cassandra-driver-issues","title":"Cassandra Driver Issues","text":"<p>If you encounter issues with the Cassandra driver:</p> <ol> <li>Ensure you have the necessary C dependencies installed for the Cassandra driver.</li> <li>Try installing the driver with: <code>pip install cassandra-driver --no-binary :all:</code></li> </ol>"},{"location":"servers/amazon-keyspaces-mcp-server/#license","title":"License","text":"<p>This project is licensed under the Apache License 2.0 - see the LICENSE file for details.</p>"},{"location":"servers/amazon-mq-mcp-server/","title":"Amazon MQ MCP Server","text":"<p>A Model Context Protocol (MCP) server for Amazon MQ that enables generative AI models to manage RabbitMQ and ActiveMQ message brokers through MCP tools.</p>"},{"location":"servers/amazon-mq-mcp-server/#features","title":"Features","text":"<p>This MCP server acts as a bridge between MCP clients and Amazon MQ, allowing generative AI models to create, configure, and manage message brokers. The server provides a secure way to interact with Amazon MQ resources while maintaining proper access controls and resource tagging.</p> <pre><code>graph LR\n    A[Model] &lt;--&gt; B[MCP Client]\n    B &lt;--&gt; C[\"Amazon MQ MCP Server\"]\n    C &lt;--&gt; D[Amazon MQ Service]\n    D --&gt; E[RabbitMQ Brokers]\n    D --&gt; F[ActiveMQ Brokers]\n\n    style A fill:#f9f,stroke:#333,stroke-width:2px\n    style B fill:#bbf,stroke:#333,stroke-width:2px\n    style C fill:#bfb,stroke:#333,stroke-width:4px\n    style D fill:#fbb,stroke:#333,stroke-width:2px\n    style E fill:#fbf,stroke:#333,stroke-width:2px\n    style F fill:#dff,stroke:#333,stroke-width:2px</code></pre> <p>From a security perspective, this server implements resource tagging to ensure that only resources created through the MCP server can be modified by it. This prevents unauthorized modifications to existing Amazon MQ resources that were not created by the MCP server.</p>"},{"location":"servers/amazon-mq-mcp-server/#key-capabilities","title":"Key Capabilities","text":"<ul> <li>Create and manage Amazon MQ brokers (RabbitMQ and ActiveMQ)</li> <li>Configure broker settings and parameters</li> <li>List and describe existing brokers</li> <li>Reboot and update brokers</li> <li>Create and manage broker configurations</li> <li>Automatic resource tagging for security</li> </ul>"},{"location":"servers/amazon-mq-mcp-server/#prerequisites","title":"Prerequisites","text":"<ol> <li>Install <code>uv</code> from Astral or the GitHub README</li> <li>Install Python using <code>uv python install 3.10</code></li> <li>AWS account with permissions to create and manage Amazon MQ resources</li> </ol>"},{"location":"servers/amazon-mq-mcp-server/#setup","title":"Setup","text":""},{"location":"servers/amazon-mq-mcp-server/#iam-configuration","title":"IAM Configuration","text":"<p>The authorization between AmazonMQ MCP server and your AWS accounts are performed with AWS profile you setup on the host. There are several ways to setup a AWS profile, however we recommend creating a new IAM role that has <code>AmazonMQReadOnlyAccess</code> permission following the principle of \"least privilege\". Note, if you want to use tools that mutate your tagged resources, you need to grant <code>AmazonMQFullAccess</code>. Finally, configure a AWS profile on the host that assumes the new role (for more information, check out the AWS CLI help page).</p>"},{"location":"servers/amazon-mq-mcp-server/#installation","title":"Installation","text":"<p>Configure the MCP server in your MCP client configuration (e.g., for Amazon Q Developer CLI, edit <code>~/.aws/amazonq/mcp.json</code>):</p> <pre><code>{\n  \"mcpServers\": {\n    \"awslabs.amazon-mq-mcp-server\": {\n      \"command\": \"uvx\",\n      \"args\": [\"awslabs.amazon-mq-mcp-server@latest\"],\n      \"env\": {\n        \"AWS_PROFILE\": \"your-aws-profile\",\n        \"AWS_REGION\": \"us-east-1\"\n      }\n    }\n  }\n}\n</code></pre> <p>If you would like to specify a flag (for example, to allow creation of resources), you can pass it to the args</p> <pre><code>{\n  \"mcpServers\": {\n    \"awslabs.amazon-mq-mcp-server\": {\n      \"command\": \"uvx\",\n      \"args\": [\"awslabs.amazon-mq-mcp-server@latest\", \"--allow-resource-creation\"],\n      \"env\": {\n        \"AWS_PROFILE\": \"your-aws-profile\",\n        \"AWS_REGION\": \"us-east-1\"\n      }\n    }\n  }\n}\n</code></pre> <p>or docker after a successful <code>docker build -t awslabs/amazon-mq-mcp-server .</code>:</p> <pre><code># fictitious `.env` file with AWS temporary credentials\nAWS_ACCESS_KEY_ID=&lt;from the profile you set up&gt;\nAWS_SECRET_ACCESS_KEY=&lt;from the profile you set up&gt;\nAWS_SESSION_TOKEN=&lt;from the profile you set up&gt;\n</code></pre> <pre><code>  {\n    \"mcpServers\": {\n      \"awslabs.amazon-mq-mcp-server\": {\n        \"command\": \"docker\",\n        \"args\": [\n          \"run\",\n          \"--rm\",\n          \"--interactive\",\n          \"--env-file\",\n          \"/full/path/to/file/above/.env\",\n          \"awslabs/amazon-mq-mcp-server:latest\"\n        ],\n        \"env\": {},\n        \"disabled\": false,\n        \"autoApprove\": []\n      }\n    }\n  }\n</code></pre>"},{"location":"servers/amazon-mq-mcp-server/#server-configuration-options","title":"Server Configuration Options","text":"<p>The Amazon MQ MCP Server supports several command-line arguments that can be used to configure its behavior:</p>"},{"location":"servers/amazon-mq-mcp-server/#-allow-resource-creation","title":"<code>--allow-resource-creation</code>","text":"<p>Allow tools that create resources in the user's AWS account. When this flag is enabled, the <code>create_broker</code> and <code>create_configuration</code> tools will be created for the MCP client, preventing the creation of new Amazon MQ resources. Default is False.</p> <p>This flag is particularly useful for: - Testing environments where resource creation should be restricted - Limiting the scope of actions available to the AI model</p> <p>Example: <pre><code>uv run awslabs.amazon-mq-mcp-server --allow-resource-creation\n</code></pre></p>"},{"location":"servers/amazon-mq-mcp-server/#security-features","title":"Security Features","text":"<p>The MCP server implements a security mechanism that only allows modification of resources that were created by the MCP server itself. This is achieved by:</p> <ol> <li>Automatically tagging all created resources with a <code>mcp_server_version</code> tag</li> <li>Validating this tag before allowing any mutative actions (update, delete, reboot)</li> <li>Rejecting operations on resources that don't have the appropriate tag</li> </ol>"},{"location":"servers/amazon-mq-mcp-server/#best-practices","title":"Best Practices","text":"<ul> <li>Use descriptive broker names to easily identify resources</li> <li>Follow the principle of least privilege when setting up IAM permissions</li> <li>Use separate AWS profiles for different environments (dev, test, prod)</li> <li>Monitor broker metrics and logs for performance and issues</li> <li>Implement proper error handling in your client applications</li> </ul>"},{"location":"servers/amazon-mq-mcp-server/#security-considerations","title":"Security Considerations","text":"<p>When using this MCP server, consider:</p> <ul> <li>The MCP server needs permissions to create and manage Amazon MQ resources</li> <li>Only resources created by the MCP server can be modified by it</li> <li>Ensure proper network security for your brokers (use <code>publicly_accessible: false</code> when possible)</li> <li>Implement strong authentication for broker users</li> <li>Review and rotate credentials regularly</li> </ul>"},{"location":"servers/amazon-mq-mcp-server/#troubleshooting","title":"Troubleshooting","text":"<ul> <li>If you encounter permission errors, verify your IAM user has the correct policies attached</li> <li>For connection issues, check network configurations and security groups</li> <li>If resource modification fails with a tag validation error, it means the resource was not created by the MCP server</li> <li>For general Amazon MQ issues, consult the Amazon MQ documentation</li> </ul>"},{"location":"servers/amazon-mq-mcp-server/#version","title":"Version","text":"<p>Current MCP server version: 1.0.0</p>"},{"location":"servers/amazon-neptune-mcp-server/","title":"Amazon neptune mcp server","text":"<pre><code>---\ntitle: Amazon Neptune MCP Server\n---\n\n# AWS Labs Amazon Neptune MCP Server\n\nAn Amazon Neptune MCP server that allows for fetching status, schema, and querying using openCypher and Gremlin for Neptune Database and openCypher for Neptune Analytics.\n\n## Features\n\nThe Amazon Neptune MCP Server provides the following capabilities:\n\n1. **Run Queries**: Execute openCypher and/or Gremlin queries against the configured database\n2. **Schema**: Get the schema in the configured graph as a text string\n3. **Status**: Find if the graph is \"Available\" or \"Unavailable\" to your server.  This is useful in helping to ensure that the graph is connected.\n\n### AWS Requirements\n\n1. **AWS CLI Configuration**: You must have the AWS CLI configured with credentials and an AWS_PROFILE that has access to Amazon Neptune\n2. **Amazon Neptune**: You must have at least one Amazon Neptune Database or Amazon Neptune Analytics graph.\n3. **IAM Permissions**: Your IAM role/user must have appropriate permissions to:\n   - Access Amazon Neptune\n   - Query Amazon Neptune\n4. **Access**: The location where you are running the server must have access to the Amazon Neptune instance.  Neptune Database resides in a private VPC so access into the private VPC.  Neptune Analytics can be access either using a public endpoint, if configured, or the access will be needed to the private endpoint.\n\nNote: This server will run any query sent to it, which could include both mutating and read-only actions.  Properly configuring the permissions of the role to allow/disallow specific data plane actions as specified here:\n* [Neptune Database](https://docs.aws.amazon.com/neptune/latest/userguide/security.html)\n* [Neptune Analytics](https://docs.aws.amazon.com/neptune-analytics/latest/userguide/security.html)\n\n\n## Prerequisites\n\n1. Install `uv` from [Astral](https://docs.astral.sh/uv/getting-started/installation/) or the [GitHub README](https://github.com/astral-sh/uv#installation)\n2. Install Python using `uv python install 3.10`\n\n## Installation\n\nBelow is an example of how to configure your MCP client, although different clients may require a different format.\n\n\n```json\n{\n  \"mcpServers\": {\n    \"Neptune Query\": {\n      \"command\": \"uvx\",\n      \"args\": [\"awslabs.amazon-neptune-mcp-server@latest\"],\n      \"env\": {\n        \"FASTMCP_LOG_LEVEL\": \"INFO\",\n        \"NEPTUNE_ENDPOINT\": \"&lt;INSERT NEPTUNE ENDPOINT IN FORMAT SPECIFIED BELOW&gt;\"\n      }\n    }\n  }\n}\n\n```\n### Docker Configuration\nAfter building with `docker build -t awslabs/amazon-neptune-mcp-server .`:\n\n```\n{\n  \"mcpServers\": {\n    \"awslabs.amazon-neptune-mcp-server\": {\n        \"command\": \"docker\",\n        \"args\": [\n          \"run\",\n          \"--rm\",\n          \"-i\",\n          \"awslabs/amazon-neptune-mcp-server\"\n        ],\n        \"env\": {\n        \"FASTMCP_LOG_LEVEL\": \"INFO\",\n        \"NEPTUNE_ENDPOINT\": \"&lt;INSERT NEPTUNE ENDPOINT IN FORMAT SPECIFIED BELOW&gt;\"\n        },\n        \"disabled\": false,\n        \"autoApprove\": []\n    }\n  }\n}\n```\n\nWhen specifying the Neptune Endpoint the following formats are expected:\n\nFor Neptune Database:\n`neptune-db://&lt;Cluster Endpoint&gt;`\n\nFor Neptune Analytics:\n`neptune-graph://&lt;graph identifier&gt;`\n</code></pre>"},{"location":"servers/amazon-sns-sqs-mcp-server/","title":"Amazon SNS / SQS MCP Server","text":"<p>A Model Context Protocol (MCP) server for Amazon SNS / SQS that enables generative AI models to manage SNS Topics and SQS Queues through MCP tools.</p>"},{"location":"servers/amazon-sns-sqs-mcp-server/#features","title":"Features","text":"<p>This MCP server acts as a bridge between MCP clients and Amazon SNS / SQS, allowing generative AI models to create, configure, and manage Topics / Queues. The server provides a secure way to interact with Amazon SNS / SQS resources while maintaining proper access controls and resource tagging.</p> <pre><code>graph LR\n    A[Model] &lt;--&gt; B[MCP Client]\n    B &lt;--&gt; C[\"Amazon SNS / SQS MCP Server\"]\n    C &lt;--&gt; D[Amazon SNS / SQS Service]\n    style A fill:#f9f,stroke:#333,stroke-width:2px\n    style B fill:#bbf,stroke:#333,stroke-width:2px\n    style C fill:#bfb,stroke:#333,stroke-width:4px\n    style D fill:#fbb,stroke:#333,stroke-width:2px</code></pre> <p>From a security perspective, this server implements resource tagging to ensure that only resources created through the MCP server can be modified by it. This prevents unauthorized modifications to existing Amazon SNS/SQS resources that were not created by the MCP server.</p>"},{"location":"servers/amazon-sns-sqs-mcp-server/#key-capabilities","title":"Key Capabilities","text":"<p>This MCP server provides tools to: - Create, list, and manage Amazon SNS topics - Create, list, and manage Amazon SNS subscriptions - Create, list, and manage Amazon SQS queues - Send and receive messages using SNS and SQS</p>"},{"location":"servers/amazon-sns-sqs-mcp-server/#prerequisites","title":"Prerequisites","text":"<ol> <li>Install <code>uv</code> from Astral or the GitHub README</li> <li>Install Python using <code>uv python install 3.10</code></li> <li>AWS account with permissions to create and manage Amazon SNS / SQS resources</li> </ol>"},{"location":"servers/amazon-sns-sqs-mcp-server/#setup","title":"Setup","text":""},{"location":"servers/amazon-sns-sqs-mcp-server/#iam-configuration","title":"IAM Configuration","text":"<p>The authorization between the MCP server and your AWS accounts are performed with AWS profile you setup on the host. There are several ways to setup a AWS profile, however we recommend creating a new IAM role that has <code>AmazonSQSReadOnlyAccess</code> and <code>AmazonSNSReadOnlyAccess</code> permission following the principle of \"least privilege\". Note, if you want to use tools that mutate your tagged resources, you need to grant <code>AmazonSNSFullAccess</code> and <code>AmazonSQSFullAccess</code>. Finally, configure a AWS profile on the host that assumes the new role (for more information, check out the AWS CLI help page).</p>"},{"location":"servers/amazon-sns-sqs-mcp-server/#installation","title":"Installation","text":"<p>Configure the MCP server in your MCP client configuration (e.g., for Amazon Q Developer CLI, edit <code>~/.aws/amazonq/mcp.json</code>):</p> <pre><code>{\n  \"mcpServers\": {\n    \"awslabs.amazon-sns-sqs-mcp-server\": {\n      \"command\": \"uvx\",\n      \"args\": [\"awslabs.amazon-sns-sqs-mcp-server@latest\"],\n      \"env\": {\n        \"AWS_PROFILE\": \"your-aws-profile\",\n        \"AWS_REGION\": \"us-east-1\"\n      }\n    }\n  }\n}\n</code></pre> <p>or docker after a successful <code>docker build -t awslabs/amazon-sns-sqs-mcp-server.</code>:</p> <pre><code># fictitious `.env` file with AWS temporary credentials\nAWS_ACCESS_KEY_ID=&lt;from the profile you set up&gt;\nAWS_SECRET_ACCESS_KEY=&lt;from the profile you set up&gt;\nAWS_SESSION_TOKEN=&lt;from the profile you set up&gt;\n</code></pre> <pre><code>  {\n    \"mcpServers\": {\n      \"awslabs.sns-sqs-mcp-server\": {\n        \"command\": \"docker\",\n        \"args\": [\n          \"run\",\n          \"--rm\",\n          \"--interactive\",\n          \"--env-file\",\n          \"/full/path/to/file/above/.env\",\n          \"awslabs/amazon-sns-sqs-mcp-server:latest\"\n        ],\n        \"env\": {},\n        \"disabled\": false,\n        \"autoApprove\": []\n      }\n    }\n  }\n</code></pre>"},{"location":"servers/amazon-sns-sqs-mcp-server/#server-configuration-options","title":"Server Configuration Options","text":"<p>The Amazon SNS / SQS MCP Server supports several command-line arguments that can be used to configure its behavior:</p>"},{"location":"servers/amazon-sns-sqs-mcp-server/#-allow-resource-creation","title":"<code>--allow-resource-creation</code>","text":"<p>Enables tools that create resources in the user's AWS account. When this flag is not enabled, the create new resources tools will be hidden from the MCP client, preventing the creation of new Amazon SNS / SQS resources. It also currently prevents deletion of any topics / queues. Default is False.</p> <p>This flag is particularly useful for: - Testing environments where resource creation should be restricted - Limiting the scope of actions available to the AI model</p> <p>Example: <pre><code>uv run awslabs.amazon-sns-sqs-mcp-server --disallow-resource-creation\n</code></pre></p>"},{"location":"servers/amazon-sns-sqs-mcp-server/#security-features","title":"Security Features","text":"<p>The MCP server implements a security mechanism that only allows modification of resources that were created by the MCP server itself. This is achieved by:</p> <ol> <li>Automatically tagging all created resources with a <code>mcp_server_version</code> tag</li> <li>Validating this tag before allowing any mutative actions (update, delete) - this is a deterministic check that ensures only resources created by the MCP server can be modified</li> <li>Rejecting operations on resources that don't have the appropriate tag</li> <li>Application-to-Person (A2P) messaging mutative operations are not enabled by default for security reasons</li> </ol>"},{"location":"servers/amazon-sns-sqs-mcp-server/#best-practices","title":"Best Practices","text":"<ul> <li>Use descriptive topic and queue names to easily identify resources</li> <li>Follow the principle of least privilege when setting up IAM permissions</li> <li>Use separate AWS profiles for different environments (dev, test, prod)</li> <li>Implement proper error handling in your client applications</li> </ul>"},{"location":"servers/amazon-sns-sqs-mcp-server/#security-considerations","title":"Security Considerations","text":"<p>When using this MCP server, consider:</p> <ul> <li>The MCP server needs permissions to create and manage Amazon SNS / SQS resources</li> <li>Only resources created by the MCP server can be modified by it since they are tagged</li> <li>Resource creation is disabled by default, enable it by setting the <code>--allow-resource-creation</code> flag on</li> </ul>"},{"location":"servers/amazon-sns-sqs-mcp-server/#troubleshooting","title":"Troubleshooting","text":"<ul> <li>If you encounter permission errors, verify your IAM user has the correct policies attached</li> <li>For connection issues, check network configurations and security groups</li> <li>If resource modification fails with a tag validation error, it means the resource was not created by the MCP server</li> <li>For general Amazon SNS / SQS issues, consult the Amazon SNS documentation , Amazon SQS documentation</li> </ul>"},{"location":"servers/amazon-sns-sqs-mcp-server/#version","title":"Version","text":"<p>Current MCP server version: 1.0.0</p>"},{"location":"servers/aurora-dsql-mcp-server/","title":"Aurora dsql mcp server","text":"<pre><code>---\ntitle: Amazon Aurora DSQL MCP Server\n---\n\n# AWS Labs Aurora DSQL MCP Server\n\nAn AWS Labs Model Context Protocol (MCP) server for Aurora DSQL\n\n## Features\n\n- Converting human-readable questions and commands into structured Postgres-compatible SQL queries and executing them against the configured Aurora DSQL database.\n- Read-only by default, transactions enabled with `--allow-writes`\n- Connection reuse between requests for improved performance\n\n## Prerequisites\n\n1. An AWS account with an [Aurora DSQL Cluster](https://docs.aws.amazon.com/aurora-dsql/latest/userguide/getting-started.html)\n1. This MCP server can only be run locally on the same host as your LLM client.\n1. Set up AWS credentials with access to AWS services\n   - You need an AWS account with appropriate permissions\n   - Configure AWS credentials with `aws configure` or environment variables\n\n## Installation\n\n### Using `uv`\n\n1. Install `uv` from [Astral](https://docs.astral.sh/uv/getting-started/installation/) or the [GitHub README](https://github.com/astral-sh/uv#installation)\n2. Install Python using `uv python install 3.10`\n\nConfigure the MCP server in your MCP client configuration (e.g., for Amazon Q Developer CLI, edit `~/.aws/amazonq/mcp.json`):\n\n```json\n{\n  \"mcpServers\": {\n    \"awslabs.aurora-dsql-mcp-server\": {\n      \"command\": \"uvx\",\n      \"args\": [\n        \"awslabs.aurora-dsql-mcp-server@latest\",\n        \"--cluster_endpoint\",\n        \"[your dsql cluster endpoint]\",\n        \"--region\",\n        \"[your dsql cluster region, e.g. us-east-1]\",\n        \"--database_user\",\n        \"[your dsql username]\",\n        \"--profile\", \"default\"\n      ],\n      \"env\": {\n        \"FASTMCP_LOG_LEVEL\": \"ERROR\"\n      },\n      \"disabled\": false,\n      \"autoApprove\": []\n    }\n  }\n}\n```\n\n### Using Docker\n\n1. 'git clone https://github.com/awslabs/mcp.git'\n2. Go to sub-directory 'src/aurora-dsql-mcp-server/'\n3. Run 'docker build -t awslabs/aurora-dsql-mcp-server:latest .'\n4. Create a env file with tempoary credentials:\n\nEither manually:\n```file\n# fictitious `.env` file with AWS temporary credentials\nAWS_ACCESS_KEY_ID=&lt;from the profile you set up&gt;\nAWS_SECRET_ACCESS_KEY=&lt;from the profile you set up&gt;\nAWS_SESSION_TOKEN=&lt;from the profile you set up&gt;\n```\n\nOr using `aws configure`:\n\n```bash\naws configure export-credentials --profile your-profile-name --format env &gt; temp_aws_credentials.env | sed 's/^export //' &gt; temp_aws_credentials.env\n```\n\n```json\n{\n  \"mcpServers\": {\n    \"awslabs.aurora-dsql-mcp-server\": {\n      \"command\": \"docker\",\n      \"args\": [\n        \"run\",\n        \"-i\",\n        \"--rm\",\n        \"--env-file\",\n        \"/full/path/to/file/above/.env\",\n        \"awslabs/aurora-dsql-mcp-server:latest\",\n        \"--cluster_endpoint\", \"[your data]\",\n        \"--database_user\", \"[your data]\",\n        \"--region\", \"[your data]\"\n      ]\n    }\n  }\n}\n```\n\n## Server Configuration options\n\n### `--allow-writes`\n\nBy default, the dsql mcp server does not allow write operations. Any invocations of transact tool will fail in this mode. To use transact tool, allow writes by passing `--allow-writes` parameter.\n\n### `--cluster_endpoint`\n\nThis is mandatory parameter to specify the cluster to connect to. This should be the full endpoint of your cluster, e.g., `01abc2ldefg3hijklmnopqurstu.dsql.us-east-1.on.aws`\n\n### `--database_user`\n\nThis is a mandatory parameter to specify the user to connect as. For example\n`admin`, or `my_user`. Note that the AWS credentials you are using must have\npermission to login as that user. For more information on setting up and using\ndatabase roles in DSQL, see [Using database roles with IAM roles](https://docs.aws.amazon.com/aurora-dsql/latest/userguide/using-database-and-iam-roles.html).\n\n### `--profile`\n\nYou can specify the aws profile to use for your credentials. Note that this is\nnot supported for docker installation.\n\nUsing the `AWS_PROFILE` environment variable in your MCP configuration is also\nsupported:\n\n```json\n\"env\": {\n  \"AWS_PROFILE\": \"your-aws-profile\"\n}\n```\n\nIf neither is provided, the MCP server defaults to using the \"default\" profile in your AWS configuration file.\n\n### `--region`\n\nThis is a mandatory parameter to specify the region of your DSQL database.\n</code></pre>"},{"location":"servers/aws-bedrock-data-automation-mcp-server/","title":"AWS Bedrock Data Automation MCP Server","text":"<p>A Model Context Protocol (MCP) server for Amazon Bedrock Data Automation that enables AI assistants to analyze documents, images, videos, and audio files using Amazon Bedrock Data Automation projects.</p>"},{"location":"servers/aws-bedrock-data-automation-mcp-server/#features","title":"Features","text":"<ul> <li>Project Management: List and get details about Bedrock Data Automation projects</li> <li>Asset Analysis: Extract insights from unstructured content using Bedrock Data Automation</li> <li>Support for Multiple Content Types: Process documents, images, videos, and audio files</li> <li>Integration with Amazon S3: Seamlessly upload and download assets and results</li> </ul>"},{"location":"servers/aws-bedrock-data-automation-mcp-server/#prerequisites","title":"Prerequisites","text":"<ol> <li>Install <code>uv</code> from Astral or the GitHub README</li> <li>Install Python using <code>uv python install 3.10</code></li> <li>Set up AWS credentials with access to Amazon Bedrock Data Automation</li> <li>You need an AWS account with Amazon Bedrock Data Automation enabled</li> <li>Configure AWS credentials with <code>aws configure</code> or environment variables</li> <li>Ensure your IAM role/user has permissions to use Amazon Bedrock Data Automation</li> <li>Create an AWS S3 Bucket</li> <li>Example AWS CLI command to create the bucket</li> <li><code>bash       aws s3 create-bucket &lt;bucket-name&gt;</code></li> </ol>"},{"location":"servers/aws-bedrock-data-automation-mcp-server/#installation","title":"Installation","text":"<p>Configure the MCP server in your MCP client configuration (e.g., for Amazon Q Developer CLI, edit <code>~/.aws/amazonq/mcp.json</code>):</p> <pre><code>{\n  \"mcpServers\": {\n    \"awslabs.aws-bedrock-data-automation-mcp-server\": {\n      \"command\": \"uvx\",\n      \"args\": [\"awslabs.aws-bedrock-data-automation-mcp-server@latest\"],\n      \"env\": {\n        \"AWS_PROFILE\": \"your-aws-profile\",\n        \"AWS_REGION\": \"us-east-1\",\n        \"AWS_BUCKET_NAME\": \"your-s3-bucket-name\",\n        \"BASE_DIR\": \"/path/to/base/directory\",\n        \"FASTMCP_LOG_LEVEL\": \"ERROR\"\n      },\n      \"disabled\": false,\n      \"autoApprove\": []\n    }\n  }\n}\n</code></pre> <p>or docker after a successful <code>docker build -t awslabs/aws-bedrock-data-automation-mcp-server .</code>:</p> <pre><code>{\n  \"mcpServers\": {\n    \"awslabs.aws-bedrock-data-automation-mcp-server\": {\n      \"command\": \"docker\",\n      \"args\": [\n        \"run\",\n        \"--rm\",\n        \"--interactive\",\n        \"--env\",\n        \"AWS_PROFILE\",\n        \"--env\",\n        \"AWS_REGION\",\n        \"--env\",\n        \"AWS_BUCKET_NAME\",\n        \"--env\",\n        \"BASE_DIR\",\n        \"--env\",\n        \"FASTMCP_LOG_LEVEL\",\n        \"awslabs/aws-bedrock-data-automation-mcp-server:latest\"\n      ],\n      \"env\": {\n        \"AWS_PROFILE\": \"your-aws-profile\",\n        \"AWS_REGION\": \"us-east-1\",\n        \"AWS_BUCKET_NAME\": \"your-s3-bucket-name\",\n        \"BASE_DIR\": \"/path/to/base/directory\",\n        \"FASTMCP_LOG_LEVEL\": \"ERROR\"\n      },\n      \"disabled\": false,\n      \"autoApprove\": []\n    }\n  }\n}\n</code></pre>"},{"location":"servers/aws-bedrock-data-automation-mcp-server/#environment-variables","title":"Environment Variables","text":"<ul> <li><code>AWS_PROFILE</code>: AWS CLI profile to use for credentials</li> <li><code>AWS_REGION</code>: AWS region to use (default: us-east-1)</li> <li><code>AWS_BUCKET_NAME</code>: S3 bucket name for storing assets and results</li> <li><code>BASE_DIR</code>: Base directory for file operations (optional)</li> <li><code>FASTMCP_LOG_LEVEL</code>: Logging level (ERROR, WARNING, INFO, DEBUG)</li> </ul>"},{"location":"servers/aws-bedrock-data-automation-mcp-server/#aws-authentication","title":"AWS Authentication","text":"<p>The server uses the AWS profile specified in the <code>AWS_PROFILE</code> environment variable. If not provided, it defaults to the default credential provider chain.</p> <pre><code>\"env\": {\n  \"AWS_PROFILE\": \"your-aws-profile\",\n  \"AWS_REGION\": \"us-east-1\"\n}\n</code></pre> <p>Make sure the AWS profile has permissions to access Amazon Bedrock Data Automation services. The MCP server creates a boto3 session using the specified profile to authenticate with AWS services. Amazon Bedrock Data Automation services is currently available in the following regions: us-east-1 and us-west-2.</p>"},{"location":"servers/aws-bedrock-data-automation-mcp-server/#tools","title":"Tools","text":""},{"location":"servers/aws-bedrock-data-automation-mcp-server/#getprojects","title":"getprojects","text":"<p>Get a list of data automation projects.</p> <pre><code>getprojects() -&gt; list\n</code></pre> <p>Returns a list of available Bedrock Data Automation projects.</p>"},{"location":"servers/aws-bedrock-data-automation-mcp-server/#getprojectdetails","title":"getprojectdetails","text":"<p>Get details of a specific data automation project.</p> <pre><code>getprojectdetails(projectArn: str) -&gt; dict\n</code></pre> <p>Returns detailed information about a specific Bedrock Data Automation project.</p>"},{"location":"servers/aws-bedrock-data-automation-mcp-server/#analyzeasset","title":"analyzeasset","text":"<p>Analyze an asset using a data automation project.</p> <pre><code>analyzeasset(assetPath: str, projectArn: Optional[str] = None) -&gt; dict\n</code></pre> <p>Extracts insights from unstructured content (documents, images, videos, audio) using Amazon Bedrock Data Automation.</p> <ul> <li><code>assetPath</code>: Path to the asset file to analyze</li> <li><code>projectArn</code>: ARN of the Bedrock Data Automation project to use (optional, uses default public project if not provided)</li> </ul>"},{"location":"servers/aws-bedrock-data-automation-mcp-server/#example-usage","title":"Example Usage","text":"<pre><code># List available projects\nprojects = await getprojects()\n\n# Get details of a specific project\nproject_details = await getprojectdetails(projectArn=\"arn:aws:bedrock:us-east-1:123456789012:data-automation-project/my-project\")\n\n# Analyze a document\nresults = await analyzeasset(assetPath=\"/path/to/document.pdf\")\n\n# Analyze an image with a specific project\nresults = await analyzeasset(\n    assetPath=\"/path/to/image.jpg\",\n    projectArn=\"arn:aws:bedrock:us-east-1:123456789012:data-automation-project/my-project\"\n)\n</code></pre>"},{"location":"servers/aws-bedrock-data-automation-mcp-server/#security-considerations","title":"Security Considerations","text":"<ul> <li>Use AWS IAM roles with appropriate permissions</li> <li>Store credentials securely</li> <li>Use temporary credentials when possible</li> <li>Ensure S3 bucket permissions are properly configured</li> </ul>"},{"location":"servers/aws-bedrock-data-automation-mcp-server/#license","title":"License","text":"<p>This project is licensed under the Apache License, Version 2.0. See the LICENSE file for details.</p>"},{"location":"servers/aws-diagram-mcp-server/","title":"AWS Diagram MCP Server","text":"<p>Model Context Protocol (MCP) server for AWS Diagrams</p> <p>This MCP server that seamlessly creates diagrams using the Python diagrams package DSL. This server allows you to generate AWS diagrams, sequence diagrams, flow diagrams, and class diagrams using Python code.</p> <p></p>"},{"location":"servers/aws-diagram-mcp-server/#prerequisites","title":"Prerequisites","text":"<ol> <li>Install <code>uv</code> from Astral or the GitHub README</li> <li>Install Python using <code>uv python install 3.10</code></li> <li>Install GraphViz https://www.graphviz.org/</li> </ol>"},{"location":"servers/aws-diagram-mcp-server/#installation","title":"Installation","text":"<p>Configure the MCP server in your MCP client configuration (e.g., for Amazon Q Developer CLI, edit <code>~/.aws/amazonq/mcp.json</code>):</p> <pre><code>{\n  \"mcpServers\": {\n    \"awslabs.aws-diagram-mcp-server\": {\n      \"command\": \"uvx\",\n      \"args\": [\"awslabs.aws-diagram-mcp-server\"],\n      \"env\": {\n        \"FASTMCP_LOG_LEVEL\": \"ERROR\"\n      },\n      \"autoApprove\": [],\n      \"disabled\": false\n    }\n  }\n}\n</code></pre> <p>or docker after a successful <code>docker build -t awslabs/aws-diagram-mcp-server .</code>:</p> <pre><code>  {\n    \"mcpServers\": {\n      \"awslabs.aws-diagram-mcp-server\": {\n        \"command\": \"docker\",\n        \"args\": [\n          \"run\",\n          \"--rm\",\n          \"--interactive\",\n          \"--env\",\n          \"FASTMCP_LOG_LEVEL=ERROR\",\n          \"awslabs/aws-diagram-mcp-server:latest\"\n        ],\n        \"env\": {},\n        \"disabled\": false,\n        \"autoApprove\": []\n      }\n    }\n  }\n</code></pre>"},{"location":"servers/aws-diagram-mcp-server/#features","title":"Features","text":"<p>The Diagrams MCP Server provides the following capabilities:</p> <ol> <li>Generate Diagrams: Create professional diagrams using Python code</li> <li>Multiple Diagram Types: Support for AWS architecture, sequence diagrams, flow charts, class diagrams, and more</li> <li>Customization: Customize diagram appearance, layout, and styling</li> <li>Security: Code scanning to ensure secure diagram generation</li> </ol>"},{"location":"servers/aws-diagram-mcp-server/#quick-example","title":"Quick Example","text":"<pre><code>from diagrams import Diagram\nfrom diagrams.aws.compute import Lambda\nfrom diagrams.aws.database import Dynamodb\nfrom diagrams.aws.network import APIGateway\n\nwith Diagram(\"Serverless Application\", show=False):\n    api = APIGateway(\"API Gateway\")\n    function = Lambda(\"Function\")\n    database = Dynamodb(\"DynamoDB\")\n\n    api &gt;&gt; function &gt;&gt; database\n</code></pre>"},{"location":"servers/aws-diagram-mcp-server/#development","title":"Development","text":""},{"location":"servers/aws-diagram-mcp-server/#testing","title":"Testing","text":"<p>The project includes a comprehensive test suite to ensure the functionality of the MCP server. The tests are organized by module and cover all aspects of the server's functionality.</p> <p>To run the tests, use the provided script:</p> <pre><code>./run_tests.sh\n</code></pre> <p>This script will automatically install pytest and its dependencies if they're not already installed.</p> <p>Or run pytest directly (if you have pytest installed):</p> <pre><code>pytest -xvs tests/\n</code></pre> <p>To run with coverage:</p> <pre><code>pytest --cov=awslabs.aws_diagram_mcp_server --cov-report=term-missing tests/\n</code></pre> <p>For more information about the tests, see the tests README.</p>"},{"location":"servers/aws-diagram-mcp-server/#development-dependencies","title":"Development Dependencies","text":"<p>To set up the development environment, install the development dependencies:</p> <pre><code>uv pip install -e \".[dev]\"\n</code></pre> <p>This will install the required dependencies for development, including pytest, pytest-asyncio, and pytest-cov.</p>"},{"location":"servers/aws-documentation-mcp-server/","title":"AWS Documentation MCP Server","text":"<p>Model Context Protocol (MCP) server for AWS Documentation</p> <p>This MCP server provides tools to access AWS documentation, search for content, and get recommendations.</p>"},{"location":"servers/aws-documentation-mcp-server/#features","title":"Features","text":"<ul> <li>Read Documentation: Fetch and convert AWS documentation pages to markdown format</li> <li>Search Documentation: Search AWS documentation using the official search API (global only)</li> <li>Recommendations: Get content recommendations for AWS documentation pages (global only)</li> <li>Get Available Services List: Get a list of available AWS services in China regions (China only)</li> </ul>"},{"location":"servers/aws-documentation-mcp-server/#prerequisites","title":"Prerequisites","text":""},{"location":"servers/aws-documentation-mcp-server/#installation-requirements","title":"Installation Requirements","text":"<ol> <li>Install <code>uv</code> from Astral or the GitHub README</li> <li>Install Python 3.10 or newer using <code>uv python install 3.10</code> (or a more recent version)</li> </ol>"},{"location":"servers/aws-documentation-mcp-server/#installation","title":"Installation","text":"<p>Configure the MCP server in your MCP client configuration (e.g., for Amazon Q Developer CLI, edit <code>~/.aws/amazonq/mcp.json</code>):</p> <pre><code>{\n  \"mcpServers\": {\n    \"awslabs.aws-documentation-mcp-server\": {\n      \"command\": \"uvx\",\n      \"args\": [\"awslabs.aws-documentation-mcp-server@latest\"],\n      \"env\": {\n        \"FASTMCP_LOG_LEVEL\": \"ERROR\",\n        \"AWS_DOCUMENTATION_PARTITION\": \"aws\"\n      },\n      \"disabled\": false,\n      \"autoApprove\": []\n    }\n  }\n}\n</code></pre> <p>Note: Set <code>AWS_DOCUMENTATION_PARTITION</code> to <code>aws-cn</code> to query AWS China documentation instead of global AWS documentation.</p> <p>or docker after a successful <code>docker build -t awslabs/aws-documentation-mcp-server .</code>:</p> <pre><code>{\n  \"mcpServers\": {\n    \"awslabs.aws-documentation-mcp-server\": {\n      \"command\": \"docker\",\n      \"args\": [\n        \"run\",\n        \"--rm\",\n        \"--interactive\",\n        \"--env\",\n        \"FASTMCP_LOG_LEVEL=ERROR\",\n        \"--env\",\n        \"AWS_DOCUMENTATION_PARTITION=aws\",\n        \"awslabs/aws-documentation-mcp-server:latest\"\n      ],\n      \"env\": {},\n      \"disabled\": false,\n      \"autoApprove\": []\n    }\n  }\n}\n</code></pre>"},{"location":"servers/aws-documentation-mcp-server/#basic-usage","title":"Basic Usage","text":"<p>Example:</p> <ul> <li>\"look up documentation on S3 bucket naming rule. cite your sources\"</li> <li>\"recommend content for page https://docs.aws.amazon.com/AmazonS3/latest/userguide/bucketnamingrules.html\"</li> </ul> <p></p>"},{"location":"servers/aws-documentation-mcp-server/#tools","title":"Tools","text":""},{"location":"servers/aws-documentation-mcp-server/#read_documentation","title":"read_documentation","text":"<p>Fetches an AWS documentation page and converts it to markdown format.</p> <pre><code>read_documentation(url: str) -&gt; str\n</code></pre>"},{"location":"servers/aws-documentation-mcp-server/#search_documentation-global-only","title":"search_documentation (global only)","text":"<p>Searches AWS documentation using the official AWS Documentation Search API.</p> <pre><code>search_documentation(search_phrase: str, limit: int) -&gt; list[dict]\n</code></pre>"},{"location":"servers/aws-documentation-mcp-server/#recommend-global-only","title":"recommend (global only)","text":"<p>Gets content recommendations for an AWS documentation page.</p> <pre><code>recommend(url: str) -&gt; list[dict]\n</code></pre>"},{"location":"servers/aws-documentation-mcp-server/#get_available_services-china-only","title":"get_available_services (China only)","text":"<p>Gets a list of available AWS services in China regions.</p> <pre><code>get_available_services() -&gt; str\n</code></pre>"},{"location":"servers/aws-location-mcp-server/","title":"Amazon Location Service MCP Server","text":"<p>Model Context Protocol (MCP) server for Amazon Location Service</p> <p>This MCP server provides tools to access Amazon Location Service capabilities, focusing on place search and geographical coordinates.</p>"},{"location":"servers/aws-location-mcp-server/#features","title":"Features","text":"<ul> <li>Search for Places: Search for places using geocoding</li> <li>Get Place Details: Get details for specific places by PlaceId</li> <li>Reverse Geocode: Convert coordinates to addresses</li> <li>Search Nearby: Search for places near a specified location</li> <li>Open Now Search: Search for places that are currently open</li> <li>Route Calculation: Calculate routes between locations using Amazon Location Service</li> <li>Optimize Waypoints: Optimize the order of waypoints for a route using Amazon Location Service</li> </ul>"},{"location":"servers/aws-location-mcp-server/#prerequisites","title":"Prerequisites","text":""},{"location":"servers/aws-location-mcp-server/#requirements","title":"Requirements","text":"<ol> <li>Have an AWS account with Amazon Location Service enabled</li> <li>Install <code>uv</code> from Astral or the GitHub README</li> <li>Install Python 3.10 or newer using <code>uv python install 3.10</code> (or a more recent version)</li> </ol>"},{"location":"servers/aws-location-mcp-server/#installation","title":"Installation","text":"<p>Here are the ways you can work with the Amazon Location MCP server:</p>"},{"location":"servers/aws-location-mcp-server/#configuration","title":"Configuration","text":"<p>Configure the server in your MCP configuration file. Here are some ways you can work with MCP across AWS, and we'll be adding support to more products soon: (e.g. for Amazon Q Developer CLI MCP, <code>~/.aws/amazonq/mcp.json</code>):</p> <pre><code>{\n  \"mcpServers\": {\n    \"awslabs.aws-location-mcp-server\": {\n        \"command\": \"uvx\",\n        \"args\": [\"awslabs.aws-location-mcp-server@latest\"],\n        \"env\": {\n          \"AWS_PROFILE\": \"your-aws-profile\",\n          \"AWS_REGION\": \"us-east-1\",\n          \"FASTMCP_LOG_LEVEL\": \"ERROR\"\n        },\n        \"disabled\": false,\n        \"autoApprove\": []\n    }\n  }\n}\n</code></pre>"},{"location":"servers/aws-location-mcp-server/#using-temporary-credentials","title":"Using Temporary Credentials","text":"<p>For temporary credentials (such as those from AWS STS, IAM roles, or federation):</p> <pre><code>{\n  \"mcpServers\": {\n    \"awslabs.aws-location-mcp-server\": {\n        \"command\": \"uvx\",\n        \"args\": [\"awslabs.aws-location-mcp-server@latest\"],\n        \"env\": {\n          \"AWS_ACCESS_KEY_ID\": \"your-temporary-access-key\",\n          \"AWS_SECRET_ACCESS_KEY\": \"your-temporary-secret-key\",\n          \"AWS_SESSION_TOKEN\": \"your-session-token\",\n          \"AWS_REGION\": \"us-east-1\",\n          \"FASTMCP_LOG_LEVEL\": \"ERROR\"\n        },\n        \"disabled\": false,\n        \"autoApprove\": []\n    }\n  }\n}\n</code></pre>"},{"location":"servers/aws-location-mcp-server/#docker-configuration","title":"Docker Configuration","text":"<p>After building with <code>docker build -t awslabs/aws-location-mcp-server .</code>:</p> <pre><code>{\n  \"mcpServers\": {\n    \"awslabs.aws-location-mcp-server\": {\n        \"command\": \"docker\",\n        \"args\": [\n          \"run\",\n          \"--rm\",\n          \"-i\",\n          \"awslabs/aws-location-mcp-server\"\n        ],\n        \"env\": {\n          \"AWS_PROFILE\": \"your-aws-profile\",\n          \"AWS_REGION\": \"us-east-1\"\n        },\n        \"disabled\": false,\n        \"autoApprove\": []\n    }\n  }\n}\n</code></pre>"},{"location":"servers/aws-location-mcp-server/#docker-with-temporary-credentials","title":"Docker with Temporary Credentials","text":"<pre><code>{\n  \"mcpServers\": {\n    \"awslabs.aws-location-mcp-server\": {\n        \"command\": \"docker\",\n        \"args\": [\n          \"run\",\n          \"--rm\",\n          \"-i\",\n          \"awslabs/aws-location-mcp-server\"\n        ],\n        \"env\": {\n          \"AWS_ACCESS_KEY_ID\": \"your-temporary-access-key\",\n          \"AWS_SECRET_ACCESS_KEY\": \"your-temporary-secret-key\",\n          \"AWS_SESSION_TOKEN\": \"your-session-token\",\n          \"AWS_REGION\": \"us-east-1\"\n        },\n        \"disabled\": false,\n        \"autoApprove\": []\n    }\n  }\n}\n</code></pre>"},{"location":"servers/aws-location-mcp-server/#environment-variables","title":"Environment Variables","text":"<ul> <li><code>AWS_PROFILE</code>: AWS CLI profile to use for credentials</li> <li><code>AWS_REGION</code>: AWS region to use (default: us-east-1)</li> <li><code>AWS_ACCESS_KEY_ID</code> and <code>AWS_SECRET_ACCESS_KEY</code>: Explicit AWS credentials (alternative to AWS_PROFILE)</li> <li><code>AWS_SESSION_TOKEN</code>: Session token for temporary credentials (used with AWS_ACCESS_KEY_ID and AWS_SECRET_ACCESS_KEY)</li> <li><code>FASTMCP_LOG_LEVEL</code>: Logging level (ERROR, WARNING, INFO, DEBUG)</li> </ul>"},{"location":"servers/aws-location-mcp-server/#tools","title":"Tools","text":"<p>The server exposes the following tools through the MCP interface:</p>"},{"location":"servers/aws-location-mcp-server/#search_places","title":"search_places","text":"<p>Search for places using Amazon Location Service geocoding capabilities.</p> <pre><code>search_places(query: str, max_results: int = 5, mode: str = 'summary') -&gt; dict\n</code></pre>"},{"location":"servers/aws-location-mcp-server/#get_place","title":"get_place","text":"<p>Get details for a specific place using its unique place ID.</p> <pre><code>get_place(place_id: str, mode: str = 'summary') -&gt; dict\n</code></pre>"},{"location":"servers/aws-location-mcp-server/#reverse_geocode","title":"reverse_geocode","text":"<p>Convert coordinates to an address using reverse geocoding.</p> <pre><code>reverse_geocode(longitude: float, latitude: float) -&gt; dict\n</code></pre>"},{"location":"servers/aws-location-mcp-server/#search_nearby","title":"search_nearby","text":"<p>Search for places near a specific location with optional radius expansion.</p> <pre><code>search_nearby(longitude: float, latitude: float, radius: int = 500, max_results: int = 5,\n              query: str = None, max_radius: int = 10000, expansion_factor: float = 2.0,\n              mode: str = 'summary') -&gt; dict\n</code></pre>"},{"location":"servers/aws-location-mcp-server/#search_places_open_now","title":"search_places_open_now","text":"<p>Search for places that are currently open, with radius expansion if needed.</p> <pre><code>search_places_open_now(query: str, max_results: int = 5, initial_radius: int = 500,\n                       max_radius: int = 50000, expansion_factor: float = 2.0) -&gt; dict\n</code></pre>"},{"location":"servers/aws-location-mcp-server/#calculate_route","title":"calculate_route","text":"<p>Calculate a route between two locations using Amazon Location Service.</p> <p><pre><code>calculate_route(\n    departure_position: list,  # [longitude, latitude]\n    destination_position: list,  # [longitude, latitude]\n    travel_mode: str = 'Car',  # 'Car', 'Truck', 'Walking', or 'Bicycle'\n    optimize_for: str = 'FastestRoute'  # 'FastestRoute' or 'ShortestRoute'\n) -&gt; dict\n</code></pre> Returns route geometry, distance, duration, and turn-by-turn directions.</p> <ul> <li><code>departure_position</code>: List of [longitude, latitude] for the starting point.</li> <li><code>destination_position</code>: List of [longitude, latitude] for the destination.</li> <li><code>travel_mode</code>: Travel mode, one of <code>'Car'</code>, <code>'Truck'</code>, <code>'Walking'</code>, or <code>'Bicycle'</code>.</li> <li><code>optimize_for</code>: Route optimization, either <code>'FastestRoute'</code> or <code>'ShortestRoute'</code>.</li> </ul> <p>See AWS documentation for more details.</p>"},{"location":"servers/aws-location-mcp-server/#get_coordinates","title":"get_coordinates","text":"<p>Get coordinates for a location name or address.</p> <pre><code>get_coordinates(location: str) -&gt; dict\n</code></pre>"},{"location":"servers/aws-location-mcp-server/#optimize_waypoints","title":"optimize_waypoints","text":"<p>Optimize the order of waypoints using Amazon Location Service geo-routes API.</p> <p><pre><code>optimize_waypoints(\n    origin_position: list,  # [longitude, latitude]\n    destination_position: list,  # [longitude, latitude]\n    waypoints: list,  # List of waypoints, each as a dict with at least Position [longitude, latitude]\n    travel_mode: str = 'Car',\n    mode: str = 'summary'\n) -&gt; dict\n</code></pre> Returns the optimized order of waypoints, total distance, and duration.</p>"},{"location":"servers/aws-location-mcp-server/#amazon-location-service-resources","title":"Amazon Location Service Resources","text":"<p>This server uses the Amazon Location Service geo-places and route calculation APIs for: - Geocoding (converting addresses to coordinates) - Reverse geocoding (converting coordinates to addresses) - Place search (finding places by name, category, etc.) - Place details (getting information about specific places) - Route calculation (finding routes between locations)</p>"},{"location":"servers/aws-location-mcp-server/#security-considerations","title":"Security Considerations","text":"<ul> <li>Use AWS profiles for credential management</li> <li>Use IAM policies to restrict access to only the required Amazon Location Service resources</li> <li>Use temporary credentials (AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY, and AWS_SESSION_TOKEN) from AWS STS for enhanced security</li> <li>Implement AWS IAM roles with temporary credentials for applications and services</li> <li>Regularly rotate credentials and use the shortest practical expiration time for temporary credentials</li> </ul>"},{"location":"servers/aws-serverless-mcp-server/","title":"AWS Serverless MCP Server","text":""},{"location":"servers/aws-serverless-mcp-server/#overview","title":"Overview","text":"<p>The AWS Serverless Model Context Protocol (MCP) Server is an open-source tool that combines AI assistance with serverless expertise to streamline how developers build serverless applications. It provides contextual guidance specific to serverless development, helping developers make informed decisions about architecture, implementation, and deployment throughout the entire application development lifecycle. With AWS Serverless MCP, developers can build reliable, efficient, and production-ready serverless applications with confidence.</p> <p>Key benefits of the Serverless MCP Server include:</p> <ul> <li>AI-powered serverless development: Provides rich contextual information to AI coding assistants to ensure your serverless application aligns with AWS best practices.</li> <li>Comprehensive tooling: Offers tools for initialization, deployment, monitoring, and troubleshooting of serverless applications.</li> <li>Architecture guidance: Helps evaluate design choices and select optimal serverless patterns based on application needs. Offers recommendations on event sources, function boundaries, and service integrations.</li> <li>Operational best practices: Ensures alignment with AWS architectural principles. Suggests effective use of AWS services for event processing, data persistence, and service communication, and guides implementation of security controls, performance tuning, and cost optimization.</li> <li>Security-first approach: Implements built-in guardrails with read-only defaults and controlled access to sensitive data.</li> </ul>"},{"location":"servers/aws-serverless-mcp-server/#features","title":"Features","text":"<p>The set of tools provided by the Serverless MCP server can be broken down into four categories:</p> <ol> <li>Serverless Application Lifecycle<ul> <li>Initialize, build, and deploy Serverless Application Model (SAM) applications with SAM CLI</li> <li>Test Lambda functions locally and remotely</li> </ul> </li> <li>Web Application Deployment &amp; Management<ul> <li>Deploy full-stack, frontend, and backend web applications onto AWS Serverless using Lambda Web Adapter</li> <li>Update frontend assets and optionally invaliate CloudFront caches</li> <li>Create custom domain names, including certificate and DNS setup</li> </ul> </li> <li>Observability<ul> <li>Retrieve and logs and metrics of serverless resources</li> </ul> </li> <li>Guidance, Templates, and Deployment Help<ul> <li>Provides guidance on AWS Lambda use-cases, selecting an IaC framework, and deployment process onto AWS Serverless</li> <li>Provides sample SAM templates for different serverless application types from Serverless Land</li> <li>Provides schema types for different Lambda event sources and runtimes</li> <li>Provides schema registry management and discovery for AWS EventBridge events</li> <li>Enables type-safe Lambda function development with complete event schemas</li> </ul> </li> </ol>"},{"location":"servers/aws-serverless-mcp-server/#prerequisites","title":"Prerequisites","text":"<ul> <li>Have an AWS account with credentials configured</li> <li>Install uv from Astral or the GitHub README</li> <li>Install Python 3.10 or newer using uv python install 3.10 (or a more recent version)</li> <li>Install AWS SAM CLI</li> <li>Install AWS CLI</li> </ul>"},{"location":"servers/aws-serverless-mcp-server/#installation","title":"Installation","text":"<p>You can download the AWS Serverless MCP Server from GitHub. To get started using your favorite code assistant with MCP support, like Q Developer, Cursor or Cline.</p> <p>Add the following code to your MCP client configuration. The Serverless MCP server uses the default AWS profile by default. Specify a value in AWS_PROFILE if you want to use a different profile. Similarly, adjust the AWS Region and log level values as needed. <pre><code>{\n  \"mcpServers\": {\n    \"awslabs.aws-serverless-mcp-server\": {\n      \"command\": \"uvx\",\n      \"args\": [\n        \"awslabs.aws-serverless-mcp-server@latest\",\n        \"--allow-write\",\n        \"--allow-sensitive-data-access\"\n      ],\n      \"env\": {\n          \"AWS_PROFILE\": \"your-aws-profile\",\n          \"AWS_REGION\": \"us-east-1\"\n        },\n      \"disabled\": false,\n      \"autoApprove\": []\n    }\n  }\n}\n</code></pre></p>"},{"location":"servers/aws-serverless-mcp-server/#using-temporary-credentials","title":"Using temporary credentials","text":"<pre><code>{\n  \"mcpServers\": {\n    \"awslabs.aws-serverless-mcp-server\": {\n        \"command\": \"uvx\",\n        \"args\": [\"awslabs.aws-serverless-mcp-server@latest\"],\n        \"env\": {\n          \"AWS_ACCESS_KEY_ID\": \"your-temporary-access-key\",\n          \"AWS_SECRET_ACCESS_KEY\": \"your-temporary-secret-key\",\n          \"AWS_SESSION_TOKEN\": \"your-session-token\",\n          \"AWS_REGION\": \"us-east-1\"\n        },\n        \"disabled\": false,\n        \"autoApprove\": []\n    }\n  }\n}\n</code></pre>"},{"location":"servers/aws-serverless-mcp-server/#serverless-mcp-server-configuration-options","title":"Serverless MCP Server configuration options","text":""},{"location":"servers/aws-serverless-mcp-server/#-allow-write","title":"<code>--allow-write</code>","text":"<p>Enables write access mode, which allows mutating operations and creation of public resources. By default, the server runs in read-only mode, which restricts operations to only perform read actions, preventing any changes to AWS resources.</p> <p>Mutating operations:</p> <ul> <li>sam_deploy: Deploys a SAM application into AWS Cloud using CloudFormation</li> <li>deploy_webapp: Generates SAM template and deploys a web application into AWS CloudFormation. Creates public resources, including Route 53 DNS records, and CloudFront distributions</li> <li>configure_domain: Create custom domain using Route53 and ACM certificate and associates it with the project's CloudFront distribution</li> <li>update_frontend: Uploads frontend assets to S3 bucket</li> </ul>"},{"location":"servers/aws-serverless-mcp-server/#-allow-sensitive-data-access","title":"<code>--allow-sensitive-data-access</code>","text":"<p>Enables access to sensitive data such as logs. By default, the server restricts access to sensitive data.</p> <p>Operations returning sensitive data:</p> <ul> <li>sam_logs: Returns Lambda function logs and API Gateway logs</li> </ul>"},{"location":"servers/aws-serverless-mcp-server/#local-development","title":"Local development","text":"<p>To make changes to this MCP locally and run it:</p> <ol> <li> <p>Clone this repository:    <pre><code>git clone https://github.com/awslabs/mcp.git\ncd mcp/src/aws-serverless-mcp-server\n</code></pre></p> </li> <li> <p>Install dependencies:    <pre><code>pip install -e .\n</code></pre></p> </li> <li> <p>Configure AWS credentials:</p> </li> <li>Ensure you have AWS credentials configured in <code>~/.aws/credentials</code> or set the appropriate environment variables.</li> <li> <p>You can also set the AWS_PROFILE and AWS_REGION environment variables.</p> </li> <li> <p>Run the server:    <pre><code>python -m awslabs.aws_serverless_mcp_server.server\n</code></pre></p> </li> <li> <p>To use this MCP server with AI clients, add the following to your MCP configuration: <pre><code>{\n  \"mcpServers\": {\n    \"awslabs.aws-serverless-mcp-server\": {\n        \"command\": \"mcp/src/aws-serverless-mcp-server/bin/awslabs.aws-serverless-mcp-server/\",\n        \"env\": {\n          \"AWS_PROFILE\": \"your-aws-profile\",\n          \"AWS_REGION\": \"us-east-1\",\n        },\n        \"disabled\": false,\n        \"autoApprove\": []\n    }\n  }\n}\n</code></pre></p> </li> </ol>"},{"location":"servers/aws-serverless-mcp-server/#environment-variables","title":"Environment variables","text":"<p>By default, the default AWS profile is used. However, the server can be configured through environment variables in the MCP configuration:</p> <ul> <li><code>AWS_PROFILE</code>: AWS CLI profile to use for credentials</li> <li><code>AWS_REGION</code>: AWS region to use (default: us-east-1)</li> <li><code>AWS_ACCESS_KEY_ID</code> and <code>AWS_SECRET_ACCESS_KEY</code>: Explicit AWS credentials (alternative to AWS_PROFILE)</li> <li><code>AWS_SESSION_TOKEN</code>: Session token for temporary credentials (used with AWS_ACCESS_KEY_ID and AWS_SECRET_ACCESS_KEY)</li> <li><code>FASTMCP_LOG_LEVEL</code>: Logging level (ERROR, WARNING, INFO, DEBUG)</li> </ul>"},{"location":"servers/aws-serverless-mcp-server/#available-resources","title":"Available resources","text":"<p>The server provides the following resources:</p>"},{"location":"servers/aws-serverless-mcp-server/#template-resources","title":"Template resources","text":"<ul> <li><code>template://list</code>: List of available deployment templates.</li> <li><code>template://{template_name}</code>: Details of a specific deployment template.</li> </ul>"},{"location":"servers/aws-serverless-mcp-server/#deployment-resources","title":"Deployment resources","text":"<ul> <li><code>deployment://list</code>: List of all AWS deployments managed by the MCP server.</li> <li><code>deployment://{project_name}</code>: Details about a specific deployment.</li> </ul>"},{"location":"servers/aws-serverless-mcp-server/#available-tools","title":"Available tools","text":"<p>The server exposes deployment capabilities as tools:</p>"},{"location":"servers/aws-serverless-mcp-server/#sam_init","title":"sam_init","text":"<p>Initializes a serverless application using AWS SAM (Serverless Application Model) CLI. This tool creates a new SAM project that consists of: - An AWS SAM template to define your infrastructure code - A folder structure that organizes your application - Configuration for your AWS Lambda functions You should have AWS SAM CLI installed and configured in your environment.</p> <p>Parameters:</p> <ul> <li><code>project_name</code> (required): Name of the SAM project to create</li> <li><code>runtime</code> (required): Runtime environment for the Lambda function</li> <li><code>project_directory</code> (required): Absolute path to directory where the SAM application will be initialized</li> <li><code>dependency_manager</code> (required): Dependency manager for the Lambda function</li> <li><code>architecture</code> (default: x86_64): Architecture for the Lambda function</li> <li><code>package_type</code> (default: Zip): Package type for the Lambda function</li> <li><code>application_template</code> (default: hello-world): Template for the SAM application, e.g., hello-world, quick-start, etc.</li> <li><code>application_insights</code>: Activate Amazon CloudWatch Application Insights monitoring</li> <li><code>no_application_insights</code>: Deactivate Amazon CloudWatch Application Insights monitoring</li> <li><code>base_image</code>: Base image for the application when package type is Image</li> <li><code>config_env</code>: Environment name specifying default parameter values in the configuration file</li> <li><code>config_file</code>: Absolute path to configuration file containing default parameter values</li> <li><code>debug</code>: Turn on debug logging</li> <li><code>extra_content</code>: Override custom parameters in the template's cookiecutter.json</li> <li><code>location</code>: Template or application location (Git, HTTP/HTTPS, zip file path)</li> <li><code>save_params</code>: Save parameters to the SAM configuration file</li> <li><code>tracing</code>: Activate AWS X-Ray tracing for Lambda functions</li> <li><code>no_tracing</code>: Deactivate AWS X-Ray tracing for Lambda functions</li> </ul>"},{"location":"servers/aws-serverless-mcp-server/#sam_build","title":"sam_build","text":"<p>Builds a serverless application using AWS SAM (Serverless Application Model) CLI. This command compiles your Lambda function code, creates deployment artifacts, and prepares your application for deployment. Before running this tool, the application should already be initialized with 'sam_init' tool. You should have AWS SAM CLI installed and configured in your environment.</p> <p>Parameters:</p> <ul> <li><code>project_directory</code> (required): Absolute path to directory containing the SAM project</li> <li><code>template_file</code>: Absolute path to the template file (defaults to template.yaml)</li> <li><code>base_dir</code>: Resolve relative paths to function's source code with respect to this folder</li> <li><code>build_dir</code>: The absolute path to a directory where the built artifacts are stored</li> <li><code>use_container</code> (default: false): Use a container to build the function</li> <li><code>no_use_container</code> (default: false): Run build in local machine instead of Docker container</li> <li><code>parallel</code> (default: true): Build your AWS SAM application in parallel</li> <li><code>container_env_vars</code>: Environment variables to pass to the build container</li> <li><code>container_env_var_file</code>: Absolute path to a JSON file containing container environment variables</li> <li><code>build_image</code>: The URI of the container image that you want to pull for the build</li> <li><code>debug</code> (default: false): Turn on debug logging</li> <li><code>manifest</code>: Absolute path to a custom dependency manifest file (e.g., package.json) instead of the default</li> <li><code>parameter_overrides</code>: CloudFormation parameter overrides encoded as key-value pairs</li> <li><code>region</code>: AWS Region to deploy to (e.g., us-east-1)</li> <li><code>save_params</code> (default: false): Save parameters to the SAM configuration file</li> <li><code>profile</code>: AWS profile to use</li> </ul>"},{"location":"servers/aws-serverless-mcp-server/#sam_deploy","title":"sam_deploy","text":"<p>Deploys a serverless application using AWS SAM (Serverless Application Model) CLI. This command deploys your application to AWS CloudFormation. Every time an appplication is deployed, it should be built with 'sam_build' tool before. You should have AWS SAM CLI installed and configured in your environment.</p> <p>Parameters:</p> <ul> <li><code>application_name</code> (required): Name of the application to be deployed</li> <li><code>project_directory</code> (required): Absolute path to directory containing the SAM project (defaults to current directory)</li> <li><code>template_file</code>: Absolute path to the template file (defaults to template.yaml)</li> <li><code>s3_bucket</code>: S3 bucket to deploy artifacts to</li> <li><code>s3_prefix</code>: S3 prefix for the artifacts</li> <li><code>region</code>: AWS region to deploy to</li> <li><code>profile</code>: AWS profile to use</li> <li><code>parameter_overrides</code>: CloudFormation parameter overrides encoded as key-value pairs</li> <li><code>capabilities</code> (default: [\"CAPABILITY_IAM\"]): IAM capabilities required for the deployment</li> <li><code>config_file</code>: Absolute path to the SAM configuration file</li> <li><code>config_env</code>: Environment name specifying default parameter values in the configuration file</li> <li><code>metadata</code>: Metadata to include with the stack</li> <li><code>tags</code>: Tags to apply to the stack</li> <li><code>resolve_s3</code> (default: false): Automatically create an S3 bucket for deployment artifacts</li> <li><code>debug</code> (default: false): Turn on debug logging</li> </ul>"},{"location":"servers/aws-serverless-mcp-server/#sam_logs","title":"sam_logs","text":"<p>Fetches CloudWatch logs that are generated by resources in a SAM application. Use this tool to help debug invocation failures and find root causes.</p> <p>Parameters:</p> <ul> <li><code>resource_name</code>: Name of the resource to fetch logs for (logical ID in CloudFormation/SAM template)</li> <li><code>stack_name</code>: Name of the CloudFormation stack</li> <li><code>start_time</code>: Fetch logs starting from this time (format: 5mins ago, tomorrow, or YYYY-MM-DD HH:MM:SS)</li> <li><code>end_time</code>: Fetch logs up until this time (format: 5mins ago, tomorrow, or YYYY-MM-DD HH:MM:SS)</li> <li><code>output</code> (default: text): Output format (text or json)</li> <li><code>region</code>: AWS region to use (e.g., us-east-1)</li> <li><code>profile</code>: AWS profile to use</li> <li><code>cw_log_group</code>: CloudWatch Logs log groups to fetch logs from</li> <li><code>config_env</code>: Environment name specifying default parameter values in the configuration file</li> <li><code>config_file</code>: Absolute path to configuration file containing default parameter values</li> <li><code>save_params</code> (default: false): Save parameters to the SAM configuration file</li> </ul>"},{"location":"servers/aws-serverless-mcp-server/#sam_local_invoke","title":"sam_local_invoke","text":"<p>Locally invokes a Lambda function using AWS SAM CLI. This command runs your Lambda function locally in a Docker container that simulates the AWS Lambda environment. You can use this tool to test your Lambda functions before deploying them to AWS. Docker must be installed and running in your environment.</p> <p>Parameters:</p> <ul> <li><code>project_directory</code> (required): Absolute path to directory containing the SAM project</li> <li><code>resource_name</code> (required): Name of the Lambda function to invoke locally</li> <li><code>template_file</code>: Absolute path to the SAM template file (defaults to template.yaml)</li> <li><code>event_file</code>: Absolute path to a JSON file containing event data</li> <li><code>event_data</code>: JSON string containing event data (alternative to event_file)</li> <li><code>environment_variables_file</code>: Absolute path to a JSON file containing environment variables to pass to the function</li> <li><code>docker_network</code>: Docker network to run the Lambda function in</li> <li><code>container_env_vars</code>: Environment variables to pass to the container</li> <li><code>parameter</code>: Override parameters from the template file</li> <li><code>log_file</code>: Absolute path to a file where the function logs will be written</li> <li><code>layer_cache_basedir</code>: Directory where the layers will be cached</li> <li><code>region</code>: AWS region to use (e.g., us-east-1)</li> <li><code>profile</code>: AWS profile to use</li> </ul>"},{"location":"servers/aws-serverless-mcp-server/#get_iac_guidance","title":"get_iac_guidance","text":"<p>Returns guidance on selecting an infrastructure as code (IaC) platform to deploy Serverless application to AWS. Choices include AWS SAM, CDK, and CloudFormation. Use this tool to decide which IaC tool to use for your Lambda deployments based on your specific use case and requirements.</p> <p>Parameters:</p> <ul> <li><code>iac_tool</code> (default: CloudFormation): IaC tool to use (CloudFormation, SAM, CDK, Terraform)</li> <li><code>include_examples</code> (default: true): Whether to include examples</li> </ul>"},{"location":"servers/aws-serverless-mcp-server/#get_lambda_event_schemas","title":"get_lambda_event_schemas","text":"<p>Returns AWS Lambda event schemas for different event sources (e.g. s3, sns, apigw) and programming languages.  Each Lambda event source defines its own schema and language-specific types, which should be used in the Lambda function handler to correctly parse the event data. If you cannot find a schema for your event source, you can directly parse the event data as a JSON object. For EventBridge events, you must use the list_registries, search_schema, and describe_schema tools to access the schema registry directly, get schema definitions, and generate code processing logic.</p> <p>Parameters:</p> <ul> <li><code>event_source</code> (required): Event source (e.g., api-gw, s3, sqs, sns, kinesis, eventbridge, dynamodb)</li> <li><code>runtime</code> (required): Programming language for the schema references (e.g., go, nodejs, python, java)</li> </ul>"},{"location":"servers/aws-serverless-mcp-server/#get_lambda_guidance","title":"get_lambda_guidance","text":"<p>Use this tool to determine if AWS Lambda is suitable platform to deploy an application. Returns a comprehensive guide on when to choose AWS Lambda as a deployment platform. It includes scenarios when to use and not use Lambda, advantages and disadvantages, decision criteria, and specific guidance for various use cases.</p> <p>Parameters:</p> <ul> <li><code>use_case</code> (required): Description of the use case</li> <li><code>include_examples</code> (default: true): Whether to include examples</li> </ul>"},{"location":"servers/aws-serverless-mcp-server/#deploy_webapp","title":"deploy_webapp","text":"<p>Deploy web applications to AWS Serverless, including Lambda as compute, DynamoDB as databases, API GW, ACM Certificates, and Route 53 DNS records. This tool uses the Lambda Web Adapter framework so that applications can be written in a standard web framework like Express or Next.js can be easily deployed to Lambda. You do not need to use integrate the code with any adapter framework when using this tool.</p> <p>Parameters:</p> <ul> <li><code>deployment_type</code> (required): Type of deployment (backend, frontend, fullstack)</li> <li><code>project_name</code> (required): Project name</li> <li><code>project_root</code> (required): Absolute path to the project root directory</li> <li><code>region</code>: AWS Region to deploy to (e.g., us-east-1)</li> <li><code>backend_configuration</code>: Backend configuration</li> <li><code>frontend_configuration</code>: Frontend configuration</li> </ul>"},{"location":"servers/aws-serverless-mcp-server/#configure_domain","title":"configure_domain","text":"<p>Configures a custom domain for a deployed web application on AWS Serverless. This tool sets up Route 53 DNS records, ACM certificates, and CloudFront custom domain mappings as needed. Use this tool after deploying your web application to associate it with your own domain name.</p> <p>Parameters:</p> <ul> <li><code>project_name</code> (required): Project name</li> <li><code>domain_name</code> (required): Custom domain name</li> <li><code>create_certificate</code> (default: true): Whether to create a ACM certificate</li> <li><code>create_route53_record</code> (default: true): Whether to create a Route 53 record</li> <li><code>region</code>: AWS region to use (e.g., us-east-1)</li> </ul>"},{"location":"servers/aws-serverless-mcp-server/#webapp_deployment_help","title":"webapp_deployment_help","text":"<p>Get help information about using the deploy_webapp to perform web application deployments. If deployment_type is provided, returns help information for that deployment type. Otherwise, returns a list of deployments and general help information.</p> <p>Parameters:</p> <ul> <li><code>deployment_type</code> (required): Type of deployment to get help information for (backend, frontend, fullstack)</li> </ul>"},{"location":"servers/aws-serverless-mcp-server/#get_metrics","title":"get_metrics","text":"<p>Retrieves CloudWatch metrics from a deployed web application. Use this tool get metrics on error rates, latency, concurrency, etc.</p> <p>Parameters:</p> <ul> <li><code>project_name</code> (required): Project name</li> <li><code>start_time</code>: Start time for metrics (ISO format)</li> <li><code>end_time</code>: End time for metrics (ISO format)</li> <li><code>period</code> (default: 60): Period for metrics in seconds</li> <li><code>resources</code> (default: [\"lambda\", \"apiGateway\"]): Resources to get metrics for</li> <li><code>region</code>: AWS region to use (e.g., us-east-1)</li> <li><code>stage</code> (default: \"prod\"): API Gateway stage</li> </ul>"},{"location":"servers/aws-serverless-mcp-server/#update_webapp_frontend","title":"update_webapp_frontend","text":"<p>Update the frontend assets of a deployed web application. This tool uploads new frontend assets to S3 and optionally invalidates the CloudFront cache.</p> <p>Parameters:</p> <ul> <li><code>project_name</code> (required): Project name</li> <li><code>project_root</code> (required): Project root</li> <li><code>built_assets_path</code> (required): Absolute path to pre-built frontend assets</li> <li><code>invalidate_cache</code> (default: true): Whether to invalidate the CloudFront cache</li> <li><code>region</code>: AWS region to use (e.g., us-east-1)</li> </ul>"},{"location":"servers/aws-serverless-mcp-server/#deploy_serverless_app_help","title":"deploy_serverless_app_help","text":"<p>Provides instructions on how to deploy a serverless application to AWS Lambda. Deploying a Lambda application requires generating IaC templates, building the code, packaging the code, selecting a deployment tool, and executing the deployment commands. For deploying web applications specifically, use the deploy_webapp tool.</p> <p>Parameters:</p> <ul> <li><code>application_type</code> (required): Type of application to deploy (event_driven, backend, fullstack)</li> </ul>"},{"location":"servers/aws-serverless-mcp-server/#get_serverless_templates","title":"get_serverless_templates","text":"<p>Returns example SAM templates from the Serverless Land GitHub repo. Use this tool to get examples for building serverless applications with AWS Lambda and best practices of serverless architecture.</p> <p>Parameters:</p> <ul> <li><code>template_type</code> (required): Template type (e.g., API, ETL, Web)</li> <li><code>runtime</code>: Lambda runtime (e.g., nodejs22.x, python3.13)</li> </ul>"},{"location":"servers/aws-serverless-mcp-server/#schema-tools","title":"Schema Tools","text":""},{"location":"servers/aws-serverless-mcp-server/#list_registries","title":"list_registries","text":"<p>Lists the registries in your account.</p> <p>Parameters:</p> <ul> <li><code>registry_name_prefix</code>: Limits results to registries starting with this prefix</li> <li><code>scope</code>: Filter by registry scope (LOCAL or AWS)</li> <li><code>limit</code>: Maximum number of results to return (1-100)</li> <li><code>next_token</code>: Pagination token for subsequent requests</li> </ul>"},{"location":"servers/aws-serverless-mcp-server/#search_schema","title":"search_schema","text":"<p>Search for schemas in a registry using keywords.</p> <p>Parameters:</p> <ul> <li><code>keywords</code> (required): Keywords to search for (prefix with \"aws.\" for service events)</li> <li><code>registry_name</code> (required): Registry to search in (use \"aws.events\" for AWS service events)</li> <li><code>limit</code>: Maximum number of results (1-100)</li> <li><code>next_token</code>: Pagination token</li> </ul>"},{"location":"servers/aws-serverless-mcp-server/#describe_schema","title":"describe_schema","text":"<p>Retrieve the schema definition for the specified schema version.</p> <p>Parameters:</p> <ul> <li><code>registry_name</code> (required): Registry containing the schema (use \"aws.events\" for AWS service events)</li> <li><code>schema_name</code> (required): Name of schema to retrieve (e.g., \"aws.s3@ObjectCreated\" for S3 events)</li> <li><code>schema_version</code>: Version number of schema (latest by default)</li> </ul>"},{"location":"servers/aws-serverless-mcp-server/#example-usage","title":"Example usage","text":""},{"location":"servers/aws-serverless-mcp-server/#creating-a-lambda-function-with-sam","title":"Creating a Lambda Function with SAM","text":"<p>Example user prompt:</p> <pre><code>I want to build a simple backend for a todo app using Python and deploy it to the cloud with AWS Serverless. Can you help me create a new project called my-todo-app. It should include basic functionality to add and list todos. Once it's set up, please build and deploy it with all the necessary permissions. I don\u2019t need to review the changeset before deployment.\n</code></pre> <p>This prompt would trigger the AI assistant to: 1. Initialize a new SAM project using a template. 2. Make modifications to code and infra for a todo app. 3. Build the SAM application 4. Deploy the application with CAPABILITY_IAM permissions</p>"},{"location":"servers/aws-serverless-mcp-server/#deploying-a-web-application","title":"Deploying a Web Application","text":"<p>Example user prompt:</p> <pre><code>I have a full-stack web app built with Node.js called my-web-app, and I want to deploy it to the cloud using AWS. Everything\u2019s ready \u2014 both frontend and backend. Can you set it up and deploy it with AWS Lambda so it's live and works smoothly?\n</code></pre> <p>This prompt would trigger the AI assistant to use the deploy_webapp to deploy the full stack application with the specified configuration.</p>"},{"location":"servers/aws-serverless-mcp-server/#working-with-eventbridge-schemas","title":"Working with EventBridge Schemas","text":"<p>Example user prompt:</p> <pre><code>I need to create a Lambda function that processes autoscaling events. Can you help me find the right event schema and implement type-safe event handling?\n</code></pre> <p>This prompt would trigger the AI assistant to: 1. Search for autoscaling event schemas in aws.events registry using search_schema 2. Retrieve complete schema definition using describe_schema 3. Generate type-safe handler code based on schema structure 4. Implement validation for required fields</p>"},{"location":"servers/aws-serverless-mcp-server/#security-features","title":"Security features","text":"<ol> <li>AWS Authentication: Uses AWS credentials from the environment for secure authentication</li> <li>TLS Verification: Enforces TLS verification for all AWS API calls</li> <li>Resource Tagging: Tags all created resources for traceability</li> <li>Least Privilege: Uses IAM roles with appropriate permissions for CloudFormation templates</li> </ol>"},{"location":"servers/aws-serverless-mcp-server/#security-considerations","title":"Security considerations","text":""},{"location":"servers/aws-serverless-mcp-server/#production-use-cases","title":"Production use cases","text":"<p>The AWS Serverless MCP Server can be used for production environments with proper security controls in place. For production use cases, consider the following:</p> <ul> <li>Read-Only Mode by Default: The server runs in read-only mode by default, which is safer for production environments. Only explicitly enable write access when necessary.</li> <li>Disable auto-approve: Require the user to approve each time the AI assitant executes a tool</li> </ul>"},{"location":"servers/aws-serverless-mcp-server/#role-scoping-recommendations","title":"Role scoping recommendations","text":"<p>To follow security best practices:</p> <ol> <li>Create dedicated IAM roles to be used by the AWS Serverless MCP Server with the principle of least privilege</li> <li>Use separate roles for read-only and write operations</li> <li>Implement resource tagging to limit actions to resources created by the server</li> <li>Enable AWS CloudTrail to audit all API calls made by the server</li> <li>Regularly review the permissions granted to the server's IAM role</li> <li>Use IAM Access Analyzer to identify unused permissions that can be removed</li> </ol>"},{"location":"servers/aws-serverless-mcp-server/#sensitive-information-handling","title":"Sensitive information handling","text":"<p>IMPORTANT: Do not pass secrets or sensitive information via allowed input mechanisms:</p> <ul> <li>Do not include secrets or credentials in CloudFormation templates</li> <li>Do not pass sensitive information directly in the prompt to the model</li> </ul>"},{"location":"servers/aws-serverless-mcp-server/#links","title":"Links","text":"<ul> <li>Homepage</li> <li>Documentation</li> <li>Source Code</li> <li>Bug Tracker</li> <li>Changelog</li> </ul>"},{"location":"servers/aws-serverless-mcp-server/#license","title":"License","text":"<p>Apache-2.0</p>"},{"location":"servers/aws-support-mcp-server/","title":"AWS Support MCP Server","text":"<p>A Model Context Protocol (MCP) server implementation for interacting with the AWS Support API. This server enables AI assistants to create and manage AWS support cases programmatically.</p>"},{"location":"servers/aws-support-mcp-server/#features","title":"Features","text":"<ul> <li>Create and manage AWS support cases</li> <li>Retrieve case information and communications</li> <li>Add communications to existing cases</li> <li>Resolve support cases</li> <li>Determine appropriate Issue Type, Service Code, and Category Code</li> <li>Determine appropriate Severity Level for a case</li> </ul>"},{"location":"servers/aws-support-mcp-server/#requirements","title":"Requirements","text":"<ul> <li>Python 3.7+</li> <li>AWS credentials with Support API access</li> <li>Business, Enterprise On-Ramp, or Enterprise Support plan</li> </ul>"},{"location":"servers/aws-support-mcp-server/#prerequisites","title":"Prerequisites","text":"<ol> <li>Install <code>uv</code> from Astral or the GitHub README</li> <li>Install Python using <code>uv python install 3.10</code></li> </ol>"},{"location":"servers/aws-support-mcp-server/#installation","title":"Installation","text":"<p>Configure the MCP server in your MCP client configuration (e.g., for Amazon Q Developer CLI, edit <code>~/.aws/amazonq/mcp.json</code>):</p> <pre><code>{\n   \"mcpServers\": {\n      \"awslabs_support_mcp_server\": {\n         \"command\": \"uvx\",\n         \"args\": [\n            \"-m\", \"awslabs.aws-support-mcp-server@latest\",\n            \"--debug\",\n            \"--log-file\",\n            \"./logs/mcp_support_server.log\"\n         ],\n         \"env\": {\n            \"AWS_PROFILE\": \"your-aws-profile\"\n         }\n      }\n   }\n}\n</code></pre> <p>Alternatively: <pre><code>uv pip install -e .\nuv run awslabs/aws_support_mcp_server/server.py\n</code></pre></p> <pre><code>{\n   \"mcpServers\": {\n      \"awslabs_support_mcp_server\": {\n         \"command\": \"path-to-python\",\n         \"args\": [\n            \"-m\",\n            \"awslabs.aws_support_mcp_server.server\",\n            \"--debug\",\n            \"--log-file\",\n            \"./logs/mcp_support_server.log\"\n         ],\n         \"env\": {\n            \"AWS_PROFILE\": \"manual_enterprise\"\n         }\n      }\n   }\n}\n</code></pre>"},{"location":"servers/aws-support-mcp-server/#usage","title":"Usage","text":"<p>Start the server:</p> <pre><code>python -m awslabs.aws_support_mcp_server.server [options]\n</code></pre> <p>Options: - <code>--port PORT</code>: Port to run the server on (default: 8888) - <code>--debug</code>: Enable debug logging - <code>--log-file</code>: Where to save the log file</p>"},{"location":"servers/aws-support-mcp-server/#configuration","title":"Configuration","text":"<p>The server can be configured using environment variables:</p> <ul> <li><code>AWS_REGION</code>: AWS region (default: us-east-1)</li> <li><code>AWS_PROFILE</code>: AWS credentials profile name</li> </ul>"},{"location":"servers/aws-support-mcp-server/#documentation","title":"Documentation","text":"<p>For detailed documentation on available tools and resources, see the API Documentation.</p>"},{"location":"servers/aws-support-mcp-server/#license","title":"License","text":"<p>Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.</p> <p>Licensed under the Apache License, Version 2.0 (the \"License\").</p>"},{"location":"servers/bedrock-kb-retrieval-mcp-server/","title":"Amazon Bedrock Knowledge Base Retrieval MCP Server","text":"<p>MCP server for accessing Amazon Bedrock Knowledge Bases</p>"},{"location":"servers/bedrock-kb-retrieval-mcp-server/#features","title":"Features","text":""},{"location":"servers/bedrock-kb-retrieval-mcp-server/#discover-knowledge-bases-and-their-data-sources","title":"Discover knowledge bases and their data sources","text":"<ul> <li>Find and explore all available knowledge bases</li> <li>Search for knowledge bases by name or tag</li> <li>List data sources associated with each knowledge base</li> </ul>"},{"location":"servers/bedrock-kb-retrieval-mcp-server/#query-knowledge-bases-with-natural-language","title":"Query knowledge bases with natural language","text":"<ul> <li>Retrieve information using conversational queries</li> <li>Get relevant passages from your knowledge bases</li> <li>Access citation information for all results</li> </ul>"},{"location":"servers/bedrock-kb-retrieval-mcp-server/#filter-results-by-data-source","title":"Filter results by data source","text":"<ul> <li>Focus your queries on specific data sources</li> <li>Include or exclude specific data sources</li> <li>Prioritize results from specific data sources</li> </ul>"},{"location":"servers/bedrock-kb-retrieval-mcp-server/#rerank-results","title":"Rerank results","text":"<ul> <li>Improve relevance of retrieval results</li> <li>Use Amazon Bedrock reranking capabilities</li> <li>Sort results by relevance to your query</li> </ul>"},{"location":"servers/bedrock-kb-retrieval-mcp-server/#prerequisites","title":"Prerequisites","text":""},{"location":"servers/bedrock-kb-retrieval-mcp-server/#installation-requirements","title":"Installation Requirements","text":"<ol> <li>Install <code>uv</code> from Astral or the GitHub README</li> <li>Install Python using <code>uv python install 3.10</code></li> </ol>"},{"location":"servers/bedrock-kb-retrieval-mcp-server/#aws-requirements","title":"AWS Requirements","text":"<ol> <li>AWS CLI Configuration: You must have the AWS CLI configured with credentials and an AWS_PROFILE that has access to Amazon Bedrock and Knowledge Bases</li> <li>Amazon Bedrock Knowledge Base: You must have at least one Amazon Bedrock Knowledge Base with the tag key <code>mcp-multirag-kb</code> with a value of <code>true</code></li> <li>IAM Permissions: Your IAM role/user must have appropriate permissions to:</li> <li>List and describe knowledge bases</li> <li>Access data sources</li> <li>Query knowledge bases</li> </ol>"},{"location":"servers/bedrock-kb-retrieval-mcp-server/#reranking-requirements","title":"Reranking Requirements","text":"<p>If you intend to use reranking functionality, your Bedrock Knowledge Base needs additional permissions:</p> <ol> <li>Your IAM role must have permissions for both <code>bedrock:Rerank</code> and <code>bedrock:InvokeModel</code> actions</li> <li>The Amazon Bedrock Knowledge Bases service role must also have these permissions</li> <li>Reranking is only available in specific regions. Please refer to the official documentation for an up to date list of supported regions.</li> <li>Enable model access for the available reranking models in the specified region.</li> </ol>"},{"location":"servers/bedrock-kb-retrieval-mcp-server/#controlling-reranking","title":"Controlling Reranking","text":"<p>Reranking can be globally enabled or disabled using the <code>BEDROCK_KB_RERANKING_ENABLED</code> environment variable:</p> <ul> <li>Set to <code>false</code> (default): Disables reranking for all queries unless explicitly enabled</li> <li>Set to <code>true</code>: Enables reranking for all queries unless explicitly disabled</li> </ul> <p>The environment variable accepts various formats:</p> <ul> <li>For enabling: 'true', '1', 'yes', or 'on' (case-insensitive)</li> <li>For disabling: any other value or not set (default behavior)</li> </ul> <p>This setting provides a global default, while individual API calls can still override it by explicitly setting the <code>reranking</code> parameter.</p> <p>For detailed instructions on setting up knowledge bases, see:</p> <ul> <li>Create a knowledge base</li> <li>Managing permissions for Amazon Bedrock knowledge bases</li> <li>Permissions for reranking in Amazon Bedrock</li> </ul>"},{"location":"servers/bedrock-kb-retrieval-mcp-server/#installation","title":"Installation","text":"<p>Configure the MCP server in your MCP client configuration (e.g., for Amazon Q Developer CLI, edit <code>~/.aws/amazonq/mcp.json</code>):</p> <pre><code>{\n  \"mcpServers\": {\n    \"awslabs.bedrock-kb-retrieval-mcp-server\": {\n      \"command\": \"uvx\",\n      \"args\": [\"awslabs.bedrock-kb-retrieval-mcp-server@latest\"],\n      \"env\": {\n        \"AWS_PROFILE\": \"your-profile-name\",\n        \"AWS_REGION\": \"us-east-1\",\n        \"FASTMCP_LOG_LEVEL\": \"ERROR\",\n        \"KB_INCLUSION_TAG_KEY\": \"optional-tag-key-to-filter-kbs\",\n        \"BEDROCK_KB_RERANKING_ENABLED\": \"false\"\n      },\n      \"disabled\": false,\n      \"autoApprove\": []\n    }\n  }\n}\n</code></pre> <p>or docker after a successful <code>docker build -t awslabs/bedrock-kb-retrieval-mcp-server .</code>:</p> <pre><code># fictitious `.env` file with AWS temporary credentials\nAWS_ACCESS_KEY_ID=ASIAIOSFODNN7EXAMPLE\nAWS_SECRET_ACCESS_KEY=wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY\nAWS_SESSION_TOKEN=AQoEXAMPLEH4aoAH0gNCAPy...truncated...zrkuWJOgQs8IZZaIv2BXIa2R4Olgk\n</code></pre> <pre><code>  {\n    \"mcpServers\": {\n      \"awslabs.bedrock-kb-retrieval-mcp-server\": {\n        \"command\": \"docker\",\n        \"args\": [\n          \"run\",\n          \"--rm\",\n          \"--interactive\",\n          \"--env\",\n          \"FASTMCP_LOG_LEVEL=ERROR\",\n          \"--env\",\n          \"KB_INCLUSION_TAG_KEY=optional-tag-key-to-filter-kbs\",\n          \"--env\",\n          \"BEDROCK_KB_RERANKING_ENABLED=false\",\n          \"--env\",\n          \"AWS_REGION=us-east-1\",\n          \"--env-file\",\n          \"/full/path/to/file/above/.env\",\n          \"awslabs/bedrock-kb-retrieval-mcp-server:latest\"\n        ],\n        \"env\": {},\n        \"disabled\": false,\n        \"autoApprove\": []\n      }\n    }\n  }\n</code></pre> <p>NOTE: Your credentials will need to be kept refreshed from your host</p>"},{"location":"servers/bedrock-kb-retrieval-mcp-server/#limitations","title":"Limitations","text":"<ul> <li>Results with <code>IMAGE</code> content type are not included in the KB query response.</li> <li>The <code>reranking</code> parameter requires additional permissions, Amazon Bedrock model access, and is only available in specific regions.</li> </ul>"},{"location":"servers/cdk-mcp-server/","title":"AWS CDK MCP Server","text":"<p>MCP server for AWS Cloud Development Kit (CDK) best practices, infrastructure as code patterns, and security compliance with CDK Nag.</p>"},{"location":"servers/cdk-mcp-server/#features","title":"Features","text":""},{"location":"servers/cdk-mcp-server/#cdk-general-guidance","title":"CDK General Guidance","text":"<ul> <li>Prescriptive patterns with AWS Solutions Constructs and GenAI CDK libraries</li> <li>Structured decision flow for choosing appropriate implementation approaches</li> <li>Security automation through CDK Nag integration and Lambda Powertools</li> </ul>"},{"location":"servers/cdk-mcp-server/#cdk-nag-integration","title":"CDK Nag Integration","text":"<ul> <li>Work with CDK Nag rules for security and compliance</li> <li>Explain specific CDK Nag rules with AWS Well-Architected guidance</li> <li>Check if CDK code contains Nag suppressions that require human review</li> </ul>"},{"location":"servers/cdk-mcp-server/#aws-solutions-constructs","title":"AWS Solutions Constructs","text":"<ul> <li>Search and discover AWS Solutions Constructs patterns</li> <li>Find recommended patterns for common architecture needs</li> <li>Get detailed documentation on Solutions Constructs</li> </ul>"},{"location":"servers/cdk-mcp-server/#generative-ai-cdk-constructs","title":"Generative AI CDK Constructs","text":"<ul> <li>Search for GenAI CDK constructs by name or type</li> <li>Discover specialized constructs for AI/ML workloads</li> <li>Get implementation guidance for generative AI applications</li> </ul>"},{"location":"servers/cdk-mcp-server/#lambda-layer-documentation-provider","title":"Lambda Layer Documentation Provider","text":"<ul> <li>Access comprehensive documentation for AWS Lambda layers</li> <li>Get code examples for generic Lambda layers and Python-specific layers</li> <li>Retrieve directory structure information and implementation best practices</li> <li>Seamless integration with AWS Documentation MCP Server for detailed documentation</li> </ul>"},{"location":"servers/cdk-mcp-server/#amazon-bedrock-agent-schema-generation","title":"Amazon Bedrock Agent Schema Generation","text":"<ul> <li>Use this tool when creating Bedrock Agents with Action Groups that use Lambda functions</li> <li>Streamline the creation of Bedrock Agent schemas</li> <li>Convert code files to compatible OpenAPI specifications</li> </ul>"},{"location":"servers/cdk-mcp-server/#developer-notes","title":"Developer Notes","text":"<ul> <li>Requirements: Your Lambda function must use <code>BedrockAgentResolver</code> from AWS Lambda Powertools</li> <li>Lambda Dependencies: If schema generation fails, a fallback script will be generated. If you see error messages about missing dependencies, install them and then run the script again.</li> <li>Integration: Use the generated schema with <code>bedrock.ApiSchema.fromLocalAsset()</code> in your CDK code</li> </ul>"},{"location":"servers/cdk-mcp-server/#cdk-implementation-workflow","title":"CDK Implementation Workflow","text":"<p>This diagram provides a comprehensive view of the recommended CDK implementation workflow:</p> <pre><code>graph TD\n    Start([Start]) --&gt; A[\"CDKGeneralGuidance\"]\n    A --&gt; Init[\"cdk init app\"]\n\n    Init --&gt; B{Choose Approach}\n    B --&gt;|\"Common Patterns\"| C1[\"GetAwsSolutionsConstructPattern\"]\n    B --&gt;|\"GenAI Features\"| C2[\"SearchGenAICDKConstructs\"]\n    B --&gt;|\"Custom Needs\"| C3[\"Custom CDK Code\"]\n\n    C1 --&gt; D1[\"Implement Solutions Construct\"]\n    C2 --&gt; D2[\"Implement GenAI Constructs\"]\n    C3 --&gt; D3[\"Implement Custom Resources\"]\n\n    %% Bedrock Agent with Action Groups specific flow\n    D2 --&gt;|\"For Bedrock Agents&lt;br/&gt;with Action Groups\"| BA[\"Create Lambda with&lt;br/&gt;BedrockAgentResolver\"]\n\n    %% Schema generation flow\n    BA --&gt; BS[\"GenerateBedrockAgentSchema\"]\n    BS --&gt;|\"Success\"| JSON[\"openapi.json created\"]\n    BS --&gt;|\"Import Errors\"| BSF[\"Tool generates&lt;br/&gt;generate_schema.py\"]\n    BSF --&gt;|\"Missing dependencies?\"| InstallDeps[\"Install dependencies\"]\n    InstallDeps --&gt; BSR[\"Run script manually:&lt;br/&gt;python generate_schema.py\"]\n    BSR --&gt; JSON[\"openapi.json created\"]\n\n    %% Use schema in Agent CDK\n    JSON --&gt; AgentCDK[\"Use schema in&lt;br/&gt;Agent CDK code\"]\n    AgentCDK --&gt; D2\n\n    %% Conditional Lambda Powertools implementation\n    D1 &amp; D2 &amp; D3 --&gt; HasLambda{\"Using Lambda&lt;br/&gt;Functions?\"}\n    HasLambda --&gt; UseLayer{\"Using Lambda&lt;br/&gt;Layers?\"}\n    UseLayer --&gt;|\"Yes\"| LLDP[\"LambdaLayerDocumentationProvider\"]\n\n    HasLambda --&gt;|\"No\"| SkipL[\"Skip\"]\n\n    %% Rest of workflow\n    LLDP[\"LambdaLayerDocumentationProvider\"] --&gt; Synth[\"cdk synth\"]\n    SkipL --&gt; Synth\n\n    Synth --&gt; Nag{\"CDK Nag&lt;br/&gt;warnings?\"}\n    Nag --&gt;|Yes| E[\"ExplainCDKNagRule\"]\n    Nag --&gt;|No| Deploy[\"cdk deploy\"]\n\n    E --&gt; Fix[\"Fix or Add Suppressions\"]\n    Fix --&gt; CN[\"CheckCDKNagSuppressions\"]\n    CN --&gt; Synth\n\n    %% Styling with darker colors\n    classDef default fill:#424242,stroke:#ffffff,stroke-width:1px,color:#ffffff;\n    classDef cmd fill:#4a148c,stroke:#ffffff,stroke-width:1px,color:#ffffff;\n    classDef tool fill:#01579b,stroke:#ffffff,stroke-width:1px,color:#ffffff;\n    classDef note fill:#1b5e20,stroke:#ffffff,stroke-width:1px,color:#ffffff;\n    classDef output fill:#006064,stroke:#ffffff,stroke-width:1px,color:#ffffff;\n    classDef decision fill:#5d4037,stroke:#ffffff,stroke-width:1px,color:#ffffff;\n\n    class Init,Synth,Deploy,BSR cmd;\n    class A,C1,C2,BS,E,CN,LLDP tool;\n    class JSON output;\n    class HasLambda,UseLayer,Nag decision;</code></pre>"},{"location":"servers/cdk-mcp-server/#available-mcp-tools","title":"Available MCP Tools","text":"<ul> <li>CDKGeneralGuidance: Get prescriptive advice for building AWS applications with CDK</li> <li>GetAwsSolutionsConstructPattern: Find vetted architecture patterns combining AWS services</li> <li>SearchGenAICDKConstructs: Discover GenAI CDK constructs by name or features</li> <li>GenerateBedrockAgentSchema: Create OpenAPI schemas for Bedrock Agent action groups</li> <li>LambdaLayerDocumentationProvider: Access documentation for Lambda layers implementation</li> <li>ExplainCDKNagRule: Get detailed guidance on CDK Nag security rules</li> <li>CheckCDKNagSuppressions: Validate CDK Nag suppressions in your code</li> </ul>"},{"location":"servers/cdk-mcp-server/#available-mcp-resources","title":"Available MCP Resources","text":"<ul> <li>CDK Nag Rules: Access rule packs via <code>cdk-nag://rules/{rule_pack}</code></li> <li>AWS Solutions Constructs: Access patterns via <code>aws-solutions-constructs://{pattern_name}</code></li> <li>GenAI CDK Constructs: Access documentation via <code>genai-cdk-constructs://{construct_type}/{construct_name}</code></li> <li>Lambda Powertools: Get guidance on Lambda Powertools via <code>lambda-powertools://{topic}</code></li> </ul>"},{"location":"servers/cdk-mcp-server/#prerequisites","title":"Prerequisites","text":"<ol> <li>Install <code>uv</code> from Astral or the GitHub README</li> <li>Install Python using <code>uv python install 3.10</code></li> <li>Install AWS CDK CLI using <code>npm install -g aws-cdk</code> (Note: The MCP server itself doesn't use the CDK CLI directly, but it guides users through CDK application development that requires the CLI)</li> </ol>"},{"location":"servers/cdk-mcp-server/#installation","title":"Installation","text":"<p>Configure the MCP server in your MCP client configuration (e.g., for Amazon Q Developer CLI, edit <code>~/.aws/amazonq/mcp.json</code>):</p> <pre><code>{\n  \"mcpServers\": {\n    \"awslabs.cdk-mcp-server\": {\n      \"command\": \"uvx\",\n      \"args\": [\"awslabs.cdk-mcp-server@latest\"],\n      \"env\": {\n        \"FASTMCP_LOG_LEVEL\": \"ERROR\"\n      },\n      \"disabled\": false,\n      \"autoApprove\": []\n    }\n  }\n}\n</code></pre> <p>or docker after a successful <code>docker build -t awslabs/cdk-mcp-server .</code>:</p> <pre><code>  {\n    \"mcpServers\": {\n      \"awslabs.cdk-mcp-server\": {\n        \"command\": \"docker\",\n        \"args\": [\n          \"run\",\n          \"--rm\",\n          \"--interactive\",\n          \"--env\",\n          \"FASTMCP_LOG_LEVEL=ERROR\",\n          \"awslabs/cdk-mcp-server:latest\"\n        ],\n        \"env\": {},\n        \"disabled\": false,\n        \"autoApprove\": []\n      }\n    }\n  }\n</code></pre>"},{"location":"servers/cdk-mcp-server/#security-considerations","title":"Security Considerations","text":"<p>When using this MCP server, you should consider:</p> <ul> <li>Reviewing all CDK Nag warnings and errors manually</li> <li>Fixing security issues rather than suppressing them whenever possible</li> <li>Documenting clear justifications for any necessary suppressions</li> <li>Using the CheckCDKNagSuppressions tool to verify no unauthorized suppressions exist</li> </ul> <p>Before applying CDK NAG Suppressions, you should consider conducting your own independent assessment to ensure that your use would comply with your own specific security and quality control practices and standards, as well as the local laws, rules, and regulations that govern you and your content.</p>"},{"location":"servers/cfn-mcp-server/","title":"CloudFormation MCP Server","text":"<p>Model Context Protocol (MCP) server that enables LLMs to directly create and manage over 1,100 AWS resources through natural language using AWS Cloud Control API and Iac Generator with Infrastructure as Code best practices.</p>"},{"location":"servers/cfn-mcp-server/#features","title":"Features","text":"<ul> <li>Resource Creation: Uses a declarative approach to create any of 1,100+ AWS resources through Cloud Control API</li> <li>Resource Reading: Reads all properties and attributes of specific AWS resources</li> <li>Resource Updates: Uses a declarative approach to apply changes to existing AWS resources</li> <li>Resource Deletion: Safely removes AWS resources with proper validation</li> <li>Resource Listing: Enumerates all resources of a specified type across your AWS environment</li> <li>Schema Information: Returns detailed CloudFormation schema for any resource to enable more effective operations</li> <li>Natural Language Interface: Transform infrastructure-as-code from static authoring to dynamic conversations</li> <li>Partner Resource Support: Works with both AWS-native and partner-defined resources</li> <li>Template Generation: Generates a template on created/existing resources for a subset of resource types</li> </ul>"},{"location":"servers/cfn-mcp-server/#prerequisites","title":"Prerequisites","text":"<ol> <li>Configure AWS credentials:</li> <li>Via AWS CLI: <code>aws configure</code></li> <li>Or set environment variables (AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY, AWS_DEFAULT_REGION)</li> <li>Ensure your IAM role or user has the necessary permissions (see Security Considerations)</li> </ol>"},{"location":"servers/cfn-mcp-server/#installation","title":"Installation","text":"<p>Configure the MCP server in your MCP client configuration (e.g., for Amazon Q Developer CLI, edit <code>~/.aws/amazonq/mcp.json</code>):</p> <pre><code>{\n  \"mcpServers\": {\n    \"awslabs.cfn-mcp-server\": {\n      \"command\": \"uvx\",\n      \"args\": [\n        \"awslabs.cfn-mcp-server@latest\"\n      ],\n      \"env\": {\n        \"AWS_PROFILE\": \"your-named-profile\"\n      },\n      \"disabled\": false,\n      \"autoApprove\": []\n    }\n  }\n}\n</code></pre> <p>If you would like to prevent the MCP from taking any mutating actions (i.e. Create/Update/Delete Resource), you can specify the readonly flag as demonstrated below:</p> <pre><code>{\n  \"mcpServers\": {\n    \"awslabs.cfn-mcp-server\": {\n      \"command\": \"uvx\",\n      \"args\": [\n        \"awslabs.cfn-mcp-server@latest\",\n        \"--readonly\"\n      ],\n      \"env\": {\n        \"AWS_PROFILE\": \"your-named-profile\"\n      },\n      \"disabled\": false,\n      \"autoApprove\": []\n    }\n  }\n}\n</code></pre> <p>or docker after a successful <code>docker build -t awslabs/cfn-mcp-server .</code>:</p> <pre><code># fictitious `.env` file with AWS temporary credentials\nAWS_ACCESS_KEY_ID=ASIAIOSFODNN7EXAMPLE\nAWS_SECRET_ACCESS_KEY=wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY\nAWS_SESSION_TOKEN=AQoEXAMPLEH4aoAH0gNCAPy...truncated...zrkuWJOgQs8IZZaIv2BXIa2R4Olgk\n</code></pre> <pre><code>  {\n    \"mcpServers\": {\n      \"awslabs.cfn-mcp-server\": {\n        \"command\": \"docker\",\n        \"args\": [\n          \"run\",\n          \"--rm\",\n          \"--interactive\",\n          \"--env-file\",\n          \"/full/path/to/file/above/.env\",\n          \"awslabs/cfn-mcp-server:latest\",\n          \"--readonly\" // Optional paramter if you would like to restrict the MCP to only read actions\n        ],\n        \"env\": {},\n        \"disabled\": false,\n        \"autoApprove\": []\n      }\n    }\n  }\n</code></pre> <p>NOTE: Your credentials will need to be kept refreshed from your host</p>"},{"location":"servers/cfn-mcp-server/#tools","title":"Tools","text":""},{"location":"servers/cfn-mcp-server/#create_resource","title":"create_resource","text":"<p>Creates an AWS resource using the AWS Cloud Control API with a declarative approach. Example: Create an S3 bucket with versioning and encryption enabled.</p>"},{"location":"servers/cfn-mcp-server/#get_resource","title":"get_resource","text":"<p>Gets details of a specific AWS resource using the AWS Cloud Control API. Example: Get the configuration of an EC2 instance.</p>"},{"location":"servers/cfn-mcp-server/#update_resource","title":"update_resource","text":"<p>Updates an AWS resource using the AWS Cloud Control API with a declarative approach. Example: Update an RDS instance's storage capacity.</p>"},{"location":"servers/cfn-mcp-server/#delete_resource","title":"delete_resource","text":"<p>Deletes an AWS resource using the AWS Cloud Control API. Example: Remove an unused NAT gateway.</p>"},{"location":"servers/cfn-mcp-server/#list_resources","title":"list_resources","text":"<p>Lists AWS resources of a specified type using AWS Cloud Control API. Example: List all EC2 instances in a region.</p>"},{"location":"servers/cfn-mcp-server/#get_resource_schema_information","title":"get_resource_schema_information","text":"<p>Get schema information for an AWS CloudFormation resource. Example: Get the schema for AWS::S3::Bucket to understand all available properties.</p>"},{"location":"servers/cfn-mcp-server/#get_request_status","title":"get_request_status","text":"<p>Get the status of a mutation that was initiated by create/update/delete resource. Example: Give me the status of the last request I made.</p>"},{"location":"servers/cfn-mcp-server/#create_tempalte","title":"create_tempalte","text":"<p>Create a Cloudformation template from created or listed resources. Example: Create a YAML template for those resources.</p>"},{"location":"servers/cfn-mcp-server/#basic-usage","title":"Basic Usage","text":"<p>Examples of how to use the AWS Infrastructure as Code MCP Server:</p> <ul> <li>\"Create a new S3 bucket with versioning and encryption enabled\"</li> <li>\"List all EC2 instances in the production environment\"</li> <li>\"Update the RDS instance to increase storage to 500GB\"</li> <li>\"Delete unused NAT gateways in VPC-123\"</li> <li>\"Set up a three-tier architecture with web, app, and database layers\"</li> <li>\"Create a disaster recovery environment in us-east-1\"</li> <li>\"Configure CloudWatch alarms for all production resources\"</li> <li>\"Implement cross-region replication for critical S3 buckets\"</li> <li>\"Show me the schema for AWS::Lambda::Function\"</li> <li>\"Create a template for all the resources we created and modified\"</li> </ul>"},{"location":"servers/cfn-mcp-server/#resource-type-support","title":"Resource Type support","text":"<p>Resources which are supported by this MCP and the supported operations can be found here: https://docs.aws.amazon.com/cloudcontrolapi/latest/userguide/supported-resources.html</p>"},{"location":"servers/cfn-mcp-server/#security-considerations","title":"Security Considerations","text":"<p>When using this MCP server, you should consider:</p> <ul> <li>Ensuring proper IAM permissions are configured before use</li> <li>Use AWS CloudTrail for additional security monitoring</li> <li>Configure resource-specific permissions when possible instead of wildcard permissions</li> <li>Consider using resource tagging for better governance and cost management</li> <li>Review all changes made by the MCP server as part of your regular security reviews</li> <li>If you would like to restrict the MCP to readonly operations, specify --readonly True in the startup arguments for the MCP</li> </ul>"},{"location":"servers/cfn-mcp-server/#required-iam-permissions","title":"Required IAM Permissions","text":"<p>Ensure your AWS credentials have the following minimum permissions:</p> <pre><code>{\n    \"Version\": \"2012-10-17\",\n    \"Statement\": [\n        {\n            \"Effect\": \"Allow\",\n            \"Action\": [\n                \"cloudcontrol:ListResources\",\n                \"cloudcontrol:GetResource\",\n                \"cloudcontrol:CreateResource\",\n                \"cloudcontrol:DeleteResource\",\n                \"cloudcontrol:UpdateResource\",\n                \"cloudformation:CreateGeneratedTemplate\",\n                \"cloudformation:DescribeGeneratedTemplate\",\n                \"cloudformation:GetGeneratedTemplate\"\n            ],\n            \"Resource\": \"*\"\n        }\n    ]\n}\n</code></pre>"},{"location":"servers/cfn-mcp-server/#limitations","title":"Limitations","text":"<ul> <li>Operations are limited to resources supported by AWS Cloud Control API and Iac Generator</li> <li>Performance depends on the underlying AWS services' response times</li> <li>Some complex resource relationships may require multiple operations</li> <li>This MCP server can only manage resources in the AWS regions where Cloud Control API and/or Iac Generator is available</li> <li>Resource modification operations may be limited by service-specific constraints</li> <li>Rate limiting may affect operations when managing many resources simultaneously</li> <li>Some resource types might not support all operations (create, read, update, delete)</li> <li>Generated templates are primarily intended for importing existing resources into a CloudFormation stack and may not always work for creating new resources (in another account or region)</li> </ul>"},{"location":"servers/cloudwatch-logs-mcp-server/","title":"Cloudwatch logs mcp server","text":"<p>title: cloudwatch-logs MCP Server</p>"},{"location":"servers/cloudwatch-logs-mcp-server/#aws-labs-cloudwatch-logs-mcp-server","title":"AWS Labs cloudwatch-logs MCP Server","text":"<p>An AWS Labs Model Context Protocol (MCP) server for cloudwatch-logs</p>"},{"location":"servers/cloudwatch-logs-mcp-server/#instructions","title":"Instructions","text":"<p>Use this MCP server to run read-only commands and analyze CloudWatchLogs. Supports discovering logs groups as well as running CloudWatch Log Insight Queries. With CloudWatch Logs Insights, you can interactively search and analyze your log data in Amazon CloudWatch Logs and perform queries to help you more efficiently and effectively respond to operational issues.</p>"},{"location":"servers/cloudwatch-logs-mcp-server/#features","title":"Features","text":"<ul> <li>Discovering log groups and metadata about them within your AWS account or accounts connected by CloudWatch Cross Account Observability</li> <li>Converting human-readable questions and commands into CloudWatch Log Insight queries and executing them against the discovered log groups.</li> </ul>"},{"location":"servers/cloudwatch-logs-mcp-server/#prerequisites","title":"Prerequisites","text":"<ol> <li>Install <code>uv</code> from Astral or the GitHub README</li> <li>Install Python using <code>uv python install 3.10</code></li> <li>An AWS account with CloudWatch Log Groups</li> <li>This MCP server can only be run locally on the same host as your LLM client.</li> <li>Set up AWS credentials with access to AWS services</li> <li>You need an AWS account with appropriate permissions</li> <li>Configure AWS credentials with <code>aws configure</code> or environment variables</li> </ol>"},{"location":"servers/cloudwatch-logs-mcp-server/#available-tools","title":"Available Tools","text":"<ul> <li><code>describe_log_groups</code> - Describe log groups in the account and region, including user saved queries applicable to them. Supports Cross Account Observability.</li> <li><code>analyze_log_group</code> - Analyzes a CloudWatch log group for anomalies, top message patterns, and top error patterns within a specified time window. Log group must have at least one CloudWatch Log Anomaly Detector configured to search for anomalies.</li> <li><code>execute_log_insights_query</code> - Execute a Log Insights query against one or more log groups. Will wait for the query to complete for a configurable timeout.</li> <li><code>get_query_results</code> - Get the results of a query previously started by <code>execute_log_insights_query</code>.</li> <li><code>cancel_query</code> - Cancel an ongoing query that was previously started by <code>execute_log_insights_query</code>.</li> </ul>"},{"location":"servers/cloudwatch-logs-mcp-server/#required-iam-permissions","title":"Required IAM Permissions","text":"<ul> <li><code>logs:Describe*</code></li> <li><code>logs:Get*</code></li> <li><code>logs:List*</code></li> <li><code>logs:StartQuery</code></li> <li><code>logs:StopQuery</code></li> </ul>"},{"location":"servers/cloudwatch-logs-mcp-server/#installation","title":"Installation","text":"<p>Example for Amazon Q Developer CLI (~/.aws/amazonq/mcp.json):</p> <pre><code>{\n  \"mcpServers\": {\n    \"awslabs.cloudwatch-logs-mcp-server\": {\n      \"autoApprove\": [],\n      \"disabled\": false,\n      \"timeout\": 60,\n      \"command\": \"uvx\",\n      \"args\": [\n        \"awslabs.cloudwatch-logs-mcp-server@latest\"\n      ],\n      \"env\": {\n        \"AWS_PROFILE\": \"[The AWS Profile Name to use for AWS access]\",\n        \"AWS_REGION\": \"[The AWS region to run in]\",\n        \"FASTMCP_LOG_LEVEL\": \"ERROR\"\n      },\n      \"transportType\": \"stdio\"\n    }\n  }\n}\n</code></pre>"},{"location":"servers/cloudwatch-logs-mcp-server/#build-and-install-docker-image-locally-on-the-same-host-of-your-llm-client","title":"Build and install docker image locally on the same host of your LLM client","text":"<ol> <li><code>git clone https://github.com/awslabs/mcp.git</code></li> <li>Go to sub-directory 'src/cloudwatch-logs-mcp-server/'</li> <li>Run 'docker build -t awslabs/cloudwatch-logs-mcp-server:latest .'</li> </ol>"},{"location":"servers/cloudwatch-logs-mcp-server/#add-or-update-your-llm-clients-config-with-following","title":"Add or update your LLM client's config with following:","text":"<pre><code>{\n  \"mcpServers\": {\n    \"awslabs.cloudwatch-logs-mcp-server\": {\n      \"command\": \"docker\",\n      \"args\": [\n        \"run\",\n        \"-i\",\n        \"--rm\",\n        \"-e\", \"AWS_PROFILE=[your data]\",\n        \"-e\", \"AWS_REGION=[your data]\",\n        \"awslabs/cloudwatch-logs-mcp-server:latest\"\n      ]\n    }\n  }\n}\n</code></pre>"},{"location":"servers/cloudwatch-logs-mcp-server/#contributing","title":"Contributing","text":"<p>Contributions are welcome! Please see the CONTRIBUTING.md in the monorepo root for guidelines.</p>"},{"location":"servers/code-doc-gen-mcp-server/","title":"AWS Labs Code Documentation Generation MCP Server","text":"<p>A Model Context Protocol (MCP) server that automatically analyzes repository structure and generates comprehensive documentation for code projects. This server uses repomix to extract project structure and creates tailored documentation based on project type.</p>"},{"location":"servers/code-doc-gen-mcp-server/#architecture","title":"Architecture","text":""},{"location":"servers/code-doc-gen-mcp-server/#how-the-server-works","title":"How the Server Works","text":"<p>The code-doc-gen-mcp-server follows this workflow:</p> <ol> <li>prepare_repository:</li> <li>Uses RepomixManager to analyze a project directory</li> <li>Runs <code>repomix</code> to generate an XML representation of the repo</li> <li>Extracts directory structure from this XML</li> <li> <p>Returns a ProjectAnalysis with the directory structure</p> </li> <li> <p>create_context:</p> </li> <li> <p>Creates a DocumentationContext with the ProjectAnalysis</p> </li> <li> <p>plan_documentation:</p> </li> <li>Uses the directory structure from DocumentationContext</li> <li> <p>Creates a DocumentationPlan with document structure and sections</p> </li> <li> <p>generate_documentation:</p> </li> <li>Generates document templates based on the plan</li> </ol>"},{"location":"servers/code-doc-gen-mcp-server/#key-components","title":"Key Components","text":"<ol> <li>RepomixManager: Manages the execution of repomix and parses its XML output to extract directory structure</li> <li>DocumentationContext: Central state container that tracks project info and documentation progress</li> <li>ProjectAnalysis: Data structure containing analyzed project metadata (languages, dependencies, etc.)</li> <li>DocumentationPlan: Structured plan for document generation with section outlines</li> <li>DocumentGenerator: Creates actual document templates based on the plan</li> </ol>"},{"location":"servers/code-doc-gen-mcp-server/#features","title":"Features","text":"<ul> <li>Project Structure Analysis: Uses repomix to analyze repository structure and extract key components</li> <li>Content Organization: Creates appropriately structured documentation based on project type</li> <li>Multiple Document Types: Supports README, API docs, backend docs, frontend docs, and more</li> <li>Integration with Other MCP Servers: Works with AWS Diagram MCP server</li> <li>Custom Document Templates: Templates for different document types with appropriate sections</li> </ul>"},{"location":"servers/code-doc-gen-mcp-server/#prerequisites","title":"Prerequisites","text":"<ol> <li>Install <code>uv</code> from Astral or the GitHub README</li> <li>Install Python using <code>uv python install 3.10</code></li> <li>Install <code>repomix</code> using <code>pip install repomix&gt;=0.2.6</code></li> </ol>"},{"location":"servers/code-doc-gen-mcp-server/#installation","title":"Installation","text":"<p>This MCP server can be added to your AWS AI assistants via the appropriate MCP configuration file:</p> <pre><code>{\n  \"mcpServers\": {\n    \"awslabs.code-doc-gen-mcp-server\": {\n      \"command\": \"uvx\",\n      \"args\": [\"awslabs.code-doc-gen-mcp-server@latest\"],\n      \"env\": {\n        \"FASTMCP_LOG_LEVEL\": \"ERROR\"\n      },\n      \"disabled\": false,\n      \"autoApprove\": []\n    }\n  }\n}\n</code></pre>"},{"location":"servers/code-doc-gen-mcp-server/#core-concepts","title":"Core Concepts","text":""},{"location":"servers/code-doc-gen-mcp-server/#documentationcontext","title":"DocumentationContext","text":"<p>The <code>DocumentationContext</code> class maintains the state of the documentation process throughout its lifecycle:</p> <ul> <li><code>project_name</code>: Name of the project being documented</li> <li><code>working_dir</code>: Working directory for the project (source code location)</li> <li><code>repomix_path</code>: Path where documentation files will be generated</li> <li><code>status</code>: Current status of the documentation process</li> <li><code>current_step</code>: Current step in the documentation workflow</li> <li><code>analysis_result</code>: Contains the ProjectAnalysis with project metadata</li> </ul>"},{"location":"servers/code-doc-gen-mcp-server/#projectanalysis","title":"ProjectAnalysis","text":"<p>The <code>ProjectAnalysis</code> class contains detailed information about the project:</p> <ul> <li><code>project_type</code>: Type of project (e.g., \"Web Application\", \"CLI Tool\")</li> <li><code>features</code>: Key capabilities and functions of the project</li> <li><code>file_structure</code>: Project organization with directory structure</li> <li><code>dependencies</code>: Project dependencies with versions</li> <li><code>primary_languages</code>: Programming languages used in the project</li> <li><code>apis</code> (optional): API endpoint details</li> <li><code>backend</code> (optional): Backend implementation details</li> <li><code>frontend</code> (optional): Frontend implementation details</li> </ul>"},{"location":"servers/code-doc-gen-mcp-server/#tools","title":"Tools","text":""},{"location":"servers/code-doc-gen-mcp-server/#prepare_repository","title":"prepare_repository","text":"<pre><code>async def prepare_repository(\n    project_root: str = Field(..., description='Path to the code repository'),\n    ctx: Context = None,\n) -&gt; ProjectAnalysis\n</code></pre> <p>This tool: 1. Extracts directory structure from the repository using repomix 2. Returns a ProjectAnalysis template for the MCP client to fill 3. Provides directory structure in file_structure[\"directory_structure\"]</p> <p>The MCP client then: 1. Reviews the directory structure 2. Uses read_file to examine key files 3. Fills out the ProjectAnalysis fields 4. Sets has_infrastructure_as_code=True if CDK/Terraform code is detected</p>"},{"location":"servers/code-doc-gen-mcp-server/#create_context","title":"create_context","text":"<pre><code>async def create_context(\n    project_root: str = Field(..., description='Path to the code repository'),\n    analysis: ProjectAnalysis = Field(..., description='Completed ProjectAnalysis'),\n    ctx: Context = None,\n) -&gt; DocumentationContext\n</code></pre> <p>Creates a DocumentationContext from the completed ProjectAnalysis.</p>"},{"location":"servers/code-doc-gen-mcp-server/#plan_documentation","title":"plan_documentation","text":"<pre><code>async def plan_documentation(\n    doc_context: DocumentationContext,\n    ctx: Context,\n) -&gt; DocumentationPlan\n</code></pre> <p>Creates a documentation plan based on the project analysis, determining what document types are needed and creating appropriate document structures.</p>"},{"location":"servers/code-doc-gen-mcp-server/#generate_documentation","title":"generate_documentation","text":"<pre><code>async def generate_documentation(\n    plan: DocumentationPlan,\n    doc_context: DocumentationContext,\n    ctx: Context,\n) -&gt; List[GeneratedDocument]\n</code></pre> <p>Generates document structures with sections for the MCP client to fill with content.</p>"},{"location":"servers/code-doc-gen-mcp-server/#integration-with-other-mcp-servers","title":"Integration with Other MCP Servers","text":"<p>This MCP server is designed to work with:</p> <ul> <li>AWS Diagram MCP Server: For generating architecture diagrams</li> <li>AWS CDK MCP Server: For documenting CDK infrastructure code</li> </ul>"},{"location":"servers/code-doc-gen-mcp-server/#license","title":"License","text":"<p>This project is licensed under the Apache License, Version 2.0. See the LICENSE file for details.</p>"},{"location":"servers/core-mcp-server/","title":"Core MCP Server","text":"<p>MCP server that provides a starting point for using the following awslabs MCP servers - awslabs.cdk-mcp-server - awslabs.bedrock-kb-retrieval-mcp-server - awslabs.nova-canvas-mcp-server - awslabs.cost-analysis-mcp-server - awslabs.aws-documentation-mcp-server - awslabs.aws-diagram-mcp-server</p>"},{"location":"servers/core-mcp-server/#features","title":"Features","text":""},{"location":"servers/core-mcp-server/#planning-and-orchestration","title":"Planning and orchestration","text":"<ul> <li>Provides tool for prompt understanding and translation to AWS services</li> </ul>"},{"location":"servers/core-mcp-server/#prerequisites","title":"Prerequisites","text":"<ul> <li>Python 3.12 or higher</li> <li>uv - Fast Python package installer and resolver</li> <li>AWS credentials configured with Bedrock access</li> <li>Node.js (for UVX installation support)</li> </ul>"},{"location":"servers/core-mcp-server/#installation","title":"Installation","text":"<p>Configure the MCP server in your MCP client configuration (e.g., for Amazon Q Developer CLI, edit <code>~/.aws/amazonq/mcp.json</code>):</p> <pre><code>{\n  \"mcpServers\": {\n    \"awslabs.core-mcp-server\": {\n      \"command\": \"uvx\",\n      \"args\": [\n        \"awslabs.core-mcp-server@latest\"\n      ],\n      \"env\": {\n        \"FASTMCP_LOG_LEVEL\": \"ERROR\"\n      },\n      \"autoApprove\": [],\n      \"disabled\": false\n    }\n  }\n}\n</code></pre> <p>or docker after a successful <code>docker build -t awslabs/core-mcp-server .</code>:</p> <pre><code>  {\n    \"mcpServers\": {\n      \"awslabs.core-mcp-server\": {\n        \"command\": \"docker\",\n        \"args\": [\n          \"run\",\n          \"--rm\",\n          \"--interactive\",\n          \"--env\",\n          \"FASTMCP_LOG_LEVEL=ERROR\",\n          \"awslabs/core-mcp-server:latest\"\n        ],\n        \"env\": {},\n        \"disabled\": false,\n        \"autoApprove\": []\n      }\n    }\n  }\n</code></pre>"},{"location":"servers/core-mcp-server/#tools-and-resources","title":"Tools and Resources","text":"<p>The server exposes the following tools through the MCP interface:</p> <ul> <li><code>prompt_understanding</code> - Helps to provide guidance and planning support when building AWS Solutions for the given prompt</li> </ul>"},{"location":"servers/cost-analysis-mcp-server/","title":"Cost Analysis MCP Server","text":"<p>MCP server for generating upfront AWS service cost estimates and providing cost insights</p> <p>Important Note: This server provides estimated pricing based on AWS pricing APIs and web pages. These estimates are for pre-deployment planning purposes and do not reflect the actual expenses of deployed cloud services.</p>"},{"location":"servers/cost-analysis-mcp-server/#features","title":"Features","text":""},{"location":"servers/cost-analysis-mcp-server/#analyze-and-visualize-aws-costs","title":"Analyze and visualize AWS costs","text":"<ul> <li>Get detailed breakdown of your AWS costs by service, region and tier</li> <li>Understand how costs are distributed across various services</li> <li>Provide pre-deployment cost estimates for infrastructure planning</li> <li>Support for analyzing both CDK and Terraform projects to identify AWS services</li> </ul>"},{"location":"servers/cost-analysis-mcp-server/#query-cost-data-with-natural-language","title":"Query cost data with natural language","text":"<ul> <li>Ask questions about your AWS costs in plain English, no complex query languages required</li> <li>Get instant answers fetched from pricing webpage and AWS Pricing API, for questions related to AWS services</li> <li>Retrieve estimated pricing information before actual cloud service deployment</li> </ul>"},{"location":"servers/cost-analysis-mcp-server/#generate-cost-reports-and-insights","title":"Generate cost reports and insights","text":"<ul> <li>Generate comprehensive cost estimates based on your IaC implementation</li> <li>Get cost optimization recommendations for potential cloud infrastructure</li> <li>Provide upfront pricing analysis to support informed decision-making</li> </ul>"},{"location":"servers/cost-analysis-mcp-server/#prerequisites","title":"Prerequisites","text":"<ol> <li>Install <code>uv</code> from Astral or the GitHub README</li> <li>Install Python using <code>uv python install 3.10</code></li> <li>Set up AWS credentials with access to AWS services</li> <li>You need an AWS account with appropriate permissions</li> <li>Configure AWS credentials with <code>aws configure</code> or environment variables</li> <li>Ensure your IAM role/user has permissions to access AWS Pricing API</li> </ol>"},{"location":"servers/cost-analysis-mcp-server/#installation","title":"Installation","text":"<p>Configure the MCP server in your MCP client configuration (e.g., for Amazon Q Developer CLI, edit <code>~/.aws/amazonq/mcp.json</code>):</p> <pre><code>{\n  \"mcpServers\": {\n    \"awslabs.cost-analysis-mcp-server\": {\n      \"command\": \"uvx\",\n      \"args\": [\"awslabs.cost-analysis-mcp-server@latest\"],\n      \"env\": {\n        \"FASTMCP_LOG_LEVEL\": \"ERROR\",\n        \"AWS_PROFILE\": \"your-aws-profile\"\n      },\n      \"disabled\": false,\n      \"autoApprove\": []\n    }\n  }\n}\n</code></pre> <p>or docker after a successful <code>docker build -t awslabs/cost-analysis-mcp-server .</code>:</p> <pre><code># fictitious `.env` file with AWS temporary credentials\nAWS_ACCESS_KEY_ID=ASIAIOSFODNN7EXAMPLE\nAWS_SECRET_ACCESS_KEY=wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY\nAWS_SESSION_TOKEN=AQoEXAMPLEH4aoAH0gNCAPy...truncated...zrkuWJOgQs8IZZaIv2BXIa2R4Olgk\n</code></pre> <pre><code>  {\n    \"mcpServers\": {\n      \"awslabs.cost-analysis-mcp-server\": {\n        \"command\": \"docker\",\n        \"args\": [\n          \"run\",\n          \"--rm\",\n          \"--interactive\",\n          \"--env\",\n          \"FASTMCP_LOG_LEVEL=ERROR\",\n          \"--env-file\",\n          \"/full/path/to/file/above/.env\",\n          \"awslabs/cost-analysis-mcp-server:latest\"\n        ],\n        \"env\": {},\n        \"disabled\": false,\n        \"autoApprove\": []\n      }\n    }\n  }\n</code></pre> <p>NOTE: Your credentials will need to be kept refreshed from your host</p>"},{"location":"servers/cost-analysis-mcp-server/#aws-authentication","title":"AWS Authentication","text":"<p>The MCP server uses the AWS profile specified in the <code>AWS_PROFILE</code> environment variable. If not provided, it defaults to the \"default\" profile in your AWS configuration file.</p> <pre><code>\"env\": {\n  \"AWS_PROFILE\": \"your-aws-profile\"\n}\n</code></pre> <p>Make sure the AWS profile has permissions to access the AWS Pricing API. The MCP server creates a boto3 session using the specified profile to authenticate with AWS services. Your AWS IAM credentials remain on your local machine and are strictly used for accessing AWS services.</p>"},{"location":"servers/cost-explorer-mcp-server/","title":"Cost Explorer MCP Server","text":"<p>MCP server for analyzing AWS costs and usage data through the AWS Cost Explorer API.</p>"},{"location":"servers/cost-explorer-mcp-server/#features","title":"Features","text":""},{"location":"servers/cost-explorer-mcp-server/#analyze-aws-costs-and-usage-data","title":"Analyze AWS costs and usage data","text":"<ul> <li>Get detailed breakdown of your AWS costs by service, region, and other dimensions</li> <li>Understand how costs are distributed across various services</li> <li>Query historical cost data for specific time periods</li> <li>Filter costs by various dimensions, tags, and cost categories</li> </ul>"},{"location":"servers/cost-explorer-mcp-server/#query-cost-data-with-natural-language","title":"Query cost data with natural language","text":"<ul> <li>Ask questions about your AWS costs in plain English</li> <li>Get instant answers about your AWS spending patterns</li> <li>Retrieve historical cost data with simple queries</li> </ul>"},{"location":"servers/cost-explorer-mcp-server/#generate-cost-reports-and-insights","title":"Generate cost reports and insights","text":"<ul> <li>Generate comprehensive cost reports based on your AWS Cost Explorer data</li> <li>Get cost breakdowns by various dimensions (service, region, account, etc.)</li> <li>Analyze usage patterns and spending trends</li> </ul>"},{"location":"servers/cost-explorer-mcp-server/#prerequisites","title":"Prerequisites","text":"<ol> <li>Install <code>uv</code> from Astral or the GitHub README</li> <li>Install Python using <code>uv python install 3.10</code></li> <li>Set up AWS credentials with access to AWS Cost Explorer</li> <li>You need an AWS account with appropriate permissions</li> <li>Configure AWS credentials with <code>aws configure</code> or environment variables</li> <li>Ensure your IAM role/user has permissions to access AWS Cost Explorer API</li> </ol>"},{"location":"servers/cost-explorer-mcp-server/#installation","title":"Installation","text":"<p>Here are some ways you can work with MCP across AWS, and we'll be adding support to more products including Amazon Q Developer CLI soon: (e.g. for Amazon Q Developer CLI MCP, <code>~/.aws/amazonq/mcp.json</code>):</p> <pre><code>{\n  \"mcpServers\": {\n    \"awslabs.cost-explorer-mcp-server\": {\n      \"command\": \"uvx\",\n      \"args\": [\"awslabs.cost-explorer-mcp-server@latest\"],\n      \"env\": {\n        \"FASTMCP_LOG_LEVEL\": \"ERROR\",\n        \"AWS_PROFILE\": \"your-aws-profile\"\n      },\n      \"disabled\": false,\n      \"autoApprove\": []\n    }\n  }\n}\n</code></pre> <p>or docker after a successful <code>docker build -t awslabs/cost-explorer-mcp-server .</code>:</p> <pre><code># fictitious `.env` file with AWS temporary credentials\nAWS_ACCESS_KEY_ID=\nAWS_SECRET_ACCESS_KEY=\nAWS_SESSION_TOKEN=\n</code></pre> <pre><code>{\n  \"mcpServers\": {\n    \"awslabs.cost-explorer-mcp-server\": {\n      \"command\": \"docker\",\n      \"args\": [\n        \"run\",\n        \"--rm\",\n        \"--interactive\",\n        \"--env\",\n        \"FASTMCP_LOG_LEVEL=ERROR\",\n        \"--env-file\",\n        \"/full/path/to/file/above/.env\",\n        \"awslabs/cost-explorer-mcp-server:latest\"\n      ],\n      \"env\": {},\n      \"disabled\": false,\n      \"autoApprove\": []\n    }\n  }\n}\n</code></pre> <p>NOTE: Your credentials will need to be kept refreshed from your host</p>"},{"location":"servers/cost-explorer-mcp-server/#aws-authentication","title":"AWS Authentication","text":"<p>The MCP server uses the AWS profile specified in the <code>AWS_PROFILE</code> environment variable. If not provided, it defaults to the \"default\" profile in your AWS configuration file.</p> <pre><code>\"env\": {\n  \"AWS_PROFILE\": \"your-aws-profile\"\n}\n</code></pre> <p>Make sure the AWS profile has permissions to access the AWS Cost Explorer API. The MCP server creates a boto3 session using the specified profile to authenticate with AWS services. Your AWS IAM credentials remain on your local machine and are strictly used for accessing AWS services.</p>"},{"location":"servers/cost-explorer-mcp-server/#cost-considerations","title":"Cost Considerations","text":"<p>Important: AWS Cost Explorer API incurs charges on a per-request basis. Each API call made by this MCP server will result in charges to your AWS account.</p> <ul> <li>Cost Explorer API Pricing: The AWS Cost Explorer API lets you directly access the interactive, ad-hoc query engine that powers AWS Cost Explorer. Each request will incur a cost of $0.01.</li> <li>Each tool invocation that queries Cost Explorer (get_dimension_values, get_tag_values, get_cost_and_usage) will generate at least one billable API request</li> <li>Complex queries with multiple filters or large date ranges may result in multiple API calls</li> </ul> <p>For current pricing information, please refer to the AWS Cost Explorer Pricing page.</p>"},{"location":"servers/cost-explorer-mcp-server/#security-considerations","title":"Security Considerations","text":""},{"location":"servers/cost-explorer-mcp-server/#required-iam-permissions","title":"Required IAM Permissions","text":"<p>The following IAM permissions are required for this MCP server: - ce:GetCostAndUsage - ce:GetDimensionValues - ce:GetTags</p>"},{"location":"servers/cost-explorer-mcp-server/#available-tools","title":"Available Tools","text":"<p>The Cost Explorer MCP Server provides the following tools:</p> <ol> <li><code>get_today_date</code> - Get the current date and month to determine relevent data when answering last month.</li> <li><code>get_dimension_values</code> - Get available values for a specific dimension (e.g., SERVICE, REGION)</li> <li><code>get_tag_values</code> - Get available values for a specific tag key</li> <li><code>get_cost_and_usage</code> - Retrieve AWS cost and usage data with filtering and grouping options</li> </ol>"},{"location":"servers/cost-explorer-mcp-server/#example-usage","title":"Example Usage","text":"<p>Here are some examples of how to use the Cost Explorer MCP Server:</p>"},{"location":"servers/cost-explorer-mcp-server/#get-dimension-values","title":"Get dimension values","text":"<pre><code>What AWS services did I use last month?\n</code></pre>"},{"location":"servers/cost-explorer-mcp-server/#generate-a-cost-report","title":"Generate a cost report","text":"<pre><code>Show me my AWS costs for the last 3 months grouped by service in us-east-1 region\n</code></pre> <pre><code>What were my EC2 costs excluding us-east-2 for January 2025?\n</code></pre>"},{"location":"servers/cost-explorer-mcp-server/#license","title":"License","text":"<p>This project is licensed under the Apache License 2.0 - see the LICENSE file for details.</p>"},{"location":"servers/documentdb-mcp-server/","title":"AWS DocumentDB MCP Server","text":"<p>An AWS Labs Model Context Protocol (MCP) server for AWS DocumentDB that enables AI assistants to interact with DocumentDB databases.</p>"},{"location":"servers/documentdb-mcp-server/#overview","title":"Overview","text":"<p>The DocumentDB MCP Server provides tools to connect to and query AWS DocumentDB databases. It serves as a bridge between AI assistants and AWS DocumentDB, allowing for safe and efficient database operations through the Model Context Protocol (MCP).</p>"},{"location":"servers/documentdb-mcp-server/#features","title":"Features","text":"<ul> <li>Connection Management: Establish and maintain connections to DocumentDB clusters</li> <li>Database Management: List databases and retrieve database statistics</li> <li>Collection Management: List, create, drop collections and retrieve collection statistics</li> <li>Document Operations: Query, insert, update, and delete documents</li> <li>Aggregation Pipelines: Execute DocumentDB aggregation pipelines</li> <li>Query Planning: Get explanations of how operations will be executed</li> <li>Schema Analysis: Analyze collection schemas by sampling documents</li> <li>Read-Only Mode: Optional security feature to restrict operations to read-only operations</li> </ul>"},{"location":"servers/documentdb-mcp-server/#available-tools","title":"Available Tools","text":"<p>The DocumentDB MCP Server provides the following tools:</p>"},{"location":"servers/documentdb-mcp-server/#connection-management","title":"Connection Management","text":"<ul> <li><code>connect</code>: Connect to a DocumentDB cluster and get a connection ID</li> <li><code>disconnect</code>: Close an active connection</li> </ul>"},{"location":"servers/documentdb-mcp-server/#database-management","title":"Database Management","text":"<ul> <li><code>listDatabases</code>: List all available databases in the DocumentDB cluster</li> <li><code>getDatabaseStats</code>: Get statistics about a DocumentDB database</li> </ul>"},{"location":"servers/documentdb-mcp-server/#collection-management","title":"Collection Management","text":"<ul> <li><code>listCollections</code>: List collections in a database</li> <li><code>createCollection</code>: Create a new collection in a database (blocked in read-only mode)</li> <li><code>dropCollection</code>: Drop a collection from a database (blocked in read-only mode)</li> <li><code>getCollectionStats</code>: Get statistics about a collection</li> <li><code>countDocuments</code>: Count documents in a collection</li> <li><code>analyzeSchema</code>: Analyze the schema of a collection by sampling documents and providing field coverage</li> </ul>"},{"location":"servers/documentdb-mcp-server/#document-operations","title":"Document Operations","text":"<ul> <li><code>find</code>: Query documents from a collection</li> <li><code>aggregate</code>: Run aggregation pipelines</li> <li><code>insert</code>: Insert documents (blocked in read-only mode)</li> <li><code>update</code>: Update documents (blocked in read-only mode)</li> <li><code>delete</code>: Delete documents (blocked in read-only mode)</li> </ul>"},{"location":"servers/documentdb-mcp-server/#query-planning","title":"Query Planning","text":"<ul> <li><code>explainOperation</code>: Get an explanation of how an operation will be executed</li> </ul>"},{"location":"servers/documentdb-mcp-server/#server-configuration","title":"Server Configuration","text":""},{"location":"servers/documentdb-mcp-server/#starting-the-server","title":"Starting the Server","text":"<pre><code># Basic usage\npython -m awslabs.documentdb_mcp_server.server\n\n# With custom port and host\npython -m awslabs.documentdb_mcp_server.server --port 9000 --host 0.0.0.0\n\n# With write operations enabled\npython -m awslabs.documentdb_mcp_server.server --allow-write\n</code></pre>"},{"location":"servers/documentdb-mcp-server/#command-line-options","title":"Command Line Options","text":"Option Description Default <code>--log-level</code> Set logging level (TRACE, DEBUG, INFO, etc.) INFO <code>--connection-timeout</code> Idle connection timeout in minutes 30 <code>--allow-write</code> Enable write operations (otherwise defaults to read-only mode) False"},{"location":"servers/documentdb-mcp-server/#read-only-mode","title":"Read-Only Mode","text":"<p>By default, the server runs in read-only mode that only allows read operations. This enhances security by preventing any modifications to the database. In read-only mode:</p> <ul> <li>Read operations (<code>find</code>, <code>aggregate</code>, <code>listCollections</code>) work normally</li> <li>Write operations (<code>insert</code>, <code>update</code>, <code>delete</code>) are blocked and return a permission error</li> <li>Connection management operations (<code>connect</code>, <code>disconnect</code>) work normally</li> </ul> <p>This mode is particularly useful for: - Demonstration environments - Security-sensitive applications - Integration with public-facing AI assistants - Protecting production databases from unintended modifications</p>"},{"location":"servers/documentdb-mcp-server/#usage-examples","title":"Usage Examples","text":""},{"location":"servers/documentdb-mcp-server/#basic-connection-and-query-read-only-operations","title":"Basic Connection and Query (Read-Only Operations)","text":"<pre><code># Connect to a DocumentDB cluster\nconnection_result = await use_mcp_tool(\n    server_name=\"awslabs.aws-documentdb-mcp-server\",\n    tool_name=\"connect\",\n    arguments={\n        \"connection_string\": \"mongodb://&lt;username&gt;:&lt;password&gt;@docdb-cluster.cluster-xyz.us-west-2.docdb.amazonaws.com:27017/?tls=true&amp;tlsCAFile=global-bundle.pem\"\n    }\n)\nconnection_id = connection_result[\"connection_id\"]\n\n# Query documents\nquery_result = await use_mcp_tool(\n    server_name=\"awslabs.aws-documentdb-mcp-server\",\n    tool_name=\"find\",\n    arguments={\n        \"connection_id\": connection_id,\n        \"database\": \"my_database\",\n        \"collection\": \"users\",\n        \"query\": {\"active\": True},\n        \"limit\": 5\n    }\n)\n\n# Close the connection when done\nawait use_mcp_tool(\n    server_name=\"awslabs.aws-documentdb-mcp-server\",\n    tool_name=\"disconnect\",\n    arguments={\"connection_id\": connection_id}\n)\n</code></pre>"},{"location":"servers/documentdb-mcp-server/#enabling-write-operations","title":"Enabling Write Operations","text":"<p>To enable write operations, start the server with the <code>--allow-write</code> flag:</p> <pre><code>python -m awslabs.documentdb_mcp_server.server --allow-write\n</code></pre> <p>When the server is running with write operations enabled:</p> <pre><code># This operation will succeed\nquery_result = await use_mcp_tool(\n    server_name=\"awslabs.aws-documentdb-mcp-server\",\n    tool_name=\"find\",\n    arguments={\n        \"connection_id\": connection_id,\n        \"database\": \"my_database\",\n        \"collection\": \"users\",\n        \"query\": {\"active\": True}\n    }\n)\n\n# This operation will now succeed when --allow-write is used\ninsert_result = await use_mcp_tool(\n    server_name=\"awslabs.aws-documentdb-mcp-server\",\n    tool_name=\"insert\",\n    arguments={\n        \"connection_id\": connection_id,\n        \"database\": \"my_database\",\n        \"collection\": \"users\",\n        \"documents\": {\"name\": \"New User\", \"active\": True}\n    }\n)\n\n# Without the --allow-write flag, you would receive this error:\n# ValueError: \"Operation not permitted: Server is configured in read-only mode. Use --allow-write flag when starting the server to enable write operations.\"\n</code></pre>"},{"location":"servers/documentdb-mcp-server/#prerequisites","title":"Prerequisites","text":"<ul> <li>Network access to your DocumentDB cluster</li> <li>SSL/TLS certificate if your cluster requires TLS (typically <code>global-bundle.pem</code>)</li> </ul>"},{"location":"servers/dynamodb-mcp-server/","title":"AWS DynamoDB MCP Server","text":"<p>The official MCP Server for interacting with AWS DynamoDB</p>"},{"location":"servers/dynamodb-mcp-server/#available-mcp-tools","title":"Available MCP Tools","text":""},{"location":"servers/dynamodb-mcp-server/#table-operations","title":"Table Operations","text":"<ul> <li><code>create_table</code> - Creates a new DynamoDB table with optional secondary indexes</li> <li><code>delete_table</code> - Deletes a table and all of its items</li> <li><code>describe_table</code> - Returns table information including status, creation time, key schema and indexes</li> <li><code>list_tables</code> - Returns a paginated list of table names in your account</li> <li><code>update_table</code> - Modifies table settings including provisioned throughput, global secondary indexes, and DynamoDB Streams configuration</li> </ul>"},{"location":"servers/dynamodb-mcp-server/#item-operations","title":"Item Operations","text":"<ul> <li><code>get_item</code> - Returns attributes for an item with the given primary key</li> <li><code>put_item</code> - Creates a new item or replaces an existing item in a table</li> <li><code>update_item</code> - Edits an existing item's attributes, or adds a new item if it does not already exist</li> <li><code>delete_item</code> - Deletes a single item in a table by primary key</li> </ul>"},{"location":"servers/dynamodb-mcp-server/#query-and-scan-operations","title":"Query and Scan Operations","text":"<ul> <li><code>query</code> - Returns items from a table or index matching a partition key value, with optional sort key filtering</li> <li><code>scan</code> - Returns items and attributes by scanning a table or secondary index</li> </ul>"},{"location":"servers/dynamodb-mcp-server/#backup-and-recovery","title":"Backup and Recovery","text":"<ul> <li><code>create_backup</code> - Creates a backup of a DynamoDB table</li> <li><code>describe_backup</code> - Describes an existing backup of a table</li> <li><code>list_backups</code> - Returns a list of table backups</li> <li><code>restore_table_from_backup</code> - Creates a new table from a backup</li> <li><code>describe_continuous_backups</code> - Returns continuous backup and point in time recovery status</li> <li><code>update_continuous_backups</code> - Enables or disables point in time recovery</li> </ul>"},{"location":"servers/dynamodb-mcp-server/#time-to-live-ttl","title":"Time to Live (TTL)","text":"<ul> <li><code>update_time_to_live</code> - Enables or disables Time to Live (TTL) for the specified table</li> <li><code>describe_time_to_live</code> - Returns the Time to Live (TTL) settings for a table</li> </ul>"},{"location":"servers/dynamodb-mcp-server/#export-operations","title":"Export Operations","text":"<ul> <li><code>describe_export</code> - Returns information about a table export</li> <li><code>list_exports</code> - Returns a list of table exports</li> </ul>"},{"location":"servers/dynamodb-mcp-server/#tags-and-resource-policies","title":"Tags and Resource Policies","text":"<ul> <li><code>put_resource_policy</code> - Attaches a resource-based policy document to a table or stream</li> <li><code>get_resource_policy</code> - Returns the resource-based policy document attached to a table or stream</li> <li><code>tag_resource</code> - Adds tags to a DynamoDB resource</li> <li><code>untag_resource</code> - Removes tags from a DynamoDB resource</li> <li><code>list_tags_of_resource</code> - Returns tags for a DynamoDB resource</li> </ul>"},{"location":"servers/dynamodb-mcp-server/#misc","title":"Misc","text":"<ul> <li><code>describe_limits</code> - Returns the current provisioned-capacity quotas for your AWS account</li> <li><code>describe_endpoints</code> - Returns DynamoDB endpoints for the current region</li> </ul>"},{"location":"servers/dynamodb-mcp-server/#instructions","title":"Instructions","text":"<p>The official MCP Server for interacting with AWS DynamoDB provides a comprehensive set of tools for managing DynamoDB resources. Each tool maps directly to DynamoDB API operations and supports all relevant parameters.</p> <p>To use these tools, ensure you have proper AWS credentials configured with appropriate permissions for DynamoDB operations. The server will automatically use credentials from environment variables (AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY, AWS_SESSION_TOKEN) or other standard AWS credential sources.</p> <p>All tools support an optional <code>region_name</code> parameter to specify which AWS region to operate in. If not provided, it will use the AWS_REGION environment variable or default to 'us-west-2'.</p>"},{"location":"servers/dynamodb-mcp-server/#prerequisites","title":"Prerequisites","text":"<ol> <li>Install <code>uv</code> from Astral or the GitHub README</li> <li>Install Python using <code>uv python install 3.10</code></li> <li>Set up AWS credentials with access to AWS services</li> <li>Consider setting up Read-only permission if you don't want the LLM to modify any resources</li> </ol>"},{"location":"servers/dynamodb-mcp-server/#installation","title":"Installation","text":"<p>Add the MCP to your favorite agentic tools. e.g. for Amazon Q Developer CLI MCP, <code>~/.aws/amazonq/mcp.json</code>):</p> <pre><code>{\n  \"mcpServers\": {\n    \"awslabs.dynamodb-mcp-server\": {\n      \"command\": \"uvx\",\n      \"args\": [\"awslabs.dynamodb-mcp-server@latest\"],\n      \"env\": {\n        \"DDB-MCP-READONLY\": \"true\",\n        \"AWS_PROFILE\": \"default\",\n        \"AWS_REGION\": \"us-west-2\",\n        \"FASTMCP_LOG_LEVEL\": \"ERROR\"\n      },\n      \"disabled\": false,\n      \"autoApprove\": []\n    }\n  }\n}\n</code></pre> <p>or docker after a successful <code>docker build -t awslabs/dynamodb-mcp-server .</code>:</p> <pre><code>  {\n    \"mcpServers\": {\n      \"awslabs.dynamodb-mcp-server\": {\n        \"command\": \"docker\",\n        \"args\": [\n          \"run\",\n          \"--rm\",\n          \"--interactive\",\n          \"--env\",\n          \"FASTMCP_LOG_LEVEL=ERROR\",\n          \"awslabs/dynamodb-mcp-server:latest\"\n        ],\n        \"env\": {},\n        \"disabled\": false,\n        \"autoApprove\": []\n      }\n    }\n  }\n</code></pre>"},{"location":"servers/ecs-mcp-server/","title":"Amazon ECS MCP Server","text":"<p>An MCP server for containerizing applications, deploying applications to Amazon Elastic Container Service (ECS), troubleshooting ECS deployments, and managing ECS resources. This server enables AI assistants to help users with the full lifecycle of containerized applications on AWS.</p>"},{"location":"servers/ecs-mcp-server/#features","title":"Features","text":"<ul> <li>Containerization Guidance: Provides best practices and guidance for containerizing web applications</li> <li>ECS Deployment: Deploy containerized applications to AWS ECS using Fargate</li> <li>Load Balancer Integration: Automatically configure Application Load Balancers (ALBs) for web traffic</li> <li>Infrastructure as Code: Generate and apply CloudFormation templates for ECS infrastructure</li> <li>URL Management: Return public ALB URLs for immediate access to deployed applications</li> <li>Circuit Breaker: Implement deployment circuit breaker with automatic rollback</li> <li>Container Insights: Enable enhanced container insights for monitoring</li> <li>VPC Endpoints: Configure VPC endpoints for secure access to AWS services without internet exposure</li> <li>Security Best Practices: Implement AWS security best practices for container deployments</li> <li>Resource Management: List and explore ECS resources such as task definitions, services, clusters, and tasks</li> <li>ECR Integration: View repositories and container images in Amazon ECR</li> </ul> <p>Customers can use the <code>containerize_app</code> tool to help them containerize their applications with best practices and deploy them to Amazon ECS. The <code>create_ecs_infrastructure</code> tool automates infrastructure deployment using CloudFormation, while <code>get_deployment_status</code> returns the status of deployments and provide the URL of the set up Application Load Balancer. When resources are no longer needed, the <code>delete_ecs_infrastructure</code> tool allows for easy cleanup and removal of all deployed components.</p> <p>Customers can list and view their ECS resources (clusters, services, tasks, task definitions) and access their ECR resources (container images) using the <code>ecs_resource_management</code> tool. When running into ECS deployment issues, they can use the <code>ecs_troubleshooting_tool</code> to diagnose and resolve common problems.</p>"},{"location":"servers/ecs-mcp-server/#installation","title":"Installation","text":"<pre><code># Install using uv\nuv pip install awslabs.ecs-mcp-server\n\n# Or install using pip\npip install awslabs.ecs-mcp-server\n</code></pre> <p>You can also run the MCP server directly from a local clone of the GitHub repository:</p> <pre><code># Clone the awslabs repository\ngit clone https://github.com/awslabs/mcp.git\n\n# Run the server directly using uv\nuv --directory /path/to/ecs-mcp-server/src/ecs-mcp-server/awslabs/ecs_mcp_server run main.py\n</code></pre>"},{"location":"servers/ecs-mcp-server/#usage-environments","title":"Usage Environments","text":"<p>The ECS MCP Server is currently in development and is designed for the following environments:</p> <ul> <li>Development and Prototyping: Ideal for local application development, testing containerization approaches, and rapidly iterating on deployment configurations.</li> <li>Learning and Exploration: Excellent for users who want to learn about containerization, ECS, and AWS infrastructure.</li> <li>Testing and Staging: Suitable for integration testing and pre-production validation in non-critical environments.</li> </ul> <p>Not Recommended For: - Production Workloads: As this tool is still in active development, it is not suited for production deployments or business-critical applications. - Regulated or Sensitive Workloads: Not suitable for applications handling sensitive data or subject to regulatory compliance requirements.</p> <p>Important Note on Troubleshooting Tools: Even the troubleshooting tools should be used with caution in production environments. Always set <code>ALLOW_SENSITIVE_DATA=false</code> and <code>ALLOW_WRITE=false</code> flags when connecting to production accounts to prevent accidental exposure of sensitive information or unintended infrastructure modifications.</p>"},{"location":"servers/ecs-mcp-server/#production-considerations","title":"Production Considerations","text":"<p>While the ECS MCP Server is primarily designed for development, testing, and non-critical environments, certain components can be considered for controlled production use with appropriate safeguards.</p>"},{"location":"servers/ecs-mcp-server/#allowlisted-actions-for-production","title":"Allowlisted Actions for Production","text":"<p>The following operations are read-only and relatively safe for production environments when used with appropriate IAM permissions. Note: they can return sensitive information, so ensure <code>ALLOW_SENSITIVE_DATA=false</code> is set in production configurations.</p> Tool Operation Production Safety <code>ecs_resource_management</code> <code>list</code> operations (clusters, services, tasks) \u2705 Safe - Read-only <code>ecs_resource_management</code> <code>describe</code> operations (clusters, services, tasks) \u2705 Safe - Read-only <code>ecs_troubleshooting_tool</code> <code>fetch_service_events</code> \u2705 Safe - Read-only <code>ecs_troubleshooting_tool</code> <code>get_ecs_troubleshooting_guidance</code> \u2705 Safe - Read-only <code>get_deployment_status</code> Status checking \u2705 Safe - Read-only <p>The following operations modify resources and should be used with extreme caution in production:</p> Tool Operation Production Safety <code>create_ecs_infrastructure</code> Creating resources \u26a0\ufe0f High Risk - Creates infrastructure <code>delete_ecs_infrastructure</code> Deleting resources \ud83d\uded1 Dangerous - Deletes infrastructure <code>containerize_app</code> Generate container configs \ud83d\udfe1 Medium Risk - Local changes only"},{"location":"servers/ecs-mcp-server/#when-to-consider-production-use","title":"When to Consider Production Use","text":"<p>The ECS MCP Server may be appropriate for production environments in the following scenarios:</p> <ol> <li>Read-only monitoring: Using resource management tools with read-only IAM policies</li> <li>Troubleshooting non-critical issues: Using diagnostic tools to gather logs and status information</li> <li>Sandbox or isolated environments: Using deployment tools in production-like environments that are isolated from core services</li> </ol>"},{"location":"servers/ecs-mcp-server/#when-to-avoid-production-use","title":"When to Avoid Production Use","text":"<p>Avoid using ECS MCP Server in production for:</p> <ol> <li>Critical business infrastructure</li> <li>Applications handling sensitive customer data</li> <li>High-throughput or high-availability services</li> <li>Regulated workloads with compliance requirements</li> <li>Infrastructure lacking proper backup and disaster recovery procedures</li> </ol>"},{"location":"servers/ecs-mcp-server/#configuration","title":"Configuration","text":"<p>Add the ECS MCP Server to your MCP client configuration:</p> <pre><code>{\n  \"mcpServers\": {\n    \"awslabs.ecs-mcp-server\": {\n      \"command\": \"uvx\",\n      \"args\": [\"--from\", \"awslabs-ecs-mcp-server\", \"ecs-mcp-server\"],\n      \"env\": {\n        \"AWS_PROFILE\": \"your-aws-profile\", // Optional - uses your local AWS configuration if not specified\n        \"AWS_REGION\": \"your-aws-region\", // Optional - uses your local AWS configuration if not specified\n        \"FASTMCP_LOG_LEVEL\": \"ERROR\",\n        \"FASTMCP_LOG_FILE\": \"/path/to/ecs-mcp-server.log\",\n        \"ALLOW_WRITE\": \"false\",\n        \"ALLOW_SENSITIVE_DATA\": \"false\"\n      }\n    }\n  }\n}\n</code></pre> <p>If running from a local repository, configure the MCP client like this:</p> <pre><code>{\n  \"mcpServers\": {\n    \"awslabs.ecs-mcp-server\": {\n      \"command\": \"uv\",\n      \"args\": [\n        \"--directory\",\n        \"/path/to/ecs-mcp-server/src/ecs-mcp-server/awslabs/ecs_mcp_server\",\n        \"run\",\n        \"main.py\"\n      ],\n      \"env\": {\n        \"AWS_PROFILE\": \"your-aws-profile\",\n        \"AWS_REGION\": \"your-aws-region\",\n        \"FASTMCP_LOG_LEVEL\": \"DEBUG\",\n        \"FASTMCP_LOG_FILE\": \"/path/to/ecs-mcp-server.log\",\n        \"ALLOW_WRITE\": \"false\",\n        \"ALLOW_SENSITIVE_DATA\": \"false\"\n      }\n    }\n  }\n}\n</code></pre>"},{"location":"servers/ecs-mcp-server/#security-controls","title":"Security Controls","text":"<p>The ECS MCP Server includes security controls in your MCP client configuration to prevent accidental changes to infrastructure and limit access to sensitive data:</p>"},{"location":"servers/ecs-mcp-server/#allow_write","title":"ALLOW_WRITE","text":"<p>Controls whether write operations (creating or deleting infrastructure) are allowed.</p> <pre><code># Enable write operations\n\"ALLOW_WRITE\": \"true\"\n\n# Disable write operations (default)\n\"ALLOW_WRITE\": \"false\"\n</code></pre>"},{"location":"servers/ecs-mcp-server/#allow_sensitive_data","title":"ALLOW_SENSITIVE_DATA","text":"<p>Controls whether tools that return logs and detailed resource information are allowed.</p> <pre><code># Enable access to sensitive data\n\"ALLOW_SENSITIVE_DATA\": \"true\"\n\n# Disable access to sensitive data (default)\n\"ALLOW_SENSITIVE_DATA\": \"false\"\n</code></pre>"},{"location":"servers/ecs-mcp-server/#iam-best-practices","title":"IAM Best Practices","text":"<p>We strongly recommend creating dedicated IAM roles with least-privilege permissions when using the ECS MCP Server:</p> <ol> <li>Create a dedicated IAM role specifically for ECS MCP Server operations</li> <li>Apply least-privilege permissions by attaching only the necessary policies based on your use case</li> <li>Use scoped-down resource policies whenever possible</li> <li>Apply a permission boundary to limit the maximum permissions</li> </ol> <p>For detailed example IAM policies tailored for different ECS MCP Server use cases (read-only monitoring, troubleshooting, deployment, and service-specific access), see EXAMPLE_IAM_POLICIES.md.</p>"},{"location":"servers/ecs-mcp-server/#mcp-tools","title":"MCP Tools","text":""},{"location":"servers/ecs-mcp-server/#deployment-tools","title":"Deployment Tools","text":"<p>These tools help you containerize applications and deploy them to Amazon ECS with proper infrastructure setup and monitoring.</p> <ul> <li>containerize_app: Generates Dockerfile and container configurations for web applications</li> <li>create_ecs_infrastructure: Creates AWS infrastructure needed to deploy your containerized application using ECS. This includes:</li> <li>Application Load Balancer (ALB) with public-facing endpoints</li> <li>Network security groups with appropriate inbound/outbound rules</li> <li>IAM roles and policies with least-privilege permissions</li> <li>VPC configurations with public and private subnets (if needed)</li> <li>S3 Gateway endpoint associations for ECR image pulls</li> <li>ECS cluster with capacity provider settings</li> <li>Task definition with CPU/memory allocations and container configs</li> <li>Service configuration with desired count and auto-scaling policies</li> <li>Health check configuration and deployment circuit breakers</li> <li>get_deployment_status: Gets the status of an ECS deployment and returns the ALB URL</li> <li>delete_ecs_infrastructure: Deletes the AWS infrastructure created by the ECS MCP Server</li> </ul>"},{"location":"servers/ecs-mcp-server/#troubleshooting-tool","title":"Troubleshooting Tool","text":"<p>The troubleshooting tool helps diagnose and resolve common ECS deployment issues stemming from infrastructure, service, task, and network configuration.</p> <ul> <li>ecs_troubleshooting_tool: Consolidated tool with the following actions:</li> <li>get_ecs_troubleshooting_guidance: Initial assessment and troubleshooting path recommendation</li> <li>fetch_cloudformation_status: Infrastructure-level diagnostics for CloudFormation stacks</li> <li>fetch_service_events: Service-level diagnostics for ECS services</li> <li>fetch_task_failures: Task-level diagnostics for ECS task failures</li> <li>fetch_task_logs: Application-level diagnostics through CloudWatch logs</li> <li>detect_image_pull_failures: Specialized tool for detecting container image pull failures</li> <li>fetch_network_configuration: Network-level diagnostics for ECS deployments including VPC, subnets, security groups, and load balancers</li> </ul>"},{"location":"servers/ecs-mcp-server/#resource-management","title":"Resource Management","text":"<p>This tool provides read-only access to Amazon ECS resources to help you monitor and understand your deployment environment.</p> <ul> <li>ecs_resource_management: List and describe ECS resources including:</li> <li>Clusters: List all clusters, describe specific cluster details</li> <li>Services: List services in a cluster, describe service configuration</li> <li>Tasks: List running or stopped tasks, describe task details and status</li> <li>Task Definitions: List task definition families, describe specific task definition revisions</li> <li>Container Instances: List container instances, describe instance health and capacity</li> <li>Capacity Providers: List and describe capacity providers associated with clusters</li> <li>ECR repositories and container images</li> </ul>"},{"location":"servers/ecs-mcp-server/#example-prompts","title":"Example Prompts","text":""},{"location":"servers/ecs-mcp-server/#containerization-and-deployment","title":"Containerization and Deployment","text":"<ul> <li>\"Containerize this Node.js app and deploy it to AWS\"</li> <li>\"Deploy this Flask application to Amazon ECS\"</li> <li>\"Create an ECS deployment for this web application with auto-scaling\"</li> <li>\"Set up a containerized environment for this Django app on Amazon ECS\"</li> <li>\"List all my ECS clusters\"</li> <li>\"Show me details for my-cluster\"</li> </ul>"},{"location":"servers/ecs-mcp-server/#troubleshooting","title":"Troubleshooting","text":"<ul> <li>\"Help me troubleshoot my ECS deployment\"</li> <li>\"My ECS tasks keep failing, can you diagnose the issue?\"</li> <li>\"The ALB health check is failing for my ECS service\"</li> <li>\"Why can't I access my deployed application?\"</li> <li>\"Check what's wrong with my CloudFormation stack\"</li> </ul>"},{"location":"servers/ecs-mcp-server/#resource-management_1","title":"Resource Management","text":"<ul> <li>\"Show me my ECS clusters\"</li> <li>\"List all running tasks in my ECS cluster\"</li> <li>\"Describe my ECS service configuration\"</li> <li>\"Get information about my task definition\"</li> </ul>"},{"location":"servers/ecs-mcp-server/#requirements","title":"Requirements","text":"<ul> <li>Python 3.10+</li> <li>AWS credentials with permissions for ECS, ECR, CloudFormation, and related services</li> <li>Docker (for local containerization testing)</li> </ul>"},{"location":"servers/ecs-mcp-server/#license","title":"License","text":"<p>This project is licensed under the Apache-2.0 License.</p>"},{"location":"servers/eks-mcp-server/","title":"Amazon EKS MCP Server","text":"<p>The Amazon EKS MCP server provides AI code assistants with resource management tools and real-time cluster state visibility. This provides large language models (LLMs) with essential tooling and contextual awareness, enabling AI code assistants to streamline application development through tailored guidance \u2014 from initial setup through production optimization and troubleshooting.</p> <p>Integrating the EKS MCP server into AI code assistants enhances development workflow across all phases, from simplifying initial cluster setup with automated prerequisite creation and application of best practices. Further, it streamlines application deployment with high-level workflows and automated code generation. Finally, it accelerates troubleshooting through intelligent debugging tools and knowledge base access. All of this simplifies complex operations through natural language interactions in AI code assistants.</p>"},{"location":"servers/eks-mcp-server/#key-features","title":"Key features","text":"<ul> <li>Enables users of AI code assistants to create new EKS clusters, complete with prerequisites such as dedicated VPCs, networking, and EKS Auto Mode node pools, by translating requests into the appropriate AWS CloudFormation actions.</li> <li>Provides the ability to deploy containerized applications by applying existing Kubernetes YAML files or by generating new deployment and service manifests based on user-provided parameters.</li> <li>Supports full lifecycle management of individual Kubernetes resources (such as Pods, Services, and Deployments) within EKS clusters, enabling create, read, update, patch, and delete operations.</li> <li>Provides the ability to list Kubernetes resources with filtering by namespace, labels, and fields, simplifying the process for both users and LLMs to gather information about the state of Kubernetes applications and EKS infrastructure.</li> <li>Facilitates operational tasks such as retrieving logs from specific pods and containers or fetching Kubernetes events related to particular resources, supporting troubleshooting and monitoring for both direct users and AI-driven workflows.</li> <li>Enables users to troubleshoot issues with an EKS cluster.</li> </ul>"},{"location":"servers/eks-mcp-server/#prerequisites","title":"Prerequisites","text":"<ul> <li>Install Python 3.10+</li> <li>Install the <code>uv</code> package manager</li> <li>Install and configure the AWS CLI with credentials</li> </ul>"},{"location":"servers/eks-mcp-server/#setup","title":"Setup","text":"<p>Add these IAM policies to the IAM role or user that you use to manage your EKS cluster resources.</p>"},{"location":"servers/eks-mcp-server/#read-only-operations-policy","title":"Read-Only Operations Policy","text":"<p>For read operations, the following permissions are required:</p> <pre><code>{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Effect\": \"Allow\",\n      \"Action\": [\n        \"eks:DescribeCluster\",\n        \"cloudformation:DescribeStacks\",\n        \"cloudwatch:GetMetricData\",\n        \"logs:StartQuery\",\n        \"logs:GetQueryResults\",\n        \"iam:GetRole\",\n        \"iam:GetRolePolicy\",\n        \"iam:ListRolePolicies\",\n        \"iam:ListAttachedRolePolicies\",\n        \"iam:GetPolicy\",\n        \"iam:GetPolicyVersion\",\n        \"eks-mcpserver:QueryKnowledgeBase\"\n      ],\n      \"Resource\": \"*\"\n    }\n  ]\n}\n</code></pre>"},{"location":"servers/eks-mcp-server/#write-operations-policy","title":"Write Operations Policy","text":"<p>For write operations, we recommend the following IAM policies to ensure successful deployment of EKS clusters using the CloudFormation template in <code>/awslabs/eks_mcp_server/templates/eks-templates/eks-with-vpc.yaml</code>:</p> <ul> <li>IAMFullAccess: Enables creation and management of IAM roles and policies required for cluster operation</li> <li>AmazonVPCFullAccess: Allows creation and configuration of VPC resources including subnets, route tables, internet gateways, and NAT gateways</li> <li>AWSCloudFormationFullAccess: Provides permissions to create, update, and delete CloudFormation stacks that orchestrate the deployment</li> <li>EKS Full Access (provided below): Required for creating and managing EKS clusters, including control plane configuration, node groups, and add-ons    <code>{     \"Version\": \"2012-10-17\",     \"Statement\": [       {         \"Effect\": \"Allow\",         \"Action\": \"eks:*\",         \"Resource\": \"*\"       }     ]   }</code></li> </ul> <p>Important Security Note: Users should exercise caution when <code>--allow-write</code> and <code>--allow-sensitive-data-access</code> modes are enabled with these broad permissions, as this combination grants significant privileges to the MCP server. Only enable these flags when necessary and in trusted environments. For production use, consider creating more restrictive custom policies.</p>"},{"location":"servers/eks-mcp-server/#kubernetes-api-access-requirements","title":"Kubernetes API Access Requirements","text":"<p>All Kubernetes API operations will only work when one of the following conditions is met:</p> <ol> <li>The user's principal (IAM role/user) actually created the EKS cluster being accessed</li> <li>An EKS Access Entry has been configured for the user's principal</li> </ol> <p>If you encounter authorization errors when using Kubernetes API operations, verify that an access entry has been properly configured for your principal.</p>"},{"location":"servers/eks-mcp-server/#quickstart","title":"Quickstart","text":"<p>This quickstart guide walks you through the steps to configure the Amazon EKS MCP Server for use with both the Cursor IDE and the Amazon Q Developer CLI. By following these steps, you'll setup your development environment to leverage the EKS MCP Server's tools for managing your Amazon EKS clusters and Kubernetes resources.</p> <p>Set up Cursor</p> <ol> <li>Open Cursor.</li> <li>Click the gear icon (\u2699\ufe0f) in the top right to open the settings panel, click MCP, Add new global MCP server.</li> <li>Paste your MCP server definition. For example, this example shows how to configure the EKS MCP Server, including enabling mutating actions by adding the <code>--allow-write</code> flag to the server arguments:</li> </ol> <p>For Mac/Linux:</p> <pre><code>```\n{\n  \"mcpServers\": {\n    \"awslabs.eks-mcp-server\": {\n      \"autoApprove\": [],\n      \"disabled\": false,\n      \"command\": \"uvx\",\n      \"args\": [\n        \"awslabs.eks-mcp-server@latest\",\n        \"--allow-write\"\n      ],\n      \"env\": {\n        \"FASTMCP_LOG_LEVEL\": \"ERROR\"\n      },\n      \"transportType\": \"stdio\"\n    }\n  }\n}\n```\n</code></pre> <p>For Windows:</p> <pre><code>```\n{\n  \"mcpServers\": {\n    \"awslabs.eks-mcp-server\": {\n      \"autoApprove\": [],\n      \"disabled\": false,\n      \"command\": \"uvx\",\n      \"args\": [\n        \"--from\",\n        \"awslabs.eks-mcp-server@latest\",\n        \"awslabs.eks-mcp-server.exe\",\n        \"--allow-write\"\n      ],\n      \"env\": {\n        \"FASTMCP_LOG_LEVEL\": \"ERROR\"\n      },\n      \"transportType\": \"stdio\"\n    }\n  }\n}\n```\n\nAfter a few minutes, you should see a green indicator if your MCP server definition is valid.\n</code></pre> <ol> <li>Open a chat panel in Cursor (e.g., <code>Ctrl/\u2318 + L</code>).  In your Cursor chat window, enter your prompt. For example, \"Create a new EKS cluster named 'my-test-cluster' in the 'us-west-2' region using Kubernetes version 1.31.\"</li> </ol> <p>Set up the Amazon Q Developer CLI</p> <ol> <li>Install the Amazon Q Developer CLI .</li> <li>The Q Developer CLI supports MCP servers for tools and prompts out-of-the-box. Edit your Q developer CLI's MCP configuration file named mcp.json following these instructions. For example:</li> </ol> <p>For Mac/Linux:</p> <pre><code>```\n{\n  \"mcpServers\": {\n    \"awslabs.eks-mcp-server\": {\n      \"command\": \"uvx\",\n      \"args\": [\"awslabs.eks-mcp-server@latest\"],\n      \"env\": {\n        \"FASTMCP_LOG_LEVEL\": \"ERROR\"\n      },\n      \"autoApprove\": [],\n      \"disabled\": false\n    }\n  }\n}\n```\n</code></pre> <p>For Windows:</p> <pre><code>```\n{\n  \"mcpServers\": {\n    \"awslabs.eks-mcp-server\": {\n      \"command\": \"uvx\",\n      \"args\": [\"--from\", \"awslabs.eks-mcp-server@latest\", \"awslabs.eks-mcp-server.exe\"],\n      \"env\": {\n        \"FASTMCP_LOG_LEVEL\": \"ERROR\"\n      },\n      \"autoApprove\": [],\n      \"disabled\": false\n    }\n  }\n}\n```\n</code></pre> <ol> <li>Verify your setup by running the <code>/tools</code> command in the Q Developer CLI to see the available EKS MCP tools.</li> </ol> <p>Note that this is a basic quickstart. You can enable additional capabilities, such as running MCP servers in containers or combining more MCP servers like the AWS Documentation MCP Server into a single MCP server definition. To view an example, see the Installation and Setup guide in AWS MCP Servers on GitHub. To view a real-world implementation with application code in context with an MCP server, see the Server Developer guide in Anthropic documentation.</p>"},{"location":"servers/eks-mcp-server/#configurations","title":"Configurations","text":""},{"location":"servers/eks-mcp-server/#arguments","title":"Arguments","text":"<p>The <code>args</code> field in the MCP server definition specifies the command-line arguments passed to the server when it starts. These arguments control how the server is executed and configured. For example:</p> <p>For Mac/Linux: <pre><code>{\n  \"mcpServers\": {\n    \"awslabs.eks-mcp-server\": {\n      \"command\": \"uvx\",\n      \"args\": [\n        \"awslabs.eks-mcp-server@latest\",\n        \"--allow-write\",\n        \"--allow-sensitive-data-access\"\n      ],\n      \"env\": {\n        \"AWS_PROFILE\": \"your-profile\",\n        \"AWS_REGION\": \"us-east-1\"\n      }\n    }\n  }\n}\n</code></pre></p> <p>For Windows: <pre><code>{\n  \"mcpServers\": {\n    \"awslabs.eks-mcp-server\": {\n      \"command\": \"uvx\",\n      \"args\": [\n        \"--from\",\n        \"awslabs.eks-mcp-server@latest\",\n        \"awslabs.eks-mcp-server.exe\",\n        \"--allow-write\",\n        \"--allow-sensitive-data-access\"\n      ],\n      \"env\": {\n        \"AWS_PROFILE\": \"your-profile\",\n        \"AWS_REGION\": \"us-east-1\"\n      }\n    }\n  }\n}\n</code></pre></p>"},{"location":"servers/eks-mcp-server/#command-format","title":"Command Format","text":"<p>The command format differs between operating systems:</p> <p>For Mac/Linux: * <code>awslabs.eks-mcp-server@latest</code> - Specifies the latest package/version specifier for the MCP client config.</p> <p>For Windows: * <code>--from awslabs.eks-mcp-server@latest awslabs.eks-mcp-server.exe</code> - Windows requires the <code>--from</code> flag to specify the package and the <code>.exe</code> extension.</p> <p>Both formats enable MCP server startup and tool registration.</p>"},{"location":"servers/eks-mcp-server/#-allow-write-optional","title":"<code>--allow-write</code> (optional)","text":"<p>Enables write access mode, which allows mutating operations (e.g., create, update, delete resources) for apply_yaml, generate_app_manifest, manage_k8s_resource, manage_eks_stacks, add_inline_policy tool operations.</p> <ul> <li>Default: false (The server runs in read-only mode by default)</li> <li>Example: Add <code>--allow-write</code> to the <code>args</code> list in your MCP server definition.</li> </ul>"},{"location":"servers/eks-mcp-server/#-allow-sensitive-data-access-optional","title":"<code>--allow-sensitive-data-access</code> (optional)","text":"<p>Enables access to sensitive data such as logs, events, and Kubernetes Secrets.</p> <ul> <li>Default: false (Access to sensitive data is restricted by default)</li> <li>Example: Add <code>--allow-sensitive-data-access</code> to the <code>args</code> list in your MCP server definition.</li> </ul>"},{"location":"servers/eks-mcp-server/#environment-variables","title":"Environment variables","text":"<p>The <code>env</code> field in the MCP server definition allows you to configure environment variables that control the behavior of the EKS MCP server.  For example:</p> <pre><code>{\n  \"mcpServers\": {\n    \"awslabs.eks-mcp-server\": {\n      \"env\": {\n        \"FASTMCP_LOG_LEVEL\": \"ERROR\",\n        \"AWS_PROFILE\": \"my-profile\",\n        \"AWS_REGION\": \"us-west-2\"\n      }\n    }\n  }\n}\n</code></pre>"},{"location":"servers/eks-mcp-server/#fastmcp_log_level-optional","title":"<code>FASTMCP_LOG_LEVEL</code> (optional)","text":"<p>Sets the logging level verbosity for the server.</p> <ul> <li>Valid values: \"DEBUG\", \"INFO\", \"WARNING\", \"ERROR\", \"CRITICAL\"</li> <li>Default: \"WARNING\"</li> <li>Example: <code>\"FASTMCP_LOG_LEVEL\": \"ERROR\"</code></li> </ul>"},{"location":"servers/eks-mcp-server/#aws_profile-optional","title":"<code>AWS_PROFILE</code> (optional)","text":"<p>Specifies the AWS profile to use for authentication.</p> <ul> <li>Default: None (If not set, uses default AWS credentials).</li> <li>Example: <code>\"AWS_PROFILE\": \"my-profile\"</code></li> </ul>"},{"location":"servers/eks-mcp-server/#aws_region-optional","title":"<code>AWS_REGION</code> (optional)","text":"<p>Specifies the AWS region where EKS clusters are managed, which will be used for all AWS service operations.</p> <ul> <li>Default: None (If not set, uses default AWS region).</li> <li>Example: <code>\"AWS_REGION\": \"us-west-2\"</code></li> </ul>"},{"location":"servers/eks-mcp-server/#tools","title":"Tools","text":"<p>The following tools are provided by the EKS MCP server for managing Amazon EKS clusters and Kubernetes resources. Each tool performs a specific action that can be invoked to automate common tasks in your EKS clusters and Kubernetes workloads.</p>"},{"location":"servers/eks-mcp-server/#eks-cluster-management","title":"EKS Cluster Management","text":""},{"location":"servers/eks-mcp-server/#manage_eks_stacks","title":"<code>manage_eks_stacks</code>","text":"<p>Manages EKS CloudFormation stacks with operations for generating templates, deploying, describing, and deleting EKS clusters and their underlying infrastructure. Note: Cluster creation typically takes 15-20 minutes to complete.</p> <p>Features:</p> <ul> <li>Generates CloudFormation templates for EKS clusters, embedding specified cluster names.</li> <li>Deploys EKS clusters using CloudFormation, creating or updating stacks with VPC, subnets, NAT gateways, IAM roles, and node pools.</li> <li>Describes existing EKS CloudFormation stacks, providing details like status, outputs, and creation time.</li> <li>Deletes EKS CloudFormation stacks and their associated resources, ensuring proper cleanup.</li> <li>Ensures safety by only modifying/deleting stacks that were originally created by this tool.</li> </ul> <p>Parameters:</p> <ul> <li>operation (generate, deploy, describe, delete), template_file (for generate/deploy), cluster_name</li> </ul>"},{"location":"servers/eks-mcp-server/#kubernetes-resource-management","title":"Kubernetes Resource Management","text":""},{"location":"servers/eks-mcp-server/#manage_k8s_resource","title":"<code>manage_k8s_resource</code>","text":"<p>Manages individual Kubernetes resources with various operations.</p> <p>Features:</p> <ul> <li>Supports create, replace, patch, delete, and read Kubernetes operations.</li> <li>Handles both namespaced and non-namespaced Kubernetes resources.</li> </ul> <p>Parameters:</p> <ul> <li>operation (create, replace, patch, delete, read), cluster_name, kind, api_version, name, namespace (optional), body (for create/replace/patch)</li> </ul>"},{"location":"servers/eks-mcp-server/#apply_yaml","title":"<code>apply_yaml</code>","text":"<p>Applies Kubernetes YAML manifests to an EKS cluster.</p> <p>Features:</p> <ul> <li>Supports multi-document YAML files.</li> <li>Applies all resources in the manifest to the specified namespace.</li> <li>Can update existing resources if force is true.</li> </ul> <p>Parameters:</p> <ul> <li>yaml_path, cluster_name, namespace, force</li> </ul>"},{"location":"servers/eks-mcp-server/#list_k8s_resources","title":"<code>list_k8s_resources</code>","text":"<p>Lists Kubernetes resources of a specific kind in an EKS cluster.</p> <p>Features:</p> <ul> <li>Returns summaries of EKS resources with metadata.</li> <li>Supports filtering by EKS cluster namespace, labels, and fields.</li> </ul> <p>Parameters:</p> <ul> <li>cluster_name, kind, api_version, namespace (optional), label_selector (optional), field_selector (optional)</li> </ul>"},{"location":"servers/eks-mcp-server/#list_api_versions","title":"<code>list_api_versions</code>","text":"<p>Lists all available API versions in the specified Kubernetes cluster.</p> <p>Features:</p> <ul> <li>Discovers all available API versions on the Kubernetes cluster.</li> <li>Helps determine the correct <code>apiVersion</code> to use for managing Kubernetes resources.</li> <li>Includes both core APIs (e.g., \"v1\") and API groups (e.g., \"apps/v1\", \"networking.k8s.io/v1\").</li> </ul> <p>Parameters:</p> <ul> <li>cluster_name</li> </ul>"},{"location":"servers/eks-mcp-server/#application-support","title":"Application Support","text":""},{"location":"servers/eks-mcp-server/#generate_app_manifest","title":"<code>generate_app_manifest</code>","text":"<p>Generates Kubernetes manifests for application deployment.</p> <p>Features:</p> <ul> <li>Generates Kubernetes deployment and service YAMLs with configurable parameters.</li> <li>Supports load balancer configuration and resource requests.</li> <li>Outputs Kubernetes manifest to a specified directory.</li> </ul> <p>Parameters:</p> <ul> <li>app_name, image_uri, output_dir, port (optional), replicas (optional), cpu (optional), memory (optional), namespace (optional), load_balancer_scheme (optional)</li> </ul>"},{"location":"servers/eks-mcp-server/#get_pod_logs","title":"<code>get_pod_logs</code>","text":"<p>Retrieves logs from pods in a Kubernetes cluster.</p> <p>Features:</p> <ul> <li>Supports filtering logs by time, line count, and byte size.</li> <li>Can retrieve logs from specific containers in a pod.</li> <li>Requires <code>--allow-sensitive-data-access</code> server flag to be enabled.</li> </ul> <p>Parameters:</p> <ul> <li>cluster_name, pod_name, namespace, container_name (optional), since_seconds (optional), tail_lines (optional), limit_bytes (optional)</li> </ul>"},{"location":"servers/eks-mcp-server/#get_k8s_events","title":"<code>get_k8s_events</code>","text":"<p>Retrieves events related to specific Kubernetes resources.</p> <p>Features:</p> <ul> <li>Returns Kubernetes event details including timestamps, count, message, reason, reporting component, and type.</li> <li>Supports both namespaced and non-namespaced Kubernetes resources.</li> <li>Requires <code>--allow-sensitive-data-access</code> server flag to be enabled.</li> </ul> <p>Parameters:</p> <ul> <li>cluster_name, kind, name, namespace (optional)</li> </ul>"},{"location":"servers/eks-mcp-server/#cloudwatch-integration","title":"CloudWatch Integration","text":""},{"location":"servers/eks-mcp-server/#get_cloudwatch_logs","title":"<code>get_cloudwatch_logs</code>","text":"<p>Retrieves logs from CloudWatch for a specific resource within an EKS cluster.</p> <p>Features:</p> <ul> <li>Fetches logs based on resource type (pod, node, container), resource name, and log type.</li> <li>Allows filtering by time range (minutes, start/end time), log content (filter_pattern), and number of entries.</li> <li>Supports specifying custom fields to be included in the query results.</li> <li>Requires <code>--allow-sensitive-data-access</code> server flag to be enabled.</li> </ul> <p>Parameters:</p> <ul> <li>cluster_name, log_type (application, host, performance, control-plane, custom), resource_type (pod, node, container, cluster), resource_name (optional), minutes (optional), start_time (optional), end_time (optional), limit (optional), filter_pattern (optional), fields (optional)</li> </ul>"},{"location":"servers/eks-mcp-server/#get_cloudwatch_metrics","title":"<code>get_cloudwatch_metrics</code>","text":"<p>Retrieves metrics from CloudWatch for Kubernetes resources.</p> <p>Features:</p> <ul> <li>Fetches metrics based on metric name and dimensions.</li> <li>Allows specification of CloudWatch namespace and time range.</li> <li>Configurable period, statistic (Average, Sum, etc.), and limit for data points.</li> <li>Supports providing custom dimensions for fine-grained metric querying.</li> </ul> <p>Parameters:</p> <ul> <li>cluster_name, metric_name, namespace, dimensions, minutes (optional), start_time (optional), end_time (optional), limit (optional), stat (optional), period (optional)</li> </ul>"},{"location":"servers/eks-mcp-server/#get_eks_metrics_guidance","title":"<code>get_eks_metrics_guidance</code>","text":"<p>Provides guidance on available CloudWatch metrics for different resource types in EKS clusters.</p> <p>Features:</p> <ul> <li>Returns a list of available Container Insights metrics for the specified resource type, including metric names, dimensions, and descriptions.</li> <li>Helps determine the correct dimensions to use with the <code>get_cloudwatch_metrics</code> tool.</li> <li>Supports the following resource types:</li> <li><code>cluster</code>: Metrics for EKS clusters (e.g., cluster_node_count, cluster_failed_node_count)</li> <li><code>node</code>: Metrics for EKS nodes (e.g., node_cpu_utilization, node_memory_utilization, node_network_total_bytes)</li> <li><code>pod</code>: Metrics for Kubernetes pods (e.g., pod_cpu_utilization, pod_memory_utilization, pod_network_rx_bytes)</li> <li><code>namespace</code>: Metrics for Kubernetes namespaces (e.g., namespace_number_of_running_pods)</li> <li><code>service</code>: Metrics for Kubernetes services (e.g., service_number_of_running_pods)</li> </ul> <p>Parameters:</p> <ul> <li>resource_type</li> </ul> <p>Implementation:</p> <p>The data in <code>/awslabs/eks_mcp_server/data/eks_cloudwatch_metrics_guidance.json</code> is generated by a Python script (<code>/awslabs/eks_mcp_server/scripts/update_eks_cloudwatch_metrics_guidance.py</code>) that scrapes the Container Insights metrics table from AWS documentation. Running the script requires installing BeautifulSoup (used for parsing HTML content) with uv: <code>uv pip install bs4</code>.</p>"},{"location":"servers/eks-mcp-server/#iam-integration","title":"IAM Integration","text":""},{"location":"servers/eks-mcp-server/#get_policies_for_role","title":"<code>get_policies_for_role</code>","text":"<p>Retrieves all policies attached to a specified IAM role, including assume role policy, managed policies, and inline policies.</p> <p>Features:</p> <ul> <li>Fetches the assume role policy document for the specified IAM role.</li> <li>Lists all attached managed policies and includes their policy documents.</li> <li>Lists all embedded inline policies and includes their policy documents.</li> </ul> <p>Parameters:</p> <ul> <li>role_name</li> </ul>"},{"location":"servers/eks-mcp-server/#add_inline_policy","title":"<code>add_inline_policy</code>","text":"<p>Adds a new inline policy with specified permissions to an IAM role; it will not modify existing policies. It will only create new policies; it will reject requests to modify existing policies.</p> <p>Features:</p> <ul> <li>Creates and attaches a new inline policy to a specified IAM role.</li> <li>Rejects requests if the policy name already exists on the role to prevent accidental modification.</li> <li>Requires <code>--allow-write</code> server flag to be enabled.</li> <li>Accepts permissions as a single JSON object (statement) or a list of JSON objects (statements).</li> </ul> <p>Parameters:</p> <ul> <li>policy_name, role_name, permissions (JSON object or array of objects)</li> </ul>"},{"location":"servers/eks-mcp-server/#troubleshooting","title":"Troubleshooting","text":""},{"location":"servers/eks-mcp-server/#search_eks_troubleshoot_guide","title":"<code>search_eks_troubleshoot_guide</code>","text":"<p>Searches the EKS Troubleshoot Guide for troubleshooting information based on a query.</p> <p>Features:</p> <ul> <li>Provides detailed troubleshooting guidance for Amazon EKS issues.</li> <li>Covers EKS Auto mode node provisioning, bootstrap issues, and controller failure modes.</li> <li>Returns symptoms, step-by-step short-term, and long-term fixes for identified issues.</li> </ul> <p>Parameters:</p> <ul> <li>query</li> </ul>"},{"location":"servers/eks-mcp-server/#security-permissions","title":"Security &amp; permissions","text":""},{"location":"servers/eks-mcp-server/#features","title":"Features","text":"<p>The EKS MCP Server implements the following security features:</p> <ol> <li>AWS Authentication: Uses AWS credentials from the environment for secure authentication.</li> <li>Kubernetes Authentication: Generates temporary credentials for Kubernetes API access.</li> <li>SSL Verification: Enforces SSL verification for all Kubernetes API calls.</li> <li>Resource Tagging: Tags all created resources for traceability.</li> <li>Least Privilege: Uses IAM roles with appropriate permissions for CloudFormation templates.</li> <li>Stack Protection: Ensures CloudFormation stacks can only be modified by the tool that created them.</li> <li>Client Caching: Caches Kubernetes clients with TTL-based expiration for security and performance.</li> </ol>"},{"location":"servers/eks-mcp-server/#considerations","title":"Considerations","text":"<p>When using the EKS MCP Server, consider the following:</p> <ul> <li>AWS Credentials: The server needs permission to create and manage EKS resources.</li> <li>Kubernetes Access: The server generates temporary credentials for Kubernetes API access.</li> <li>Network Security: Configure VPC and security groups properly for EKS clusters.</li> <li>Authentication: Use appropriate authentication mechanisms for Kubernetes resources.</li> <li>Authorization: Configure RBAC properly for Kubernetes resources.</li> <li>Data Protection: Encrypt sensitive data in Kubernetes secrets.</li> <li>Logging and Monitoring: Enable logging and monitoring for EKS clusters.</li> </ul>"},{"location":"servers/eks-mcp-server/#permissions","title":"Permissions","text":"<p>The EKS MCP Server can be used for production environments with proper security controls in place. The server runs in read-only mode by default, which is recommended and considered generally safer for production environments. Only explicitly enable write access when necessary. Below are the EKS MCP server tools available in read-only versus write-access mode:</p> <ul> <li>Read-only mode (default): <code>manage_eks_stacks</code> (with operation=\"describe\"), <code>manage_k8s_resource</code> (with operation=\"read\"), <code>list_k8s_resources</code>, <code>get_pod_logs</code>, <code>get_k8s_events</code>, <code>get_cloudwatch_logs</code>, <code>get_cloudwatch_metrics</code>, <code>get_policies_for_role</code>, <code>search_eks_troubleshoot_guide</code>, <code>list_api_versions</code>.</li> <li>Write-access mode: (require <code>--allow-write</code>): <code>manage_eks_stacks</code> (with \"generate\", \"deploy\", \"delete\"), <code>manage_k8s_resource</code> (with \"create\", \"replace\", \"patch\", \"delete\"), <code>apply_yaml</code>, <code>generate_app_manifest</code>, <code>add_inline_policy</code>.</li> </ul>"},{"location":"servers/eks-mcp-server/#autoapprove-optional","title":"<code>autoApprove</code> (optional)","text":"<p>An array within the MCP server definition that lists tool names to be automatically approved by the EKS MCP Server client, bypassing user confirmation for those specific tools. For example:</p> <p>For Mac/Linux: <pre><code>{\n  \"mcpServers\": {\n    \"awslabs.eks-mcp-server\": {\n      \"command\": \"uvx\",\n      \"args\": [\n        \"awslabs.eks-mcp-server@latest\"\n      ],\n      \"env\": {\n        \"AWS_PROFILE\": \"eks-mcp-readonly-profile\",\n        \"AWS_REGION\": \"us-east-1\",\n        \"FASTMCP_LOG_LEVEL\": \"INFO\"\n      },\n      \"autoApprove\": [\n        \"manage_eks_stacks\",\n        \"manage_k8s_resource\",\n        \"list_k8s_resources\",\n        \"get_pod_logs\",\n        \"get_k8s_events\",\n        \"get_cloudwatch_logs\",\n        \"get_cloudwatch_metrics\",\n        \"get_policies_for_role\",\n        \"search_eks_troubleshoot_guide\",\n        \"list_api_versions\"\n      ]\n    }\n  }\n}\n</code></pre></p> <p>For Windows: <pre><code>{\n  \"mcpServers\": {\n    \"awslabs.eks-mcp-server\": {\n      \"command\": \"uvx\",\n      \"args\": [\n        \"--from\",\n        \"awslabs.eks-mcp-server@latest\",\n        \"awslabs.eks-mcp-server.exe\"\n      ],\n      \"env\": {\n        \"AWS_PROFILE\": \"eks-mcp-readonly-profile\",\n        \"AWS_REGION\": \"us-east-1\",\n        \"FASTMCP_LOG_LEVEL\": \"INFO\"\n      },\n      \"autoApprove\": [\n        \"manage_eks_stacks\",\n        \"manage_k8s_resource\",\n        \"list_k8s_resources\",\n        \"get_pod_logs\",\n        \"get_k8s_events\",\n        \"get_cloudwatch_logs\",\n        \"get_cloudwatch_metrics\",\n        \"get_policies_for_role\",\n        \"search_eks_troubleshoot_guide\",\n        \"list_api_versions\"\n      ]\n    }\n  }\n}\n</code></pre></p>"},{"location":"servers/eks-mcp-server/#iam-permissions-management","title":"IAM Permissions Management","text":"<p>When the <code>--allow-write</code> flag is enabled, the EKS MCP Server can create missing IAM permissions for EKS resources through the <code>add_inline_policy</code> tool. This tool enables the following:</p> <ul> <li>Only creates new inline policies; it never modifies existing policies.</li> <li>Is useful for automatically fixing common permissions issues with EKS clusters.</li> <li>Should be used with caution and with properly scoped IAM roles.</li> </ul>"},{"location":"servers/eks-mcp-server/#role-scoping-recommendations","title":"Role Scoping Recommendations","text":"<p>In accordance with security best practices, we recommend the following:</p> <ol> <li>Create dedicated IAM roles to be used by the EKS MCP Server with the principle of \"least privilege.\"</li> <li>Use separate roles for read-only and write operations.</li> <li>Implement resource tagging to limit actions to resources created by the server.</li> <li>Enable AWS CloudTrail to audit all API calls made by the server.</li> <li>Regularly review the permissions granted to the server's IAM role.</li> <li>Use IAM Access Analyzer to identify unused permissions that can be removed.</li> </ol>"},{"location":"servers/eks-mcp-server/#sensitive-information-handling","title":"Sensitive Information Handling","text":"<p>IMPORTANT: Do not pass secrets or sensitive information via allowed input mechanisms:</p> <ul> <li>Do not include secrets or credentials in YAML files applied with <code>apply_yaml</code>.</li> <li>Do not pass sensitive information directly in the prompt to the model.</li> <li>Do not include secrets in CloudFormation templates or application manifests.</li> <li>Avoid using MCP tools for creating Kubernetes Secrets, as this would require providing the secret data to the model.</li> </ul> <p>YAML Content Security:</p> <ul> <li>Only use YAML files from trustworthy sources.</li> <li>The server relies on Kubernetes API validation for YAML content and does not perform its own validation.</li> <li>Audit YAML files before applying them to your cluster.</li> </ul> <p>Instead of passing secrets through MCP:</p> <ul> <li>Use AWS Secrets Manager or Parameter Store to store sensitive information.</li> <li>Configure proper Kubernetes RBAC for service accounts.</li> <li>Use IAM roles for service accounts (IRSA) for AWS service access from pods.</li> </ul>"},{"location":"servers/eks-mcp-server/#general-best-practices","title":"General Best Practices","text":"<ul> <li>Resource Naming: Use descriptive names for EKS clusters and Kubernetes resources.</li> <li>Namespace Usage: Organize resources into namespaces for better management.</li> <li>Error Handling: Check for errors in tool responses and handle them appropriately.</li> <li>Resource Cleanup: Delete unused resources to avoid unnecessary costs.</li> <li>Monitoring: Monitor cluster and resource status regularly.</li> <li>Security: Follow AWS security best practices for EKS clusters.</li> <li>Backup: Regularly backup important Kubernetes resources.</li> </ul>"},{"location":"servers/eks-mcp-server/#general-troubleshooting","title":"General Troubleshooting","text":"<ul> <li>Permission Errors: Verify that your AWS credentials have the necessary permissions.</li> <li>CloudFormation Errors: Check the CloudFormation console for stack creation errors.</li> <li>Kubernetes API Errors: Verify that the EKS cluster is running and accessible.</li> <li>Network Issues: Check VPC and security group configurations.</li> <li>Client Errors: Verify that the MCP client is configured correctly.</li> <li>Log Level: Increase the log level to DEBUG for more detailed logs.</li> </ul> <p>For general EKS issues, consult the Amazon EKS documentation.</p>"},{"location":"servers/eks-mcp-server/#version","title":"Version","text":"<p>Current MCP server version: 0.1.0</p>"},{"location":"servers/elasticache-mcp-server/","title":"AWS ElastiCache MCP Server","text":"<p>The official MCP Server for interacting with AWS ElastiCache</p>"},{"location":"servers/elasticache-mcp-server/#available-mcp-tools","title":"Available MCP Tools","text":""},{"location":"servers/elasticache-mcp-server/#replication-group-operations","title":"Replication Group Operations","text":"<ul> <li><code>create-replication-group</code> - Create an Amazon ElastiCache replication group with specified configuration</li> <li><code>delete-replication-group</code> - Delete an ElastiCache replication group with optional final snapshot</li> <li><code>describe-replication-groups</code> - Get detailed information about one or more replication groups</li> <li><code>modify-replication-group</code> - Modify settings of an existing replication group</li> <li><code>modify-replication-group-shard-configuration</code> - Modify the shard configuration of a replication group</li> <li><code>test-migration</code> - Test migration from a Redis instance to an ElastiCache replication group</li> <li><code>start-migration</code> - Start migration from a Redis instance to an ElastiCache replication group</li> <li><code>complete-migration</code> - Complete migration from a Redis instance to an ElastiCache replication group</li> <li><code>connect-jump-host-replication-group</code> - Configure an EC2 instance as a jump host for replication group access</li> <li><code>create-jump-host-replication-group</code> - Create an EC2 jump host to access a replication group via SSH tunnel</li> <li><code>get-ssh-tunnel-command-replication-group</code> - Generate SSH tunnel command for replication group access</li> </ul>"},{"location":"servers/elasticache-mcp-server/#cache-cluster-operations","title":"Cache Cluster Operations","text":"<ul> <li><code>create-cache-cluster</code> - Create a new ElastiCache cache cluster</li> <li><code>delete-cache-cluster</code> - Delete a cache cluster with optional final snapshot</li> <li><code>describe-cache-clusters</code> - Get detailed information about one or more cache clusters</li> <li><code>modify-cache-cluster</code> - Modify settings of an existing cache cluster</li> <li><code>connect-jump-host-cache-cluster</code> - Configure an EC2 instance as a jump host for cluster access</li> <li><code>create-jump-host-cache-cluster</code> - Create an EC2 jump host to access a cluster via SSH tunnel</li> <li><code>get-ssh-tunnel-command-cache-cluster</code> - Generate SSH tunnel command for cluster access</li> </ul>"},{"location":"servers/elasticache-mcp-server/#serverless-cache-operations","title":"Serverless Cache Operations","text":"<ul> <li><code>create-serverless-cache</code> - Create a new ElastiCache serverless cache</li> <li><code>delete-serverless-cache</code> - Delete a serverless cache</li> <li><code>describe-serverless-caches</code> - Get information about serverless caches</li> <li><code>modify-serverless-cache</code> - Modify settings of a serverless cache</li> <li><code>connect-jump-host-serverless-cache</code> - Configure an EC2 instance as a jump host for serverless cache access</li> <li><code>create-jump-host-serverless-cache</code> - Create an EC2 jump host to access a serverless cache via SSH tunnel</li> <li><code>get-ssh-tunnel-command-serverless-cache</code> - Generate SSH tunnel command for serverless cache access</li> </ul>"},{"location":"servers/elasticache-mcp-server/#cloudwatch-operations","title":"CloudWatch Operations","text":"<ul> <li><code>get-metric-statistics</code> - Get CloudWatch metric statistics for ElastiCache resources with customizable time periods and dimensions</li> </ul>"},{"location":"servers/elasticache-mcp-server/#cloudwatch-logs-operations","title":"CloudWatch Logs Operations","text":"<ul> <li><code>describe-log-groups</code> - List and describe CloudWatch Logs log groups</li> <li><code>create-log-group</code> - Create a new CloudWatch Logs log group</li> <li><code>describe-log-streams</code> - List and describe log streams in a log group</li> <li><code>filter-log-events</code> - Search and filter log events across log streams</li> <li><code>get-log-events</code> - Retrieve log events from a specific log stream</li> </ul>"},{"location":"servers/elasticache-mcp-server/#firehose-operations","title":"Firehose Operations","text":"<ul> <li><code>list-delivery-streams</code> - List your Kinesis Data Firehose delivery streams</li> </ul>"},{"location":"servers/elasticache-mcp-server/#cost-explorer-operations","title":"Cost Explorer Operations","text":"<ul> <li><code>get-cost-and-usage</code> - Get cost and usage data for ElastiCache resources with customizable time periods and granularity</li> </ul>"},{"location":"servers/elasticache-mcp-server/#misc-operations","title":"Misc Operations","text":"<ul> <li><code>describe-cache-engine-versions</code> - List available cache engines and their versions</li> <li><code>describe-engine-default-parameters</code> - Get default parameters for a cache engine family</li> <li><code>describe-events</code> - Get events related to clusters, security groups, and parameters</li> <li><code>describe-service-updates</code> - Get information about available service updates</li> <li><code>batch-apply-update-action</code> - Apply service updates to resources</li> <li><code>batch-stop-update-action</code> - Stop service updates on resources</li> </ul>"},{"location":"servers/elasticache-mcp-server/#instructions","title":"Instructions","text":"<p>The official MCP Server for interacting with AWS ElastiCache provides a comprehensive set of tools for managing ElastiCache resources. Each tool maps directly to ElastiCache API operations and supports all relevant parameters.</p> <p>To use these tools, ensure you have proper AWS credentials configured with appropriate permissions for ElastiCache operations. The server will automatically use credentials from environment variables (AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY, AWS_SESSION_TOKEN) or other standard AWS credential sources.</p> <p>All tools support an optional <code>region_name</code> parameter to specify which AWS region to operate in. If not provided, it will use the AWS_REGION environment variable or default to 'us-west-2'.</p>"},{"location":"servers/elasticache-mcp-server/#prerequisites","title":"Prerequisites","text":"<ol> <li>Install <code>uv</code> from Astral or the GitHub README</li> <li>Install Python using <code>uv python install 3.10</code></li> <li>Set up AWS credentials with access to AWS services</li> <li>Consider setting up Read-only permission if you don't want the LLM to modify any resources</li> </ol>"},{"location":"servers/elasticache-mcp-server/#installation","title":"Installation","text":"<p>Add the MCP to your favorite agentic tools. e.g. for Amazon Q Developer CLI MCP, <code>~/.aws/amazonq/mcp.json</code>):</p> <p><pre><code>{\n  \"mcpServers\": {\n    \"awslabs.elasticache-mcp-server\": {\n      \"command\": \"uvx\",\n      \"args\": [\"awslabs.elasticache-mcp-server@latest\"],\n      \"env\": {\n        \"AWS_PROFILE\": \"default\",\n        \"AWS_REGION\": \"us-west-2\",\n        \"FASTMCP_LOG_LEVEL\": \"ERROR\"\n      },\n      \"disabled\": false,\n      \"autoApprove\": []\n    }\n  }\n}\n</code></pre> If you would like to prevent the MCP from taking any mutating actions (i.e. Create/Update/Delete Resource), you can specify the readonly flag as demonstrated below:</p> <pre><code>{\n  \"mcpServers\": {\n    \"awslabs.elasticache-mcp-server\": {\n      \"command\": \"uvx\",\n      \"args\": [\n        \"awslabs.elasticache-mcp-server@latest\",\n        \"--readonly\"\n      ],\n      \"env\": {\n        \"AWS_PROFILE\": \"default\",\n        \"AWS_REGION\": \"us-west-2\",\n        \"FASTMCP_LOG_LEVEL\": \"ERROR\"\n      },\n      \"disabled\": false,\n      \"autoApprove\": []\n    }\n  }\n}\n</code></pre> <p>or docker after a successful <code>docker build -t awslabs/elasticache-mcp-server .</code>:</p> <pre><code>{\n  \"mcpServers\": {\n    \"awslabs.elasticache-mcp-server\": {\n      \"command\": \"docker\",\n      \"args\": [\n        \"run\",\n        \"--rm\",\n        \"--interactive\",\n        \"--env\",\n        \"FASTMCP_LOG_LEVEL=ERROR\",\n        \"awslabs/elasticache-mcp-server:latest\",\n        \"--readonly\" // Optional paramter if you would like to restrict the MCP to only read actions\n      ],\n      \"env\": {},\n      \"disabled\": false,\n      \"autoApprove\": []\n    }\n  }\n}\n</code></pre>"},{"location":"servers/elasticache-mcp-server/#configuration","title":"Configuration","text":""},{"location":"servers/elasticache-mcp-server/#aws-configuration","title":"AWS Configuration","text":"<p>Configure AWS credentials and region:</p> <pre><code># AWS settings\nAWS_PROFILE=default              # AWS credential profile to use\nAWS_REGION=us-east-1            # AWS region to connect to\n</code></pre>"},{"location":"servers/elasticache-mcp-server/#connection-settings","title":"Connection Settings","text":"<p>Configure connection behavior and timeouts:</p> <pre><code># Connection settings\nELASTICACHE_MAX_RETRIES=3        # Maximum number of retry attempts for AWS API calls\nELASTICACHE_RETRY_MODE=standard  # AWS SDK retry mode for API calls\nELASTICACHE_CONNECT_TIMEOUT=5    # Connection timeout in seconds\nELASTICACHE_READ_TIMEOUT=10      # Read timeout in seconds\n\n# Cost Explorer settings\nCOST_EXPLORER_MAX_RETRIES=3      # Maximum number of retry attempts for Cost Explorer API calls\nCOST_EXPLORER_RETRY_MODE=standard # AWS SDK retry mode for Cost Explorer API calls\nCOST_EXPLORER_CONNECT_TIMEOUT=5   # Connection timeout in seconds for Cost Explorer\nCOST_EXPLORER_READ_TIMEOUT=10     # Read timeout in seconds for Cost Explorer\n\n# CloudWatch settings\nCLOUDWATCH_MAX_RETRIES=3         # Maximum number of retry attempts for CloudWatch API calls\nCLOUDWATCH_RETRY_MODE=standard    # AWS SDK retry mode for CloudWatch API calls\nCLOUDWATCH_CONNECT_TIMEOUT=5      # Connection timeout in seconds for CloudWatch\nCLOUDWATCH_READ_TIMEOUT=10        # Read timeout in seconds for CloudWatch\n\n# CloudWatch Logs settings\nCLOUDWATCH_LOGS_MAX_RETRIES=3     # Maximum number of retry attempts for CloudWatch Logs API calls\nCLOUDWATCH_LOGS_RETRY_MODE=standard # AWS SDK retry mode for CloudWatch Logs API calls\nCLOUDWATCH_LOGS_CONNECT_TIMEOUT=5  # Connection timeout in seconds for CloudWatch Logs\nCLOUDWATCH_LOGS_READ_TIMEOUT=10    # Read timeout in seconds for CloudWatch Logs\n\n# Firehose settings\nFIREHOSE_MAX_RETRIES=3            # Maximum number of retry attempts for Firehose API calls\nFIREHOSE_RETRY_MODE=standard      # AWS SDK retry mode for Firehose API calls\nFIREHOSE_CONNECT_TIMEOUT=5        # Connection timeout in seconds for Firehose\nFIREHOSE_READ_TIMEOUT=10          # Read timeout in seconds for Firehose\n</code></pre> <p>The server automatically handles: - AWS authentication and credential management - Connection establishment and management - Automatic retrying of failed operations - Timeout enforcement and error handling</p>"},{"location":"servers/elasticache-mcp-server/#development","title":"Development","text":""},{"location":"servers/elasticache-mcp-server/#running-tests","title":"Running Tests","text":"<pre><code>uv venv\nsource .venv/bin/activate\nuv sync\nuv run --frozen pytest\n</code></pre>"},{"location":"servers/elasticache-mcp-server/#building-docker-image","title":"Building Docker Image","text":"<pre><code>docker build -t awslabs/elasticache-mcp-server .\n</code></pre>"},{"location":"servers/elasticache-mcp-server/#running-docker-container","title":"Running Docker Container","text":"<p>```bash docker run -p 8080:8080 \\   -e AWS_PROFILE=default \\   -e AWS_REGION=us-west-2 \\   awslabs/elasticache-mcp-server</p>"},{"location":"servers/finch-mcp-server/","title":"Finch MCP Server","text":"<p>A Model Context Protocol (MCP) server for Finch that enables generative AI models to build and push container images through finch cli leveraged MCP tools.</p>"},{"location":"servers/finch-mcp-server/#features","title":"Features","text":"<p>This MCP server acts as a bridge between MCP clients and Finch, allowing generative AI models to build and push container images to repositories, and create ECR repositories as needed. The server provides a secure way to interact with Finch, ensuring that the Finch VM is properly initialized and running before performing operations.</p>"},{"location":"servers/finch-mcp-server/#key-capabilities","title":"Key Capabilities","text":"<ul> <li>Build container images using Finch</li> <li>Push container images to repositories, including Amazon ECR</li> <li>Check if ECR repositories exist and create them if needed</li> <li>Automatic management of the Finch VM on macos and windows (initialization, starting, etc.)</li> <li>Automatic configuration of ECR credential helpers when needed (only modifies finch.yaml as config.json is automatically handled)</li> </ul>"},{"location":"servers/finch-mcp-server/#prerequisites","title":"Prerequisites","text":"<ol> <li>Install <code>uv</code> from Astral or the GitHub README</li> <li>Install Python using <code>uv python install 3.10</code></li> <li>Install Finch on your system</li> <li>For ECR operations, AWS credentials with permissions to push to ECR repositories and create/describe ECR repositories</li> </ol>"},{"location":"servers/finch-mcp-server/#setup","title":"Setup","text":""},{"location":"servers/finch-mcp-server/#installation","title":"Installation","text":"<p>Configure the MCP server in your MCP client configuration:</p>"},{"location":"servers/finch-mcp-server/#default-mode-read-only-aws-resources","title":"Default Mode (Read-only AWS Resources)","text":"<p>By default, the server runs in a mode that prevents the creation of new AWS resources. This is useful for environments where you want to limit resource creation or for users who should only be able to build and push to existing repositories.</p> <pre><code>{\n  \"mcpServers\": {\n    \"awslabs.finch-mcp-server\": {\n      \"command\": \"uvx\",\n      \"args\": [\"awslabs.finch-mcp-server@latest\"],\n      \"env\": {\n        \"AWS_PROFILE\": \"default\",\n        \"AWS_REGION\": \"us-west-2\",\n        \"FASTMCP_LOG_LEVEL\": \"INFO\"\n      },\n      \"transportType\": \"stdio\",\n      \"disabled\": false,\n      \"autoApprove\": []\n    }\n  }\n}\n</code></pre> <p>In this default mode: - The <code>finch_build_container_image</code> tools will work normally - The <code>finch_create_ecr_repo</code> and <code>finch_push_image</code> tool will return an error and will not create or modify AWS resources.</p>"},{"location":"servers/finch-mcp-server/#aws-resource-write-mode","title":"AWS Resource Write Mode","text":"<p>The server can also be set to enable AWS resource creation and modification by using the <code>--enable-aws-resource-write</code> flag.</p> <pre><code>{\n  \"mcpServers\": {\n    \"awslabs.finch-mcp-server\": {\n      \"command\": \"uvx\",\n      \"args\": [\n        \"awslabs.finch-mcp-server@latest\",\n        \"--enable-aws-resource-write\"\n      ],\n      \"env\": {\n        \"AWS_PROFILE\": \"default\",\n        \"AWS_REGION\": \"us-west-2\",\n        \"FASTMCP_LOG_LEVEL\": \"INFO\"\n      },\n      \"transportType\": \"stdio\",\n      \"disabled\": false,\n      \"autoApprove\": []\n    }\n  }\n}\n</code></pre>"},{"location":"servers/finch-mcp-server/#available-tools","title":"Available Tools","text":""},{"location":"servers/finch-mcp-server/#finch_build_container_image","title":"<code>finch_build_container_image</code>","text":"<p>Build a container image using Finch.</p> <p>The tool builds a Docker image using the specified Dockerfile and context directory. It supports a range of build options including tags, platforms, and more.</p> <p>Arguments: - <code>dockerfile_path</code> (str): Absolute path to the Dockerfile - <code>context_path</code> (str): Absolute path to the build context directory - <code>tags</code> (List[str], optional): List of tags to apply to the image (e.g., [\"myimage:latest\", \"myimage:v1\"]) - <code>platforms</code> (List[str], optional): List of target platforms (e.g., [\"linux/amd64\", \"linux/arm64\"]) - <code>target</code> (str, optional): Target build stage to build - <code>no_cache</code> (bool, optional): Whether to disable cache. Defaults to False. - <code>pull</code> (bool, optional): Whether to always pull base images. Defaults to False. - <code>build_contexts</code> (List[str], optional): List of additional build contexts - <code>outputs</code> (str, optional): Output destination - <code>cache_from</code> (List[str], optional): List of external cache sources - <code>quiet</code> (bool, optional): Whether to suppress build output. Defaults to False. - <code>progress</code> (str, optional): Type of progress output. Defaults to \"auto\".</p>"},{"location":"servers/finch-mcp-server/#finch_push_image","title":"<code>finch_push_image</code>","text":"<p>Push a container image to a repository using Finch, replacing the tag with the image hash.</p> <p>If the image URL is an ECR repository, it verifies that ECR login credential helper is configured. This tool gets the image hash, creates a new tag using the hash, and pushes the image with the hash tag to the repository.</p> <p>The workflow is: 1. Get the image hash using <code>finch image inspect</code> 2. Create a new tag for the image using the short form of the hash (first 12 characters) 3. Push the hash-tagged image to the repository</p> <p>Arguments: - <code>image</code> (str): The full image name to push, including the repository URL and tag. For ECR repositories, it must follow the format: <code>&lt;aws_account_id&gt;.dkr.ecr.&lt;region&gt;.amazonaws.com/&lt;repository_name&gt;:&lt;tag&gt;</code></p> <p>Example: <pre><code># Original image: myrepo/myimage:latest\n# After processing: myrepo/myimage:1a2b3c4d5e6f (where 1a2b3c4d5e6f is the short hash)\n</code></pre></p>"},{"location":"servers/finch-mcp-server/#finch_create_ecr_repo","title":"<code>finch_create_ecr_repo</code>","text":"<p>Check if an ECR repository exists and create it if it doesn't.</p> <p>This tool checks if the specified ECR repository exists using boto3. If the repository doesn't exist, it creates a new one with the given name with scan on push enabled and immutable tags for enhanced security. The tool requires appropriate AWS credentials configured.</p> <p>Note: When the server is running in readonly mode, this tool will return an error and will not create any AWS resources.</p> <p>Arguments: - <code>app_name</code> (str): The name of the application/repository to check or create in ECR - <code>region</code> (str, optional): AWS region for the ECR repository. If not provided, uses the default region from AWS configuration</p> <p>Example: <pre><code># Check if 'my-app' repository exists in us-west-2 region, create it if it doesn't\n{\n  \"app_name\": \"my-app\",\n  \"region\": \"us-west-2\"\n}\n\n# Response if repository already exists:\n{\n  \"status\": \"success\",\n  \"message\": \"ECR repository 'my-app' already exists.\",\n}\n\n# Response if repository was created:\n{\n  \"status\": \"success\",\n  \"message\": \"Successfully created ECR repository 'my-app'.\",\n}\n\n# Response if server is in readonly mode:\n{\n  \"status\": \"error\",\n  \"message\": \"Server running in read-only mode, unable to perform the action\"\n}\n</code></pre></p>"},{"location":"servers/finch-mcp-server/#best-practices","title":"Best Practices","text":"<ul> <li>Development and Prototyping Only: The tools provided by this MCP server are intended for development and prototyping purposes only. They are not meant for production use cases.</li> <li>Security Considerations: Always review the Dockerfiles and container configurations before building and pushing images.</li> <li>Resource Management: Regularly clean up unused images and containers to free up disk space.</li> <li>Version Control: Keep track of image versions and tags to ensure reproducibility.</li> <li>Error Handling: Implement proper error handling in your applications when using these tools.</li> </ul>"},{"location":"servers/finch-mcp-server/#troubleshooting","title":"Troubleshooting","text":"<ul> <li>If you encounter permission errors with ECR, verify your AWS credentials and boto3 configuration are properly set up</li> <li>For Finch VM issues, try running <code>finch vm stop</code> and then <code>finch vm start</code> manually</li> <li>If the build fails with errors about missing files, check that your context path is correct</li> <li>For general Finch issues, consult the Finch documentation</li> </ul>"},{"location":"servers/finch-mcp-server/#version","title":"Version","text":"<p>Current MCP server version: 0.1.0</p>"},{"location":"servers/frontend-mcp-server/","title":"AWS Labs Frontend MCP Server","text":"<p>A Model Context Protocol (MCP) server that provides specialized tools for modern web application development.</p>"},{"location":"servers/frontend-mcp-server/#features","title":"Features","text":""},{"location":"servers/frontend-mcp-server/#modern-react-application-documentation","title":"Modern React Application Documentation","text":"<p>This MCP Server provides comprehensive documentation on modern React application development through its <code>GetReactDocsByTopic</code> tool, which offers guidance on:</p> <ul> <li>Essential Knowledge: Fundamental concepts for building React applications</li> <li>Basic UI Setup: Setting up a React project with Tailwind CSS and shadcn/ui</li> <li>Authentication: AWS Amplify authentication integration</li> <li>Routing: Implementing routing with React Router</li> <li>Customizing: Theming with AWS Amplify components</li> <li>Creating Components: Building React components with AWS integrations</li> <li>Troubleshooting: Common issues and solutions for React development</li> </ul>"},{"location":"servers/frontend-mcp-server/#prerequisites","title":"Prerequisites","text":"<ol> <li>Install <code>uv</code> from Astral or the GitHub README</li> <li>Install Python using <code>uv python install 3.10</code></li> </ol>"},{"location":"servers/frontend-mcp-server/#installation","title":"Installation","text":"<p>Configure the MCP server in your MCP client configuration (e.g., for Amazon Q Developer CLI, edit <code>~/.aws/amazonq/mcp.json</code>):</p> <pre><code>{\n  \"mcpServers\": {\n    \"awslabs.frontend-mcp-server\": {\n      \"command\": \"uvx\",\n      \"args\": [\"awslabs.frontend-mcp-server@latest\"],\n      \"env\": {\n        \"FASTMCP_LOG_LEVEL\": \"ERROR\"\n      },\n      \"disabled\": false,\n      \"autoApprove\": []\n    }\n  }\n}\n</code></pre>"},{"location":"servers/frontend-mcp-server/#usage","title":"Usage","text":"<p>The Frontend MCP Server provides the <code>GetReactDocsByTopic</code> tool for accessing specialized documentation on modern web application development with AWS technologies. This server will instruct the caller to clone a base web application repo and use that as the starting point for customization.</p>"},{"location":"servers/frontend-mcp-server/#getreactdocsbytopic","title":"GetReactDocsByTopic","text":"<p>This tool retrieves comprehensive documentation on specific React and AWS integration topics. To use it, specify which topic you need information on:</p> <pre><code>result = await get_react_docs_by_topic('essential-knowledge')\n</code></pre> <p>Available topics:</p> <ol> <li>essential-knowledge: Foundational concepts for building React applications with AWS services</li> <li>troubleshooting: Common issues and solutions for React development with AWS integrations</li> </ol> <p>Each topic returns comprehensive markdown documentation with explanations, code examples, and implementation guidance.</p>"},{"location":"servers/git-repo-research-mcp-server/","title":"Git Repo Research MCP Server","text":"<p>Model Context Protocol (MCP) server for researching Git repositories using semantic search</p> <p>This MCP server enables developers to research external Git repositories and influence their code generation without having to clone repositories to local projects. It provides tools to index, search, and explore Git repositories using semantic search powered by Amazon Bedrock and FAISS.</p>"},{"location":"servers/git-repo-research-mcp-server/#features","title":"Features","text":"<ul> <li>Repository Indexing: Create searchable FAISS indexes from local or remote Git repositories</li> <li>Semantic Search: Query repository content using natural language and retrieve relevant code snippets</li> <li>Repository Summary: Get directory structures and identify key files like READMEs</li> <li>GitHub Repository Search: Find repositories in AWS-related organizations filtered by licenses and keywords</li> <li>File Access: Access repository files and directories with support for both text and binary content</li> </ul>"},{"location":"servers/git-repo-research-mcp-server/#prerequisites","title":"Prerequisites","text":""},{"location":"servers/git-repo-research-mcp-server/#installation-requirements","title":"Installation Requirements","text":"<ol> <li>Install <code>uv</code> from Astral or the GitHub README</li> <li>Install Python 3.12 or newer using <code>uv python install 3.12</code></li> <li> <ul> <li>uv - Fast Python package installer and resolver</li> </ul> </li> <li>AWS credentials configured with Bedrock access</li> <li>Node.js (for UVX installation support)</li> </ol>"},{"location":"servers/git-repo-research-mcp-server/#aws-requirements","title":"AWS Requirements","text":"<ol> <li>AWS CLI Configuration: You must have the AWS CLI configured with credentials that have access to Amazon Bedrock</li> <li>Amazon Bedrock Access: Ensure your AWS account has access to embedding models like Titan Embeddings</li> <li>Environment Variables: The server uses <code>AWS_REGION</code> and <code>AWS_PROFILE</code> environment variables</li> </ol>"},{"location":"servers/git-repo-research-mcp-server/#optional-requirements","title":"Optional Requirements","text":"<ol> <li>GitHub Token: Set <code>GITHUB_TOKEN</code> environment variable for higher rate limits when searching GitHub repositories</li> </ol>"},{"location":"servers/git-repo-research-mcp-server/#installation","title":"Installation","text":"<p>To add this MCP server to your Amazon Q or Claude, add the following to your MCP config file:</p> <pre><code>{\n  \"mcpServers\": {\n    \"awslabs.git-repo-research-mcp-server\": {\n      \"command\": \"uvx\",\n      \"args\": [\"awslabs.git-repo-research-mcp-server@latest\"],\n      \"env\": {\n        \"AWS_PROFILE\": \"your-profile-name\",\n        \"AWS_REGION\": \"us-west-2\",\n        \"FASTMCP_LOG_LEVEL\": \"ERROR\",\n        \"GITHUB_TOKEN\": \"your-github-token\"\n      },\n      \"disabled\": false,\n      \"autoApprove\": []\n    }\n  }\n}\n</code></pre>"},{"location":"servers/git-repo-research-mcp-server/#tools","title":"Tools","text":""},{"location":"servers/git-repo-research-mcp-server/#create_research_repository","title":"create_research_repository","text":"<p>Indexes a Git repository (local or remote) using FAISS and Amazon Bedrock embeddings.</p> <pre><code>create_research_repository(\n    repository_path: str,\n    output_path: Optional[str] = None,\n    embedding_model: str = \"amazon.titan-embed-text-v2:0\",\n    include_patterns: Optional[List[str]] = None,\n    exclude_patterns: Optional[List[str]] = None,\n    chunk_size: int = 1000,\n    chunk_overlap: int = 200\n) -&gt; Dict\n</code></pre>"},{"location":"servers/git-repo-research-mcp-server/#search_research_repository","title":"search_research_repository","text":"<p>Performs semantic search within an indexed repository.</p> <pre><code>search_research_repository(\n    index_path: str,\n    query: str,\n    limit: int = 10,\n    threshold: float = 0.0\n) -&gt; Dict\n</code></pre>"},{"location":"servers/git-repo-research-mcp-server/#search_repositories_on_github","title":"search_repositories_on_github","text":"<p>Searches for GitHub repositories based on keywords, scoped to AWS organizations.</p> <pre><code>search_repositories_on_github(\n    keywords: List[str],\n    num_results: int = 5\n) -&gt; Dict\n</code></pre>"},{"location":"servers/git-repo-research-mcp-server/#access_file","title":"access_file","text":"<p>Accesses file or directory contents within repositories or on the filesystem.</p> <pre><code>access_file(\n    filepath: str\n) -&gt; Dict | ImageContent\n</code></pre>"},{"location":"servers/git-repo-research-mcp-server/#delete_research_repository","title":"delete_research_repository","text":"<p>Deletes an indexed repository.</p> <pre><code>delete_research_repository(\n    repository_name_or_path: str,\n    index_directory: Optional[str] = None\n) -&gt; Dict\n</code></pre>"},{"location":"servers/git-repo-research-mcp-server/#resources","title":"Resources","text":""},{"location":"servers/git-repo-research-mcp-server/#repositoriesrepository_namesummary","title":"repositories://{repository_name}/summary","text":"<p>Get a summary of an indexed repository including structure and helpful files.</p> <pre><code>repositories://awslabs_mcp/summary\n</code></pre>"},{"location":"servers/git-repo-research-mcp-server/#repositories","title":"repositories://","text":"<p>List all indexed repositories with detailed information.</p> <pre><code>repositories://\n</code></pre>"},{"location":"servers/git-repo-research-mcp-server/#repositoriesindex_directory","title":"repositories://{index_directory}","text":"<p>List all indexed repositories from a specific index directory.</p> <pre><code>repositories:///path/to/custom/index/directory\n</code></pre>"},{"location":"servers/git-repo-research-mcp-server/#considerations","title":"Considerations","text":"<ul> <li>Repository indexing requires Amazon Bedrock access and sufficient permissions</li> <li>Large repositories may take significant time to index</li> <li>Binary files (except images) are not supported for content viewing</li> <li>GitHub repository search is by default limited to AWS organizations: aws-samples, aws-solutions-library-samples, and awslabs (but can be configured to include other organizations)</li> </ul>"},{"location":"servers/kendra-index-mcp-server/","title":"AWS Labs Amazon Kendra Index MCP Server","text":"<p>An AWS Labs Model Context Protocol (MCP) server for Amazon Kendra. This MCP server allows you to use Kendra Indices as additional context for RAG.</p>"},{"location":"servers/kendra-index-mcp-server/#features","title":"Features:","text":"<ul> <li>Enhance your existing MCP-enabled ChatBot with additional RAG indices</li> <li>Enhance the responses from coding assitants such as Cline, Cursor, Windsurf, Amazon Q Developer, etc.</li> </ul>"},{"location":"servers/kendra-index-mcp-server/#pre-requisites","title":"Pre-Requisites:","text":"<ol> <li>Sign-Up for an AWS account</li> <li>Create an Amazon Kendra Index with your RAG documentation</li> <li>Install <code>uv</code> from Astral or the GitHub README</li> <li>Install Python using <code>uv python install 3.10</code></li> </ol>"},{"location":"servers/kendra-index-mcp-server/#tools","title":"Tools:","text":""},{"location":"servers/kendra-index-mcp-server/#kendraquerytool","title":"KendraQueryTool","text":"<ul> <li>The KendraQueryTool takes the query specified by the user and queries a Kendra index to gain additional context for the response. This queries either the default index, or an index specified in the users prompt.</li> <li>Required Parameters: query (str)</li> <li>Optional Parameters: indexId (str), region (str)</li> <li>Example:<ul> <li><code>Can you help me understand how to implement a progress event in the CreateHandler using Java? Use the KendraQueryTool to gain additional context.</code></li> <li><code>Can you use the test-kendra-index to help answer the following questions...</code></li> </ul> </li> </ul>"},{"location":"servers/kendra-index-mcp-server/#kendralistindexestool","title":"KendraListIndexesTool","text":"<ul> <li>The KendraListIndexesTool lists the Kendra Indexes in your account. By default it will list all the indices in the regions provided as environment variables to the mcp config file. Otherwise the region can bev specified in the prompt.</li> <li>Optional Parameters: region (str)</li> <li>Example:<ul> <li><code>Can you list the Kendra Indexes in my account in the us-west-2 region</code></li> </ul> </li> </ul>"},{"location":"servers/kendra-index-mcp-server/#setup","title":"Setup","text":""},{"location":"servers/kendra-index-mcp-server/#iam-configuration","title":"IAM Configuration","text":"<ol> <li>Provision a user in your AWS account IAM</li> <li>Attach a policy that contains at a minimum the <code>kendra:Query</code> and <code>kendra:ListIndices</code> permissions. Alternatively the AWS Managed <code>AmazonKendraFullAccess</code> policy can be attached. Always follow the principal or least privilege when granting users permissions. See the documentation for more information on IAM permissions for Amazon Kendra.</li> <li>Use <code>aws configure</code> on your environment to configure the credentials (access ID and access key)</li> </ol>"},{"location":"servers/kendra-index-mcp-server/#installation","title":"Installation","text":"<p>Configure the MCP server in your MCP client configuration (e.g., for Amazon Q Developer CLI, edit <code>~/.aws/amazonq/mcp.json</code>):</p> <p><pre><code>{\n      \"mcpServers\": {\n            \"awslabs.amazon-kendra-index-mcp-server\": {\n                  \"command\": \"uvx\",\n                  \"args\": [\"awslabs.amazon-kendra-index-mcp-server\"],\n                  \"env\": {\n                    \"FASTMCP_LOG_LEVEL\": \"ERROR\",\n                    \"KENDRA_INDEX_ID\": \"[Your Kendra Index Id]\",\n                    \"AWS_PROFILE\": \"[Your AWS Profile Name]\",\n                    \"AWS_REGION\": \"[Region where your Kendra Index resides]\"\n                  },\n                  \"disabled\": false,\n                  \"autoApprove\": []\n                }\n      }\n}\n</code></pre> or docker after a successful <code>docker build -t awslabs/amazon-kendra-index-mcp-server.</code>:</p> <pre><code># fictitious `.env` file with AWS temporary credentials\nAWS_ACCESS_KEY_ID=&lt;from the profile you set up&gt;\nAWS_SECRET_ACCESS_KEY=&lt;from the profile you set up&gt;\nAWS_SESSION_TOKEN=&lt;from the profile you set up&gt;\n</code></pre> <p><pre><code>  {\n    \"mcpServers\": {\n      \"awslabs.amazon-kendra-index-mcp-server\": {\n        \"command\": \"docker\",\n        \"args\": [\n          \"run\",\n          \"--rm\",\n          \"--interactive\",\n          \"--env-file\",\n          \"/full/path/to/file/above/.env\",\n          \"awslabs/amazon-kendra-index-mcp-server:latest\"\n        ],\n        \"env\": {},\n        \"disabled\": false,\n        \"autoApprove\": []\n      }\n    }\n  }\n</code></pre> NOTE: Your credentials will need to be kept refreshed from your host</p>"},{"location":"servers/kendra-index-mcp-server/#best-practices","title":"Best Practices","text":"<ul> <li>Follow the principle of least privilege when setting up IAM permissions</li> <li>Use separate AWS profiles for different environments (dev, test, prod)</li> <li>Monitor broker metrics and logs for performance and issues</li> <li>Implement proper error handling in your client applications</li> </ul>"},{"location":"servers/kendra-index-mcp-server/#security-considerations","title":"Security Considerations","text":"<p>When using this MCP server, consider:</p> <ul> <li>This MCP server needs permissions to query and list Amazon Kendra Indexes</li> <li>This MCP server cannot create, modify, or delete resources in your account</li> </ul>"},{"location":"servers/kendra-index-mcp-server/#troubleshooting","title":"Troubleshooting","text":"<ul> <li>If you encounter permission errors, verify your IAM user has the correct policies attached</li> <li>For connection issues, check network configurations and security groups</li> <li>If resource modification fails with a tag validation error, it means the resource was not created by the MCP server</li> <li>For general Amazon Kendra issues, consult the Amazon Kendra developer guide</li> </ul>"},{"location":"servers/kendra-index-mcp-server/#version","title":"Version","text":"<p>Current MCP server version: 0.0.0</p>"},{"location":"servers/lambda-tool-mcp-server/","title":"AWS Lambda Tool MCP Server","text":"<p>A Model Context Protocol (MCP) server for AWS Lambda to select and run Lambda function as MCP tools without code changes.</p>"},{"location":"servers/lambda-tool-mcp-server/#features","title":"Features","text":"<p>This MCP server acts as a bridge between MCP clients and AWS Lambda functions, allowing generative AI models to access and run Lambda functions as tools. This is useful, for example, to access private resources such as internal applications and databases without the need to provide public network access. This approach allows the model to use other AWS services, private networks, and the public internet.</p> <pre><code>graph LR\n    A[Model] &lt;--&gt; B[MCP Client]\n    B &lt;--&gt; C[\"MCP2Lambda&lt;br&gt;(MCP Server)\"]\n    C &lt;--&gt; D[Lambda Function]\n    D &lt;--&gt; E[Other AWS Services]\n    D &lt;--&gt; F[Internet]\n    D &lt;--&gt; G[VPC]\n\n    style A fill:#f9f,stroke:#333,stroke-width:2px\n    style B fill:#bbf,stroke:#333,stroke-width:2px\n    style C fill:#bfb,stroke:#333,stroke-width:4px\n    style D fill:#fbb,stroke:#333,stroke-width:2px\n    style E fill:#fbf,stroke:#333,stroke-width:2px\n    style F fill:#dff,stroke:#333,stroke-width:2px\n    style G fill:#ffd,stroke:#333,stroke-width:2px</code></pre> <p>From a security perspective, this approach implements segregation of duties by allowing the model to invoke the Lambda functions but not to access the other AWS services directly. The client only needs AWS credentials to invoke the Lambda functions. The Lambda functions can then interact with other AWS services (using the function role) and access public or private networks.</p>"},{"location":"servers/lambda-tool-mcp-server/#prerequisites","title":"Prerequisites","text":"<ol> <li>Install <code>uv</code> from Astral or the GitHub README</li> <li>Install Python using <code>uv python install 3.10</code></li> </ol>"},{"location":"servers/lambda-tool-mcp-server/#installation","title":"Installation","text":"<p>Configure the MCP server in your MCP client configuration (e.g., for Amazon Q Developer CLI, edit <code>~/.aws/amazonq/mcp.json</code>):</p> <pre><code>{\n  \"mcpServers\": {\n    \"awslabs.lambda-tool-mcp-server\": {\n      \"command\": \"uvx\",\n      \"args\": [\"awslabs.lambda-tool-mcp-server@latest\"],\n      \"env\": {\n        \"AWS_PROFILE\": \"your-aws-profile\",\n        \"AWS_REGION\": \"us-east-1\",\n        \"FUNCTION_PREFIX\": \"your-function-prefix\",\n        \"FUNCTION_LIST\": \"your-first-function, your-second-function\",\n        \"FUNCTION_TAG_KEY\": \"your-tag-key\",\n        \"FUNCTION_TAG_VALUE\": \"your-tag-value\",\n        \"FUNCTION_INPUT_SCHEMA_ARN_TAG_KEY\": \"your-function-tag-for-input-schema\"\n      }\n    }\n  }\n}\n</code></pre> <p>or docker after a successful <code>docker build -t awslabs/bedrock-kb-retrieval-mcp-server .</code>:</p> <pre><code># fictitious `.env` file with AWS temporary credentials\nAWS_ACCESS_KEY_ID=ASIAIOSFODNN7EXAMPLE\nAWS_SECRET_ACCESS_KEY=wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY\nAWS_SESSION_TOKEN=AQoEXAMPLEH4aoAH0gNCAPy...truncated...zrkuWJOgQs8IZZaIv2BXIa2R4Olgk\n</code></pre> <pre><code>  {\n    \"mcpServers\": {\n      \"awslabs.lambda-tool-mcp-server\": {\n        \"command\": \"docker\",\n        \"args\": [\n          \"run\",\n          \"--rm\",\n          \"--interactive\",\n          \"--env\",\n          \"AWS_REGION=us-east-1\",\n          \"--env\",\n          \"FUNCTION_PREFIX=your-function-prefix\",\n          \"--env\",\n          \"FUNCTION_LIST=your-first-function,your-second-function\",\n          \"--env\",\n          \"FUNCTION_TAG_KEY=your-tag-key\",\n          \"--env\",\n          \"FUNCTION_TAG_VALUE=your-tag-value\",\n          \"--env\",\n          \"FUNCTION_INPUT_SCHEMA_ARN_TAG_KEY=your-function-tag-for-input-schema\",\n          \"--env-file\",\n          \"/full/path/to/file/above/.env\",\n          \"awslabs/lambda-tool-mcp-server:latest\"\n        ],\n        \"env\": {},\n        \"disabled\": false,\n        \"autoApprove\": []\n      }\n    }\n  }\n</code></pre> <p>NOTE: Your credentials will need to be kept refreshed from your host</p> <p>The <code>AWS_PROFILE</code> and the <code>AWS_REGION</code> are optional, their default values are <code>default</code> and <code>us-east-1</code>.</p> <p>You can specify <code>FUNCTION_PREFIX</code>, <code>FUNCTION_LIST</code>, or both. If both are empty, all functions pass the name check. After the name check, if both <code>FUNCTION_TAG_KEY</code> and <code>FUNCTION_TAG_VALUE</code> are set, functions are further filtered by tag (with key=value). If only one of <code>FUNCTION_TAG_KEY</code> and <code>FUNCTION_TAG_VALUE</code>, then no function is selected and a warning is displayed.</p> <p>IMPORTANT: The function name is used as MCP tool name. The function description in AWS Lambda is used as MCP tool description. The function description should clarify when to use the function (what it provides) and how (which parameters). For example, a function that gives access to an internal Customer Relationship Management (CRM) system can use this description: <pre><code>Retrieve customer status on the CRM system based on { 'customerId' } or { 'customerEmail' }\n</code></pre></p> <p>The lambda function parameters can also be provided through the EventBridge Schema Registry, which provides formal JSON Schema. See Schema Support below.</p> <p>Sample functions that can be deployed via AWS SAM are provided in the <code>examples</code> folder.</p>"},{"location":"servers/lambda-tool-mcp-server/#schema-support","title":"Schema Support","text":"<p>The Lambda MCP Server supports input schema through AWS EventBridge Schema Registry. This provides formal JSON Schema documentation for your Lambda function inputs.</p>"},{"location":"servers/lambda-tool-mcp-server/#configuration","title":"Configuration","text":"<p>To use schema validation:</p> <ol> <li>Create your schema in EventBridge Schema Registry</li> <li>Tag your Lambda function with the schema ARN:    <pre><code>Key: FUNCTION_INPUT_SCHEMA_ARN_TAG_KEY (configurable)\nValue: arn:aws:schemas:region:account:schema/registry-name/schema-name\n</code></pre></li> <li>Configure the MCP server with the tag key:    <pre><code>{\n  \"env\": {\n    \"FUNCTION_INPUT_SCHEMA_ARN_TAG_KEY\": \"your-schema-arn-tag-key\"\n  }\n}\n</code></pre></li> </ol> <p>When a Lambda function has a schema tag, the MCP server will: 1. Fetch the schema from EventBridge Schema Registry 2. Add the schema to the tool's documentation</p> <p>This provides better documentation compared to describing parameters in the function description.</p>"},{"location":"servers/lambda-tool-mcp-server/#best-practices","title":"Best practices","text":"<ul> <li>Use the <code>FUNCTION_LIST</code> to specify the functions that are available as MCP tools.</li> <li>Use the <code>FUNCTION_PREFIX</code> to specify the prefix of the functions that are available as MCP tools.</li> <li>Use the <code>FUNCTION_TAG_KEY</code> and <code>FUNCTION_TAG_VALUE</code> to specify the tag key and value of the functions that are available as MCP tools.</li> <li>AWS Lambda <code>Description</code> property: the description of the function is used as MCP tool description, so it should be very detailed to help the model understand when and how to use the function</li> <li>Use EventBridge Schema Registry to provide formal input validation:</li> <li>Create JSON Schema definitions for your function inputs</li> <li>Tag functions with their schema ARNs</li> <li>Configure <code>FUNCTION_INPUT_SCHEMA_ARN_TAG_KEY</code> in the MCP server</li> </ul>"},{"location":"servers/lambda-tool-mcp-server/#security-considerations","title":"Security Considerations","text":"<p>When using this MCP server, you should consider:</p> <ul> <li>Only Lambda functions that are in the provided list or with a name starting with the prefix are imported as MCP tools.</li> <li>The MCP server needs permissions to invoke the Lambda functions.</li> <li>Each Lambda function has its own permissions to optionally access other AWS resources.</li> </ul>"},{"location":"servers/memcached-mcp-server/","title":"Amazon ElastiCache Memcached MCP Server","text":"<p>MCP server for interacting with Amazon ElastiCache Memcached through a secure and reliable connection</p>"},{"location":"servers/memcached-mcp-server/#features","title":"Features","text":""},{"location":"servers/memcached-mcp-server/#complete-memcached-protocol-support","title":"Complete Memcached Protocol Support","text":"<ul> <li>Full support for all standard Memcached operations</li> <li>Secure communication with SSL/TLS encryption</li> <li>Automatic connection management and pooling</li> <li>Built-in retry mechanism for failed operations</li> </ul>"},{"location":"servers/memcached-mcp-server/#prerequisites","title":"Prerequisites","text":"<ol> <li>Install <code>uv</code> from Astral or the GitHub README</li> <li>Install Python using <code>uv python install 3.10</code></li> <li>Access to a Memcached server.</li> <li>For instructions to connect to an Amazon ElastiCache Memcached cache click here</li> </ol>"},{"location":"servers/memcached-mcp-server/#installation","title":"Installation","text":"<p>Here are some ways you can work with MCP (e.g. for Amazon Q Developer CLI MCP, <code>~/.aws/amazonq/mcp.json</code>):</p> <pre><code>{\n  \"mcpServers\": {\n    \"awslabs.memcached-mcp-server\": {\n      \"command\": \"uvx\",\n      \"args\": [\"awslabs.memcached-mcp-server@latest\"],\n      \"env\": {\n        \"FASTMCP_LOG_LEVEL\": \"ERROR\",\n        \"MEMCACHED_HOST\": \"your-memcached-host\",\n        \"MEMCACHED_PORT\": \"11211\"\n      },\n      \"disabled\": false,\n      \"autoApprove\": []\n    }\n  }\n}\n</code></pre> <p>or docker after a successful <code>docker build -t awslabs/memcached-mcp-server .</code>:</p> <pre><code>{\n  \"mcpServers\": {\n    \"awslabs.memcached-mcp-server\": {\n      \"command\": \"docker\",\n      \"args\": [\n        \"run\",\n        \"--rm\",\n        \"--interactive\",\n        \"--env\",\n        \"FASTMCP_LOG_LEVEL=ERROR\",\n        \"--env\",\n        \"MEMCACHED_HOST=your-memcached-host\",\n        \"--env\",\n        \"MEMCACHED_PORT=11211\",\n        \"awslabs/memcached-mcp-server:latest\"\n      ],\n      \"env\": {},\n      \"disabled\": false,\n      \"autoApprove\": []\n    }\n  }\n}\n</code></pre>"},{"location":"servers/memcached-mcp-server/#configuration","title":"Configuration","text":""},{"location":"servers/memcached-mcp-server/#basic-connection-settings","title":"Basic Connection Settings","text":"<p>Configure the connection using these environment variables:</p> <pre><code># Basic settings\nMEMCACHED_HOST=127.0.0.1          # Memcached server hostname\nMEMCACHED_PORT=11211              # Memcached server port\nMEMCACHED_TIMEOUT=1              # Operation timeout in seconds\nMEMCACHED_CONNECT_TIMEOUT=5      # Connection timeout in seconds\nMEMCACHED_RETRY_TIMEOUT=1        # Retry delay in seconds\nMEMCACHED_MAX_RETRIES=3         # Maximum number of retry attempts\n</code></pre>"},{"location":"servers/memcached-mcp-server/#ssltls-configuration","title":"SSL/TLS Configuration","text":"<p>Enable and configure SSL/TLS support with these variables:</p> <pre><code># SSL/TLS settings\nMEMCACHED_USE_TLS=true                           # Enable SSL/TLS\nMEMCACHED_TLS_CERT_PATH=/path/to/client-cert.pem # Client certificate\nMEMCACHED_TLS_KEY_PATH=/path/to/client-key.pem   # Client private key\nMEMCACHED_TLS_CA_CERT_PATH=/path/to/ca-cert.pem  # CA certificate\nMEMCACHED_TLS_VERIFY=true                        # Enable cert verification\n</code></pre> <p>The server automatically handles: - Connection establishment and management - SSL/TLS encryption when enabled - Automatic retrying of failed operations - Timeout enforcement and error handling</p>"},{"location":"servers/memcached-mcp-server/#development","title":"Development","text":""},{"location":"servers/memcached-mcp-server/#running-tests","title":"Running Tests","text":"<pre><code>uv venv\nsource .venv/bin/activate\nuv sync\nuv run --frozen pytest\n</code></pre>"},{"location":"servers/memcached-mcp-server/#building-docker-image","title":"Building Docker Image","text":"<pre><code>docker build -t awslabs/memcached-mcp-server .\n</code></pre>"},{"location":"servers/memcached-mcp-server/#running-docker-container","title":"Running Docker Container","text":"<pre><code>docker run -p 8080:8080 \\\n  -e MEMCACHED_HOST=host.docker.internal \\\n  -e MEMCACHED_PORT=11211 \\\n  awslabs/memcached-mcp-server\n</code></pre>"},{"location":"servers/mysql-mcp-server/","title":"AWS Labs MySQL MCP Server","text":"<p>An AWS Labs Model Context Protocol (MCP) server for Aurora MySQL</p>"},{"location":"servers/mysql-mcp-server/#features","title":"Features","text":""},{"location":"servers/mysql-mcp-server/#natural-language-to-mysql-sql-query","title":"Natural language to MySQL SQL query","text":"<ul> <li>Converting human-readable questions and commands into structured MySQL-compatible SQL queries and executing them against the configured Aurora MySQL database.</li> </ul>"},{"location":"servers/mysql-mcp-server/#prerequisites","title":"Prerequisites","text":"<ol> <li>Install <code>uv</code> from Astral or the GitHub README</li> <li>Install Python using <code>uv python install 3.10</code></li> <li>Aurora MySQL Cluster with MySQL username and password stored in AWS Secrets Manager</li> <li>Enable RDS Data API for your Aurora MySQL Cluster, see instructions here</li> <li>This MCP server can only be run locally on the same host as your LLM client.</li> <li>Docker runtime</li> <li>Set up AWS credentials with access to AWS services</li> <li>You need an AWS account with appropriate permissions</li> <li>Configure AWS credentials with <code>aws configure</code> or environment variables</li> </ol>"},{"location":"servers/mysql-mcp-server/#installation","title":"Installation","text":"<p>Configure the MCP server in your MCP client configuration (e.g., for Amazon Q Developer CLI, edit <code>~/.aws/amazonq/mcp.json</code>):</p> <pre><code>{\n  \"mcpServers\": {\n    \"awslabs.mysql-mcp-server\": {\n      \"command\": \"uvx\",\n      \"args\": [\n        \"awslabs.mysql-mcp-server@latest\",\n        \"--resource_arn\", \"[your data]\",\n        \"--secret_arn\", \"[your data]\",\n        \"--database\", \"[your data]\",\n        \"--region\", \"[your data]\",\n        \"--readonly\", \"True\"\n      ],\n      \"env\": {\n        \"AWS_PROFILE\": \"your-aws-profile\",\n        \"AWS_REGION\": \"us-east-1\",\n        \"FASTMCP_LOG_LEVEL\": \"ERROR\"\n      },\n      \"disabled\": false,\n      \"autoApprove\": []\n    }\n  }\n}\n</code></pre>"},{"location":"servers/mysql-mcp-server/#build-and-install-docker-image-locally-on-the-same-host-of-your-llm-client","title":"Build and install docker image locally on the same host of your LLM client","text":"<ol> <li>'git clone https://github.com/awslabs/mcp.git'</li> <li>Go to sub-directory 'src/mysql-mcp-server/'</li> <li>Run 'docker build -t awslabs/mysql-mcp-server:latest .'</li> </ol>"},{"location":"servers/mysql-mcp-server/#add-or-update-your-llm-clients-config-with-following","title":"Add or update your LLM client's config with following:","text":"<pre><code>\n{\n  \"mcpServers\": {\n    \"awslabs.mysql-mcp-server\": {\n      \"command\": \"docker\",\n      \"args\": [\n        \"run\",\n        \"-i\",\n        \"--rm\",\n        \"-e\", \"AWS_ACCESS_KEY_ID=[your data]\",\n        \"-e\", \"AWS_SECRET_ACCESS_KEY=[your data]\",\n        \"-e\", \"AWS_REGION=[your data]\",\n        \"awslabs/mysql-mcp-server:latest\",\n        \"--resource_arn\", \"[your data]\",\n        \"--secret_arn\", \"[your data]\",\n        \"--database\", \"[your data]\",\n        \"--region\", \"[your data]\",\n        \"--readonly\", \"True\"\n      ]\n    }\n  }\n}\n</code></pre> <p>NOTE: By default, only read-only queries are allowed and it is controlled by --readonly parameter above. Set it to False if you also want to allow writable DML or DDL.</p>"},{"location":"servers/mysql-mcp-server/#aws-authentication","title":"AWS Authentication","text":"<p>The MCP server uses the AWS profile specified in the <code>AWS_PROFILE</code> environment variable. If not provided, it defaults to the \"default\" profile in your AWS configuration file.</p> <pre><code>\"env\": {\n  \"AWS_PROFILE\": \"your-aws-profile\"\n}\n</code></pre> <p>Make sure the AWS profile has permissions to access the RDS data API, and the secret from AWS Secrets Manager. The MCP server creates a boto3 session using the specified profile to authenticate with AWS services. Your AWS IAM credentials remain on your local machine and are strictly used for accessing AWS services.</p>"},{"location":"servers/nova-canvas-mcp-server/","title":"Amazon Nova Canvas MCP Server","text":"<p>MCP server for generating images using Amazon Nova Canvas</p>"},{"location":"servers/nova-canvas-mcp-server/#features","title":"Features","text":""},{"location":"servers/nova-canvas-mcp-server/#text-based-image-generation","title":"Text-based image generation","text":"<ul> <li>Create images from text prompts with <code>generate_image</code></li> <li>Customizable dimensions (320-4096px), quality options, and negative prompting</li> <li>Supports multiple image generation (1-5) in single request</li> <li>Adjustable parameters like cfg_scale (1.1-10.0) and seeded generation</li> </ul>"},{"location":"servers/nova-canvas-mcp-server/#color-guided-image-generation","title":"Color-guided image generation","text":"<ul> <li>Generate images with specific color palettes using <code>generate_image_with_colors</code></li> <li>Define up to 10 hex color values to influence the image style and mood</li> <li>Same customization options as text-based generation</li> </ul>"},{"location":"servers/nova-canvas-mcp-server/#workspace-integration","title":"Workspace integration","text":"<ul> <li>Images saved to user-specified workspace directories with automatic folder creation</li> </ul>"},{"location":"servers/nova-canvas-mcp-server/#aws-authentication","title":"AWS authentication","text":"<ul> <li>Uses AWS profiles for secure access to Amazon Nova Canvas services</li> </ul>"},{"location":"servers/nova-canvas-mcp-server/#prerequisites","title":"Prerequisites","text":"<ol> <li>Install <code>uv</code> from Astral or the GitHub README</li> <li>Install Python using <code>uv python install 3.10</code></li> <li>Set up AWS credentials with access to Amazon Bedrock and Nova Canvas</li> <li>You need an AWS account with Amazon Bedrock and Amazon Nova Canvas enabled</li> <li>Configure AWS credentials with <code>aws configure</code> or environment variables</li> <li>Ensure your IAM role/user has permissions to use Amazon Bedrock and Nova Canvas</li> </ol>"},{"location":"servers/nova-canvas-mcp-server/#installation","title":"Installation","text":"<p>Configure the MCP server in your MCP client configuration (e.g., for Amazon Q Developer CLI, edit <code>~/.aws/amazonq/mcp.json</code>):</p> <pre><code>{\n  \"mcpServers\": {\n    \"awslabs.nova-canvas-mcp-server\": {\n      \"command\": \"uvx\",\n      \"args\": [\"awslabs.nova-canvas-mcp-server@latest\"],\n      \"env\": {\n        \"AWS_PROFILE\": \"your-aws-profile\",\n        \"AWS_REGION\": \"us-east-1\",\n        \"FASTMCP_LOG_LEVEL\": \"ERROR\"\n      },\n      \"disabled\": false,\n      \"autoApprove\": []\n    }\n  }\n}\n</code></pre> <p>or docker after a successful <code>docker build -t awslabs/nova-canvas-mcp-server .</code>:</p> <pre><code># fictitious `.env` file with AWS temporary credentials\nAWS_ACCESS_KEY_ID=ASIAIOSFODNN7EXAMPLE\nAWS_SECRET_ACCESS_KEY=wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY\nAWS_SESSION_TOKEN=AQoEXAMPLEH4aoAH0gNCAPy...truncated...zrkuWJOgQs8IZZaIv2BXIa2R4Olgk\n</code></pre> <pre><code>  {\n    \"mcpServers\": {\n      \"awslabs.nova-canvas-mcp-server\": {\n        \"command\": \"docker\",\n        \"args\": [\n          \"run\",\n          \"--rm\",\n          \"--interactive\",\n          \"--env\",\n          \"AWS_REGION=us-east-1\",\n          \"--env\",\n          \"FASTMCP_LOG_LEVEL=ERROR\",\n          \"--env-file\",\n          \"/full/path/to/file/above/.env\",\n          \"awslabs/nova-canvas-mcp-server:latest\"\n        ],\n        \"env\": {},\n        \"disabled\": false,\n        \"autoApprove\": []\n      }\n    }\n  }\n</code></pre> <p>NOTE: Your credentials will need to be kept refreshed from your host</p>"},{"location":"servers/nova-canvas-mcp-server/#installing-via-smithery","title":"Installing via Smithery","text":"<p>To install Amazon Nova Canvas MCP Server for Claude Desktop automatically via Smithery:</p> <pre><code>npx -y @smithery/cli install @awslabs/nova-canvas-mcp-server --client claude\n</code></pre>"},{"location":"servers/nova-canvas-mcp-server/#aws-authentication_1","title":"AWS Authentication","text":"<p>The MCP server uses the AWS profile specified in the <code>AWS_PROFILE</code> environment variable. If not provided, it defaults to the \"default\" profile in your AWS configuration file.</p> <pre><code>\"env\": {\n  \"AWS_PROFILE\": \"your-aws-profile\",\n  \"AWS_REGION\": \"us-east-1\"\n}\n</code></pre> <p>Make sure the AWS profile has permissions to access Amazon Bedrock and Amazon Nova Canvas. The MCP server creates a boto3 session using the specified profile to authenticate with AWS services. Your AWS IAM credentials remain on your local machine and are strictly used for using the Amazon Bedrock model APIs.</p>"},{"location":"servers/postgres-mcp-server/","title":"AWS Labs postgres MCP Server","text":"<p>An AWS Labs Model Context Protocol (MCP) server for Aurora Postgres</p>"},{"location":"servers/postgres-mcp-server/#features","title":"Features","text":""},{"location":"servers/postgres-mcp-server/#natural-language-to-postgres-sql-query","title":"Natural language to Postgres SQL query","text":"<ul> <li>Converting human-readable questions and commands into structured Postgres-compatible SQL queries and executing them against the configured Aurora Postgres database.</li> </ul>"},{"location":"servers/postgres-mcp-server/#prerequisites","title":"Prerequisites","text":"<ol> <li>Install <code>uv</code> from Astral or the GitHub README</li> <li>Install Python using <code>uv python install 3.10</code></li> <li>Aurora Postgres Cluster with Postgres username and password stored in AWS Secrets Manager</li> <li>Enable RDS Data API for your Aurora Postgres Cluster, see instructions here</li> <li>This MCP server can only be run locally on the same host as your LLM client.</li> <li>Docker runtime</li> <li>Set up AWS credentials with access to AWS services</li> <li>You need an AWS account with appropriate permissions</li> <li>Configure AWS credentials with <code>aws configure</code> or environment variables</li> </ol>"},{"location":"servers/postgres-mcp-server/#installation","title":"Installation","text":"<p>Configure the MCP server in your MCP client configuration (e.g., for Amazon Q Developer CLI, edit <code>~/.aws/amazonq/mcp.json</code>):</p> <pre><code>{\n  \"mcpServers\": {\n    \"awslabs.postgres-mcp-server\": {\n      \"command\": \"uvx\",\n      \"args\": [\n        \"awslabs.postgres-mcp-server@latest\",\n        \"--resource_arn\", \"[your data]\",\n        \"--secret_arn\", \"[your data]\",\n        \"--database\", \"[your data]\",\n        \"--region\", \"[your data]\",\n        \"--readonly\", \"True\"\n      ],\n      \"env\": {\n        \"AWS_PROFILE\": \"your-aws-profile\",\n        \"AWS_REGION\": \"us-east-1\",\n        \"FASTMCP_LOG_LEVEL\": \"ERROR\"\n      },\n      \"disabled\": false,\n      \"autoApprove\": []\n    }\n  }\n}\n</code></pre>"},{"location":"servers/postgres-mcp-server/#build-and-install-docker-image-locally-on-the-same-host-of-your-llm-client","title":"Build and install docker image locally on the same host of your LLM client","text":"<ol> <li>'git clone https://github.com/awslabs/mcp.git'</li> <li>Go to sub-directory 'src/postgres-mcp-server/'</li> <li>Run 'docker build -t awslabs/postgres-mcp-server:latest .'</li> </ol>"},{"location":"servers/postgres-mcp-server/#add-or-update-your-llm-clients-config-with-following","title":"Add or update your LLM client's config with following:","text":"<pre><code>\n{\n  \"mcpServers\": {\n    \"awslabs.postgres-mcp-server\": {\n      \"command\": \"docker\",\n      \"args\": [\n        \"run\",\n        \"-i\",\n        \"--rm\",\n        \"-e\", \"AWS_ACCESS_KEY_ID=[your data]\",\n        \"-e\", \"AWS_SECRET_ACCESS_KEY=[your data]\",\n        \"-e\", \"AWS_REGION=[your data]\",\n        \"awslabs/postgres-mcp-server:latest\",\n        \"--resource_arn\", \"[your data]\",\n        \"--secret_arn\", \"[your data]\",\n        \"--database\", \"[your data]\",\n        \"--region\", \"[your data]\",\n        \"--readonly\", \"True\"\n      ]\n    }\n  }\n}\n</code></pre> <p>NOTE: By default, only read-only queries are allowed and it is controlled by --readonly parameter above. Set it to False if you also want to allow writable DML or DDL.</p>"},{"location":"servers/postgres-mcp-server/#aws-authentication","title":"AWS Authentication","text":"<p>The MCP server uses the AWS profile specified in the <code>AWS_PROFILE</code> environment variable. If not provided, it defaults to the \"default\" profile in your AWS configuration file.</p> <pre><code>\"env\": {\n  \"AWS_PROFILE\": \"your-aws-profile\"\n}\n</code></pre> <p>Make sure the AWS profile has permissions to access the RDS data API, and the secret from AWS Secrets Manager. The MCP server creates a boto3 session using the specified profile to authenticate with AWS services. Your AWS IAM credentials remain on your local machine and are strictly used for accessing AWS services.</p>"},{"location":"servers/prometheus-mcp-server/","title":"Prometheus MCP Server","text":"<p>The Prometheus MCP Server provides a robust interface for interacting with AWS Managed Prometheus, enabling users to execute PromQL queries, list metrics, and retrieve server information with AWS SigV4 authentication support.</p> <p>This MCP server is designed to be fully compatible with Amazon Q developer CLI, allowing seamless integration of Prometheus monitoring capabilities into your Amazon Q workflows. You can load the server directly into Amazon Q to leverage its powerful querying and metric analysis features through the familiar Q interface.</p>"},{"location":"servers/prometheus-mcp-server/#features","title":"Features","text":"<ul> <li>Execute instant PromQL queries against AWS Managed Prometheus</li> <li>Execute range queries with start time, end time, and step interval</li> <li>List all available metrics in your Prometheus instance</li> <li>Get server configuration information</li> <li>AWS SigV4 authentication for secure access</li> <li>Automatic retries with exponential backoff</li> </ul>"},{"location":"servers/prometheus-mcp-server/#installation","title":"Installation","text":""},{"location":"servers/prometheus-mcp-server/#prerequisites","title":"Prerequisites","text":"<ul> <li>Python 3.10 or higher</li> <li>AWS credentials configured with appropriate permissions</li> <li>AWS Managed Prometheus workspace</li> </ul>"},{"location":"servers/prometheus-mcp-server/#configuration","title":"Configuration","text":"<p>The server is configured through the Amazon Q MCP configuration file as shown in the Usage section below.</p>"},{"location":"servers/prometheus-mcp-server/#usage-with-amazon-q","title":"Usage with Amazon Q","text":"<p>Here are some ways you can work with MCP across AWS, and we'll be adding support to more products including Amazon Q Developer CLI soon:</p> <ol> <li> <p>Create a configuration file: <pre><code>mkdir -p ~/.aws/amazonq/\n</code></pre></p> </li> <li> <p>Add the following to <code>~/.aws/amazonq/mcp.json</code>: <pre><code>{\n  \"mcpServers\": {\n    \"awslabs.prometheus-mcp-server\": {\n      \"command\": \"uvx\",\n      \"args\": [\n        \"awslabs.prometheus-mcp-server@latest\",\n        \"--url\",\n        \"https://aps-workspaces.us-east-1.amazonaws.com/workspaces/ws-&lt;Workspace ID&gt;\",\n        \"--region\",\n        \"&lt;Your AWS Region&gt;\",\n        \"--profile\",\n        \"&lt;Your CLI Profile [default] if no profile is used&gt;\"\n      ],\n      \"env\": {\n        \"FASTMCP_LOG_LEVEL\": \"DEBUG\",\n        \"AWS_PROFILE\": \"&lt;Your CLI Profile [default] if no profile is used&gt;\"\n      }\n    }\n  }\n}\n</code></pre></p> </li> <li> <p>In Amazon Q, you can now use the Prometheus MCP server to query your metrics.</p> </li> </ol>"},{"location":"servers/prometheus-mcp-server/#available-tools","title":"Available Tools","text":"<ol> <li>execute_query</li> <li>Execute instant PromQL queries against Prometheus</li> <li> <p>Parameters: query (required), time (optional)</p> </li> <li> <p>execute_range_query</p> </li> <li>Execute PromQL queries over a time range</li> <li> <p>Parameters: query, start time, end time, step interval</p> </li> <li> <p>list_metrics</p> </li> <li>Retrieve all available metric names from Prometheus</li> <li> <p>Returns: Sorted list of metric names</p> </li> <li> <p>get_server_info</p> </li> <li>Retrieve server configuration details</li> <li>Returns: URL, region, profile, and service information</li> </ol>"},{"location":"servers/prometheus-mcp-server/#example-queries","title":"Example Queries","text":"<pre><code># Execute an instant query\nresult = await execute_query(\"up\")\n\n# Execute a range query\ndata = await execute_range_query(\n    query=\"rate(node_cpu_seconds_total[5m])\",\n    start=\"2023-01-01T00:00:00Z\",\n    end=\"2023-01-01T01:00:00Z\",\n    step=\"1m\"\n)\n\n# List available metrics\nmetrics = await list_metrics()\n\n# Get server information\ninfo = await get_server_info()\n</code></pre>"},{"location":"servers/prometheus-mcp-server/#troubleshooting","title":"Troubleshooting","text":"<p>Common issues and solutions:</p> <ol> <li>AWS Credentials Not Found</li> <li>Check ~/.aws/credentials</li> <li>Set AWS_PROFILE environment variable</li> <li> <p>Verify IAM permissions</p> </li> <li> <p>Connection Errors</p> </li> <li>Verify Prometheus URL is correct</li> <li>Check network connectivity</li> <li> <p>Ensure AWS VPC access is configured correctly</p> </li> <li> <p>Authentication Failures</p> </li> <li>Verify AWS credentials are current</li> <li>Check system clock synchronization</li> <li>Ensure correct AWS region is specified</li> </ol>"},{"location":"servers/prometheus-mcp-server/#license","title":"License","text":"<p>This project is licensed under the Apache License 2.0 - see the LICENSE file for details.</p>"},{"location":"servers/stepfunctions-tool-mcp-server/","title":"AWS Step Functions Tool MCP Server","text":"<p>A Model Context Protocol (MCP) server for AWS Step Functions to select and run state machines as MCP tools without code changes.</p>"},{"location":"servers/stepfunctions-tool-mcp-server/#features","title":"Features","text":"<p>This MCP server acts as a bridge between MCP clients and AWS Step Functions state machines, allowing generative AI models to access and run state machines as tools. This enables seamless integration with existing Step Function workflows without requiring any modifications to their definitions. Through this bridge, AI models can execute and manage complex, multi-step business processes that coordinate operations across multiple AWS services.</p> <p>The server supports both Standard and Express workflows, adapting to different execution needs. Standard workflows excel at long-running processes where status tracking is essential, while Express workflows handle high-volume, short-duration tasks with synchronous execution. This flexibility ensures optimal handling of various workflow patterns and requirements.</p> <p>To ensure data quality and provide clear documentation, the server integrates with EventBridge Schema Registry for input validation. It combines schema information with state machine definitions to generate comprehensive tool documentation, helping AI models understand both the purpose and technical requirements of each workflow.</p> <p>From a security perspective, the server implements IAM-based authentication and authorization, creating a clear separation of duties. While models can invoke state machines through the MCP server, they don't have direct access to other AWS services. Instead, the state machines themselves handle AWS service interactions using their own IAM roles, maintaining robust security boundaries while enabling powerful workflow capabilities.</p> <pre><code>graph LR\n    A[Model] &lt;--&gt; B[MCP Client]\n    B &lt;--&gt; C[\"MCP2StepFunctions&lt;br&gt;(MCP Server)\"]\n    C &lt;--&gt; D[State Machine]\n    D &lt;--&gt; E[Other AWS Services]\n    D &lt;--&gt; F[Internet]\n    D &lt;--&gt; G[VPC]\n\n    style A fill:#f9f,stroke:#333,stroke-width:2px\n    style B fill:#bbf,stroke:#333,stroke-width:2px\n    style C fill:#bfb,stroke:#333,stroke-width:4px\n    style D fill:#fbb,stroke:#333,stroke-width:2px\n    style E fill:#fbf,stroke:#333,stroke-width:2px\n    style F fill:#dff,stroke:#333,stroke-width:2px\n    style G fill:#ffd,stroke:#333,stroke-width:2px</code></pre>"},{"location":"servers/stepfunctions-tool-mcp-server/#prerequisites","title":"Prerequisites","text":"<ol> <li>Install <code>uv</code> from Astral or the GitHub README</li> <li>Install Python using <code>uv python install 3.10</code></li> </ol>"},{"location":"servers/stepfunctions-tool-mcp-server/#installation","title":"Installation","text":"<p>Configure the MCP server in your MCP client configuration (e.g., for Amazon Q Developer CLI, edit <code>~/.aws/amazonq/mcp.json</code>):</p> <pre><code>{\n  \"mcpServers\": {\n    \"awslabs.stepfunctions-tool-mcp-server\": {\n      \"command\": \"uvx\",\n      \"args\": [\"awslabs.stepfunctions-tool-mcp-server@latest\"],\n      \"env\": {\n        \"AWS_PROFILE\": \"your-aws-profile\",\n        \"AWS_REGION\": \"us-east-1\",\n        \"STATE_MACHINE_PREFIX\": \"your-state-machine-prefix\",\n        \"STATE_MACHINE_LIST\": \"your-first-state-machine, your-second-state-machine\",\n        \"STATE_MACHINE_TAG_KEY\": \"your-tag-key\",\n        \"STATE_MACHINE_TAG_VALUE\": \"your-tag-value\",\n        \"STATE_MACHINE_INPUT_SCHEMA_ARN_TAG_KEY\": \"your-state-machine-tag-for-input-schema\"\n      }\n    }\n  }\n}\n</code></pre> <p>or docker after a successful <code>docker build -t awslabs/stepfunctions-tool-mcp-server .</code>:</p> <pre><code># fictitious `.env` file with AWS temporary credentials\nAWS_ACCESS_KEY_ID=ASIAIOSFODNN7EXAMPLE\nAWS_SECRET_ACCESS_KEY=wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY\nAWS_SESSION_TOKEN=AQoEXAMPLEH4aoAH0gNCAPy...truncated...zrkuWJOgQs8IZZaIv2BXIa2R4Olgk\n</code></pre> <pre><code>  {\n    \"mcpServers\": {\n      \"awslabs.stepfunctions-tool-mcp-server\": {\n        \"command\": \"docker\",\n        \"args\": [\n          \"run\",\n          \"--rm\",\n          \"--interactive\",\n          \"--env\",\n          \"AWS_REGION=us-east-1\",\n          \"--env\",\n          \"STATE_MACHINE_PREFIX=your-state-machine-prefix\",\n          \"--env\",\n          \"STATE_MACHINE_LIST=your-first-state-machine,your-second-state-machine\",\n          \"--env\",\n          \"STATE_MACHINE_TAG_KEY=your-tag-key\",\n          \"--env\",\n          \"STATE_MACHINE_TAG_VALUE=your-tag-value\",\n          \"--env\",\n          \"STATE_MACHINE_INPUT_SCHEMA_ARN_TAG_KEY=your-state-machine-tag-for-input-schema\",\n          \"--env-file\",\n          \"/full/path/to/file/above/.env\",\n          \"awslabs/stepfunctions-tool-mcp-server:latest\"\n        ],\n        \"env\": {},\n        \"disabled\": false,\n        \"autoApprove\": []\n      }\n    }\n  }\n</code></pre> <p>NOTE: Your credentials will need to be kept refreshed from your host</p> <p>The <code>AWS_PROFILE</code> and the <code>AWS_REGION</code> are optional, their default values are <code>default</code> and <code>us-east-1</code>.</p> <p>You can specify <code>STATE_MACHINE_PREFIX</code>, <code>STATE_MACHINE_LIST</code>, or both. If both are empty, all state machines pass the name check. After the name check, if both <code>STATE_MACHINE_TAG_KEY</code> and <code>STATE_MACHINE_TAG_VALUE</code> are set, state machines are further filtered by tag (with key=value). If only one of <code>STATE_MACHINE_TAG_KEY</code> and <code>STATE_MACHINE_TAG_VALUE</code>, then no state machine is selected and a warning is displayed.</p>"},{"location":"servers/stepfunctions-tool-mcp-server/#tool-documentation","title":"Tool Documentation","text":"<p>The MCP server builds comprehensive tool documentation by combining multiple sources of information to help AI models understand and use state machines effectively.</p> <ol> <li> <p>State Machine Description: The state machine's description field provides the base tool description. For example:    <pre><code>Retrieve customer status on the CRM system based on { 'customerId' } or { 'customerEmail' }\n</code></pre></p> </li> <li> <p>Workflow Description: The Comment field from the state machine definition adds workflow context. For example:    <pre><code>{\n  \"Comment\": \"This workflow first looks up a customer ID from email, then retrieves their info\",\n  \"StartAt\": \"GetCustomerId\",\n  \"States\": { ... }\n}\n</code></pre></p> </li> <li> <p>Input Schema: The server integrates with EventBridge Schema Registry to provide formal JSON Schema documentation for state machine inputs. To enable schema support:</p> </li> <li>Create your schema in EventBridge Schema Registry</li> <li>Tag your state machine with the schema ARN:      <pre><code>Key: STATE_MACHINE_INPUT_SCHEMA_ARN_TAG_KEY (configurable)\nValue: arn:aws:schemas:region:account:schema/registry-name/schema-name\n</code></pre></li> <li>Configure the MCP server:      <pre><code>{\n  \"env\": {\n    \"STATE_MACHINE_INPUT_SCHEMA_ARN_TAG_KEY\": \"your-schema-arn-tag-key\"\n  }\n}\n</code></pre></li> </ol> <p>The server combines these sources into a unified documentation format: <pre><code>[State Machine Description]\n\nWorkflow Description: [Comment from state machine definition]\n\nInput Schema:\n[JSON Schema from EventBridge Schema Registry]\n</code></pre></p> <p>This comprehensive documentation helps AI models understand both the purpose and technical requirements of each state machine, with formal schema support ensuring correct input formatting.</p>"},{"location":"servers/stepfunctions-tool-mcp-server/#best-practices","title":"Best practices","text":"<ul> <li>Use the <code>STATE_MACHINE_LIST</code> to specify the state machines that are available as MCP tools.</li> <li>Use the <code>STATE_MACHINE_PREFIX</code> to specify the prefix of the state machines that are available as MCP tools.</li> <li>Use the <code>STATE_MACHINE_TAG_KEY</code> and <code>STATE_MACHINE_TAG_VALUE</code> to specify the tag key and value of the state machines that are available as MCP tools.</li> <li>AWS Step Functions <code>Description</code> property: the description of the state machine is used as MCP tool description, so it should be very detailed to help the model understand when and how to use the state machine</li> <li>Add workflow documentation using the <code>Comment</code> field in state machine definitions:</li> <li>Describe the workflow's purpose and steps</li> <li>Explain any important logic or conditions</li> <li>Document expected inputs and outputs</li> <li>Use EventBridge Schema Registry to provide formal input definition:</li> <li>Create JSON Schema definitions for your state machine inputs</li> <li>Tag state machines with their schema ARNs</li> <li>Configure <code>STATE_MACHINE_INPUT_SCHEMA_ARN_TAG_KEY</code> in the MCP server</li> </ul>"},{"location":"servers/stepfunctions-tool-mcp-server/#security-considerations","title":"Security Considerations","text":"<p>When using this MCP server, you should consider:</p> <ul> <li>Only state machines that are in the provided list or with a name starting with the prefix are imported as MCP tools.</li> <li>The MCP server needs permissions to invoke the state machines.</li> <li>Each state machine has its own permissions to optionally access other AWS resources.</li> </ul>"},{"location":"servers/syntheticdata-mcp-server/","title":"Synthetic Data MCP Server","text":"<p>A Model Context Protocol (MCP) server for generating, validating, and managing synthetic data.</p>"},{"location":"servers/syntheticdata-mcp-server/#overview","title":"Overview","text":"<p>This MCP server provides tools for generating synthetic data based on business descriptions, executing pandas code safely, validating data structures, and loading data to storage systems like S3.</p>"},{"location":"servers/syntheticdata-mcp-server/#features","title":"Features","text":"<ul> <li>Business-Driven Generation: Generate synthetic data instructions based on business descriptions</li> <li>Data Generation Instructions: Generate structured data generation instructions from business descriptions</li> <li>Safe Pandas Code Execution: Run pandas code in a restricted environment with automatic DataFrame detection</li> <li>JSON Lines Validation: Validate and convert JSON Lines data to CSV format</li> <li>Data Validation: Validate data structure, referential integrity, and save as CSV files</li> <li>Referential Integrity Checking: Validate relationships between tables</li> <li>Data Quality Assessment: Identify potential issues in data models (3NF validation)</li> <li>Storage Integration: Load data to various storage targets (S3) with support for:</li> <li>Multiple file formats (CSV, JSON, Parquet)</li> <li>Partitioning options</li> <li>Storage class configuration</li> <li>Encryption settings</li> </ul>"},{"location":"servers/syntheticdata-mcp-server/#prerequisites","title":"Prerequisites","text":"<ol> <li>Install <code>uv</code> from Astral or the GitHub README</li> <li>Install Python using <code>uv python install 3.10</code></li> <li>Set up AWS credentials with access to AWS services</li> <li>You need an AWS account with appropriate permissions</li> <li>Configure AWS credentials with <code>aws configure</code> or environment variables</li> </ol>"},{"location":"servers/syntheticdata-mcp-server/#installation","title":"Installation","text":"<pre><code>{\n  \"mcpServers\": {\n    \"awslabs.syntheticdata-mcp-server\": {\n      \"command\": \"uvx\",\n      \"args\": [\"awslabs.syntheticdata-mcp-server\"],\n      \"env\": {\n        \"FASTMCP_LOG_LEVEL\": \"ERROR\",\n        \"AWS_PROFILE\": \"your-aws-profile\",\n        \"AWS_REGION\": \"us-east-1\"\n      },\n      \"autoApprove\": [],\n      \"disabled\": false\n    }\n  }\n}\n</code></pre> <p>NOTE: Your credentials will need to be kept refreshed from your host</p>"},{"location":"servers/syntheticdata-mcp-server/#aws-authentication","title":"AWS Authentication","text":"<p>The MCP server uses the AWS profile specified in the <code>AWS_PROFILE</code> environment variable. If not provided, it defaults to the \"default\" profile in your AWS configuration file.</p> <pre><code>\"env\": {\n  \"AWS_PROFILE\": \"your-aws-profile\"\n}\n</code></pre>"},{"location":"servers/syntheticdata-mcp-server/#usage","title":"Usage","text":""},{"location":"servers/syntheticdata-mcp-server/#getting-data-generation-instructions","title":"Getting Data Generation Instructions","text":"<pre><code>response = await server.get_data_gen_instructions(\n    business_description=\"An e-commerce platform with customers, orders, and products\"\n)\n</code></pre>"},{"location":"servers/syntheticdata-mcp-server/#executing-pandas-code","title":"Executing Pandas Code","text":"<pre><code>response = await server.execute_pandas_code(\n    code=\"your_pandas_code_here\",\n    workspace_dir=\"/path/to/workspace\",\n    output_dir=\"data\"\n)\n</code></pre>"},{"location":"servers/syntheticdata-mcp-server/#validating-and-saving-data","title":"Validating and Saving Data","text":"<pre><code>response = await server.validate_and_save_data(\n    data={\n        \"customers\": [{\"id\": 1, \"name\": \"John\"}],\n        \"orders\": [{\"id\": 101, \"customer_id\": 1}]\n    },\n    workspace_dir=\"/path/to/workspace\",\n    output_dir=\"data\"\n)\n</code></pre>"},{"location":"servers/syntheticdata-mcp-server/#loading-to-storage","title":"Loading to Storage","text":"<pre><code>response = await server.load_to_storage(\n    data={\n        \"customers\": [{\"id\": 1, \"name\": \"John\"}]\n    },\n    targets=[{\n        \"type\": \"s3\",\n        \"config\": {\n            \"bucket\": \"my-bucket\",\n            \"prefix\": \"data/\",\n            \"format\": \"parquet\"\n        }\n    }]\n)\n</code></pre>"},{"location":"servers/terraform-mcp-server/","title":"AWS Terraform MCP Server","text":"<p>MCP server for Terraform on AWS best practices, infrastructure as code patterns, and security compliance with Checkov.</p>"},{"location":"servers/terraform-mcp-server/#features","title":"Features","text":"<ul> <li>Terraform Best Practices - Get prescriptive Terraform advice for building applications on AWS</li> <li>AWS Well-Architected guidance for Terraform configurations</li> <li>Security and compliance recommendations</li> <li> <p>AWSCC provider prioritization for consistent API behavior</p> </li> <li> <p>Security-First Development Workflow - Follow a structured process for creating secure code</p> </li> <li>Step-by-step guidance for validation and security scanning</li> <li>Integration of Checkov at the right stages of development</li> <li> <p>Clear handoff points between AI assistance and developer deployment</p> </li> <li> <p>Checkov Integration - Work with Checkov for security and compliance scanning</p> </li> <li>Run security scans on Terraform code to identify vulnerabilities</li> <li>Automatically fix identified security issues when possible</li> <li> <p>Get detailed remediation guidance for compliance issues</p> </li> <li> <p>AWS Provider Documentation - Search for AWS and AWSCC provider resources</p> </li> <li>Find documentation for specific resources and attributes</li> <li>Get example snippets and implementation guidance</li> <li> <p>Compare AWS and AWSCC provider capabilities</p> </li> <li> <p>AWS-IA GenAI Modules - Access specialized modules for AI/ML workloads</p> </li> <li>Amazon Bedrock module for generative AI applications</li> <li>OpenSearch Serverless for vector search capabilities</li> <li>SageMaker endpoint deployment for ML model hosting</li> <li> <p>Serverless Streamlit application deployment for AI interfaces</p> </li> <li> <p>Terraform Registry Module Analysis - Analyze Terraform Registry modules</p> </li> <li>Search for modules by URL or identifier</li> <li>Extract input variables, output variables, and README content</li> <li>Understand module usage and configuration options</li> <li> <p>Analyze module structure and dependencies</p> </li> <li> <p>Terraform Workflow Execution - Run Terraform commands directly</p> </li> <li>Initialize, plan, validate, apply, and destroy operations</li> <li>Pass variables and specify AWS regions</li> <li> <p>Get formatted command output for analysis</p> </li> <li> <p>Terragrunt Workflow Execution - Run Terragrunt commands directly</p> </li> <li>Initialize, plan, validate, apply, run-all and destroy operations</li> <li>Pass variables and specify AWS regions</li> <li>Configure terragrunt-config and and include/exclude paths flags</li> <li>Get formatted command output for analysis</li> </ul>"},{"location":"servers/terraform-mcp-server/#tools-and-resources","title":"Tools and Resources","text":"<ul> <li>Terraform Development Workflow: Follow security-focused development process via <code>terraform://workflow_guide</code></li> <li>AWS Best Practices: Access AWS-specific guidance via <code>terraform://aws_best_practices</code></li> <li>AWS Provider Resources: Access resource listings via <code>terraform://aws_provider_resources_listing</code></li> <li>AWSCC Provider Resources: Access resource listings via <code>terraform://awscc_provider_resources_listing</code></li> </ul>"},{"location":"servers/terraform-mcp-server/#prerequisites","title":"Prerequisites","text":"<ol> <li>Install <code>uv</code> from Astral or the GitHub README</li> <li>Install Python using <code>uv python install 3.10</code></li> <li>Install Terraform CLI for workflow execution</li> <li>Install Checkov for security scanning</li> </ol>"},{"location":"servers/terraform-mcp-server/#installation","title":"Installation","text":"<p>Configure the MCP server in your MCP client configuration (e.g., for Amazon Q Developer CLI, edit <code>~/.aws/amazonq/mcp.json</code>):</p> <pre><code>{\n  \"mcpServers\": {\n    \"awslabs.terraform-mcp-server\": {\n      \"command\": \"uvx\",\n      \"args\": [\"awslabs.terraform-mcp-server@latest\"],\n      \"env\": {\n        \"FASTMCP_LOG_LEVEL\": \"ERROR\"\n      },\n      \"disabled\": false,\n      \"autoApprove\": []\n    }\n  }\n}\n</code></pre> <p>or docker after a successful <code>docker build -t awslabs/terraform-mcp-server .</code>:</p> <pre><code>  {\n    \"mcpServers\": {\n      \"awslabs.terraform-mcp-server\": {\n        \"command\": \"docker\",\n        \"args\": [\n          \"run\",\n          \"--rm\",\n          \"--interactive\",\n          \"--env\",\n          \"FASTMCP_LOG_LEVEL=ERROR\",\n          \"awslabs/terraform-mcp-server:latest\"\n        ],\n        \"env\": {},\n        \"disabled\": false,\n        \"autoApprove\": []\n      }\n    }\n  }\n</code></pre>"},{"location":"servers/terraform-mcp-server/#security-considerations","title":"Security Considerations","text":"<p>When using this MCP server, you should consider: - Following the structured development workflow that integrates validation and security scanning - Reviewing all Checkov warnings and errors manually - Fixing security issues rather than ignoring them whenever possible - Documenting clear justifications for any necessary exceptions - Using the RunCheckovScan tool regularly to verify security compliance - Preferring the AWSCC provider for its consistent API behavior and better security defaults</p> <p>Before applying Terraform changes to production environments, you should conduct your own independent assessment to ensure that your infrastructure would comply with your own specific security and quality control practices and standards, as well as the local laws, rules, and regulations that govern you and your content.</p>"},{"location":"servers/timestream-for-influxdb-mcp-server/","title":"AWS Labs Timestream for InfluxDB MCP Server","text":"<p>An AWS Labs Model Context Protocol (MCP) server for Timestream for InfluxDB. This server provides tools to interact with AWS Timestream for InfluxDB APIs, allowing you to create and manage database instances, clusters, parameter groups, and more. It also includes tools to interact with InfluxDB's write and query APIs.</p>"},{"location":"servers/timestream-for-influxdb-mcp-server/#features","title":"Features","text":"<ul> <li>Create, update, list, describe, and delete Timestream for InfluxDB database instances</li> <li>Create, update, list, describe, and delete Timestream for InfluxDB database clusters</li> <li>Manage DB parameter groups</li> <li>Tag management for Timestream for InfluxDB resources</li> <li>Write and query data using InfluxDB's APIs</li> </ul>"},{"location":"servers/timestream-for-influxdb-mcp-server/#pre-requisites","title":"Pre-requisites","text":"<ol> <li>Install <code>uv</code> from Astral or the GitHub README</li> <li>Install Python using <code>uv python install 3.10</code></li> <li>Set up AWS credentials with access to AWS services<ul> <li>You need an AWS account with appropriate permissions</li> <li>Configure AWS credentials with <code>aws configure</code> or environment variables</li> <li>Consider starting with Read-only permission if you don't want the LLM to modify any resources</li> </ul> </li> </ol>"},{"location":"servers/timestream-for-influxdb-mcp-server/#installation","title":"Installation","text":"<p>You can modify the settings of your MCP client to run your local server (e.g. for Amazon Q Developer CLI MCP, <code>~/.aws/amazonq/mcp.json</code>)</p> <pre><code>{\n  \"mcpServers\": {\n    \"awslabs.timestream-for-influxdb-mcp-server\": {\n      \"command\": \"uvx\",\n      \"args\": [\"awslabs.timestream-for-influxdb-mcp-server@latest\"],\n      \"env\": {\n        \"AWS_PROFILE\": \"your-aws-profile\",\n        \"AWS_REGION\": \"us-east-1\",\n        \"FASTMCP_LOG_LEVEL\": \"ERROR\"\n      },\n      \"disabled\": false,\n      \"autoApprove\": []\n    }\n  }\n}\n</code></pre>"},{"location":"servers/timestream-for-influxdb-mcp-server/#available-tools","title":"Available Tools","text":"<p>The Timestream for InfluxDB MCP server provides the following tools:</p>"},{"location":"servers/timestream-for-influxdb-mcp-server/#aws-timestream-for-influxdb-management","title":"AWS Timestream for InfluxDB Management","text":""},{"location":"servers/timestream-for-influxdb-mcp-server/#database-cluster-management","title":"Database Cluster Management","text":"<ul> <li><code>CreateDbCluster</code>: Create a new Timestream for InfluxDB database cluster</li> <li><code>GetDbCluster</code>: Retrieve information about a specific DB cluster</li> <li><code>DeleteDbCluster</code>: Delete a Timestream for InfluxDB database cluster</li> <li><code>ListDbClusters</code>: List all Timestream for InfluxDB database clusters</li> <li><code>UpdateDbCluster</code>: Update a Timestream for InfluxDB database cluster</li> <li><code>ListDbClusters</code>: List all Timestream for InfluxDB database clusters</li> <li><code>ListDbInstancesForCluster</code>: List DB instances belonging to a specific cluster</li> <li><code>ListClustersByStatus</code>: List DB clusters filtered by status</li> </ul>"},{"location":"servers/timestream-for-influxdb-mcp-server/#database-instance-management","title":"Database Instance Management","text":"<ul> <li><code>CreateDbInstance</code>: Create a new Timestream for InfluxDB database instance</li> <li><code>GetDbInstance</code>: Retrieve information about a specific DB instance</li> <li><code>DeleteDbInstance</code>: Delete a Timestream for InfluxDB database instance</li> <li><code>ListDbInstances</code>: List all Timestream for InfluxDB database instances</li> <li><code>UpdateDbInstance</code>: Update a Timestream for InfluxDB database instance</li> <li><code>ListDbInstancesByStatus</code>: List DB instances filtered by status</li> </ul>"},{"location":"servers/timestream-for-influxdb-mcp-server/#parameter-group-management","title":"Parameter Group Management","text":"<ul> <li><code>CreateDbParamGroup</code>: Create a new DB parameter group</li> <li><code>GetDbParameterGroup</code>: Retrieve information about a specific DB parameter group</li> <li><code>ListDbParamGroups</code>: List all DB parameter groups</li> </ul>"},{"location":"servers/timestream-for-influxdb-mcp-server/#tag-management","title":"Tag Management","text":"<ul> <li><code>ListTagsForResource</code>: List all tags on a Timestream for InfluxDB resource</li> <li><code>TagResource</code>: Add tags to a Timestream for InfluxDB resource</li> <li><code>UntagResource</code>: Remove tags from a Timestream for InfluxDB resource</li> </ul>"},{"location":"servers/timestream-for-influxdb-mcp-server/#influxdb-data-operations","title":"InfluxDB Data Operations","text":""},{"location":"servers/timestream-for-influxdb-mcp-server/#write-api","title":"Write API","text":"<ul> <li><code>InfluxDBWritePoints</code>: Write data points to InfluxDB</li> <li><code>InfluxDBWriteLP</code>: Write data in Line Protocol format to InfluxDB</li> </ul>"},{"location":"servers/timestream-for-influxdb-mcp-server/#query-api","title":"Query API","text":"<ul> <li><code>InfluxDBQuery</code>: Query data from InfluxDB using Flux query language</li> </ul>"},{"location":"servers/valkey-mcp-server/","title":"Amazon ElastiCache/MemoryDB Valkey MCP Server","text":"<p>An AWS Labs Model Context Protocol (MCP) server for Amazon ElastiCache Valkey datastores.</p>"},{"location":"servers/valkey-mcp-server/#features","title":"Features","text":"<p>This MCP server provides tools to operate on Valkey data types. For example, it allows an agent to operate with Valkey Strings using commands such as SET, SETRANGE, GET, GETRANGE, APPEND, INCREMENT and more.</p>"},{"location":"servers/valkey-mcp-server/#supported-data-types","title":"Supported Data Types","text":"<ul> <li><code>Strings</code>- Store, retrieve, append, increment, decrement, length and more.</li> <li><code>Lists</code>- Manage List collections with push/pop operations.</li> <li><code>Sets and Sorted Sets</code>- Store and retrieve items from Sets.</li> <li><code>Hashes</code>- Store and retrieve items in Hashes. Check for existence of items in a hash, increment item values in a Hash, and more.</li> <li><code>Streams</code>- Store, retrieve, trim items in Streams.</li> <li><code>Bitmaps</code>- Bitmaps let you perform bitwise operations on strings.</li> <li><code>JSONs</code>- Store and retrieve JSON documents with path-based access.</li> <li><code>HyperLogLog</code>- Store and count items in HyperLogs.</li> </ul>"},{"location":"servers/valkey-mcp-server/#advanced-features","title":"Advanced Features","text":"<ul> <li>Cluster Support: Support for standalone and clustered Valkey deployments.</li> <li>SSL/TLS Security: Configure secure connections using SSL/TLS.</li> <li>Connection Pooling: Pools connections by default to enable efficient connection management.</li> </ul>"},{"location":"servers/valkey-mcp-server/#prerequisites","title":"Prerequisites","text":"<ol> <li>Install <code>uv</code> from Astral or the GitHub README</li> <li>Install Python using <code>uv python install 3.10</code></li> <li>Access to a Valkey datastore.</li> <li>For instructions to connect to an Amazon ElastiCache/MemoryDB Valkey datastore click here.</li> </ol>"},{"location":"servers/valkey-mcp-server/#installation","title":"Installation","text":"<p>Here are some ways you can work with MCP across AWS tools (e.g., for Amazon Q Developer CLI MCP, <code>~/.aws/amazonq/mcp.json</code>):</p> <pre><code>{\n  \"mcpServers\": {\n    \"awslabs.valkey-mcp-server\": {\n      \"command\": \"uvx\",\n      \"args\": [\n        \"awslabs.valkey-mcp-server@latest\"\n      ],\n      \"env\": {\n        \"VALKEY_HOST\": \"127.0.0.1\",\n        \"VALKEY_PORT\": \"6379\",\n        \"FASTMCP_LOG_LEVEL\": \"ERROR\"\n      },\n      \"autoApprove\": [],\n      \"disabled\": false\n    }\n  }\n}\n</code></pre> <p>Or using Docker after a successful <code>docker build -t awslabs/valkey-mcp-server .</code>:</p> <pre><code>{\n  \"mcpServers\": {\n    \"awslabs.valkey-mcp-server\": {\n      \"command\": \"docker\",\n      \"args\": [\n        \"run\",\n        \"--rm\",\n        \"--interactive\",\n        \"--env\",\n        \"FASTMCP_LOG_LEVEL=ERROR\",\n        \"--env\",\n        \"VALKEY_HOST=127.0.0.1\",\n        \"--env\",\n        \"VALKEY_PORT=6379\",\n        \"awslabs/valkey-mcp-server:latest\"\n      ],\n      \"env\": {},\n      \"disabled\": false,\n      \"autoApprove\": []\n    }\n  }\n}\n</code></pre>"},{"location":"servers/valkey-mcp-server/#configuration","title":"Configuration","text":"<p>The server can be configured using the following environment variables:</p> Name Description Default Value <code>VALKEY_HOST</code> ElastiCache Primary Endpoint or MemoryDB Cluster Endpoint or Valkey IP or hostname <code>\"127.0.0.1\"</code> <code>VALKEY_PORT</code> Valkey port <code>6379</code> <code>VALKEY_USERNAME</code> Default database username <code>None</code> <code>VALKEY_PWD</code> Default database password <code>\"\"</code> <code>VALKEY_USE_SSL</code> Enables or disables SSL/TLS <code>False</code> <code>VALKEY_CA_PATH</code> CA certificate for verifying server <code>None</code> <code>VALKEY_SSL_KEYFILE</code> Client's private key file <code>None</code> <code>VALKEY_SSL_CERTFILE</code> Client's certificate file <code>None</code> <code>VALKEY_CERT_REQS</code> Server certificate verification <code>\"required\"</code> <code>VALKEY_CA_CERTS</code> Path to trusted CA certificates <code>None</code> <code>VALKEY_CLUSTER_MODE</code> Enable Valkey Cluster mode <code>False</code>"},{"location":"servers/valkey-mcp-server/#example-usage","title":"Example Usage","text":"<p>Here are some example natural language queries that the server can handle:</p> <pre><code>\"Store user profile data in a hash\"\n\"Add this event to the activity stream\"\n\"Cache API response for 5 minutes\"\n\"Store JSON document with nested fields\"\n\"Add score 100 to user123 in leaderboard\"\n\"Get all members of the admins set\"\n</code></pre>"},{"location":"servers/valkey-mcp-server/#development","title":"Development","text":""},{"location":"servers/valkey-mcp-server/#running-tests","title":"Running Tests","text":"<pre><code>uv venv\nsource .venv/bin/activate\nuv sync\nuv run --frozen pytest\n</code></pre>"},{"location":"servers/valkey-mcp-server/#building-docker-image","title":"Building Docker Image","text":"<pre><code>docker build -t awslabs/valkey-mcp-server .\n</code></pre>"},{"location":"servers/valkey-mcp-server/#running-docker-container","title":"Running Docker Container","text":"<pre><code>docker run -p 8080:8080 \\\n  -e VALKEY_HOST=host.docker.internal \\\n  -e VALKEY_PORT=6379 \\\n  awslabs/valkey-mcp-server\n</code></pre>"}]}